{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Quali - Aprendizado Raso (RQA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estruturação de pipeline baseado em aprendizado raso utilizando atributos determinísticos calculados sobre os gráficos de recorrência (RQA).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:15:42.335300Z",
     "start_time": "2021-03-30T11:15:39.831262Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "from pretty_confusion_matrix import *\n",
    "\n",
    "# TODO: implementar rotina na classe PyNILM.utils\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "def listar_variaveis_memoria(ambiente):\n",
    "    print(\"* Variáveis instanciadas em memória:\")\n",
    "    print(\"---\")\n",
    "    total = 0\n",
    "    for name, size in sorted(((name, sys.getsizeof(value)) for name, value in ambiente.items()),\n",
    "                             key= lambda x: -x[1])[:10]:\n",
    "        total += size\n",
    "        print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))\n",
    "    print(\"---\")\n",
    "    print(\"Total:\", sizeof_fmt(total))\n",
    "    \n",
    "# TODO: implementar na classe utils\n",
    "def highlight_col(x):\n",
    "    r = 'background-color: #D9D9D9'\n",
    "    df1 = pd.DataFrame('', index=x.index, columns=x.columns)\n",
    "    df1.iloc[:, -2] = r\n",
    "    return df1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:15:42.473290Z",
     "start_time": "2021-03-30T11:15:42.339060Z"
    }
   },
   "outputs": [],
   "source": [
    "# CONSTANTES FUNDAMENTAIS DE ORGANIZACAO DE PASTAS/ARQUIVOS\n",
    "RESIDENCIA = 3\n",
    "\n",
    "# Path do arquivo H5 (base REDD ja preparada p/ NILMTK) e outros insumos fundamentais\n",
    "caminho_dados = \"D:/Projetos/phd-thesis/datasets/\"\n",
    "\n",
    "# Definir diretorios onde iremos salvar os insumos gerados do notebook (dados, imagens, etc.)\n",
    "caminho_dados_notebook = os.path.join(caminho_dados, \"22\") # Num. notebook\n",
    "if not os.path.isdir(caminho_dados_notebook):\n",
    "    os.makedirs(caminho_dados_notebook)\n",
    "caminho_imagens_notebook = os.path.join(caminho_dados_notebook, \"imagens\") # Num. notebook\n",
    "if not os.path.isdir(caminho_imagens_notebook):\n",
    "    os.makedirs(caminho_imagens_notebook)\n",
    "\n",
    "# Path do arquivo H5 (base REDD ja preparada p/ NILMTK)\n",
    "caminho_redd = os.path.join(caminho_dados, \"REDD/low_freq\")\n",
    "\n",
    "# Path completo do arquivo REDD\n",
    "arquivo_dataset = os.path.join(caminho_redd, \"redd.h5\")\n",
    "\n",
    "# VARIAVEL AUXILIAR\n",
    "# Path dos arquivos relacionados as janelas\n",
    "caminho_janelas = os.path.join(caminho_redd, \"../../phd\")\n",
    "if not os.path.isdir(caminho_janelas):\n",
    "    os.makedirs(caminho_janelas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:15:44.390903Z",
     "start_time": "2021-03-30T11:15:42.507218Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from six import iteritems\n",
    "\n",
    "from nilmtk import DataSet, TimeFrame, MeterGroup, HDFDataStore\n",
    "from nilmtk.legacy.disaggregate import CombinatorialOptimisation, FHMM\n",
    "import nilmtk.utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base REDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:15:45.051732Z",
     "start_time": "2021-03-30T11:15:44.392915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NILMTK -> Detalhes sobre o dataset REDD:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ul><li><strong>name</strong>: REDD</li><li><strong>long_name</strong>: The Reference Energy Disaggregation Data set</li><li><strong>creators</strong>: <ul><li>Kolter, Zico</li><li>Johnson, Matthew</li></ul></li><li><strong>publication_date</strong>: 2011</li><li><strong>institution</strong>: Massachusetts Institute of Technology (MIT)</li><li><strong>contact</strong>: zkolter@cs.cmu.edu</li><li><strong>description</strong>: Several weeks of power data for 6 different homes.</li><li><strong>subject</strong>: Disaggregated power demand from domestic buildings.</li><li><strong>number_of_buildings</strong>: 6</li><li><strong>timezone</strong>: US/Eastern</li><li><strong>geo_location</strong>: <ul><li><strong>locality</strong>: Massachusetts</li><li><strong>country</strong>: US</li><li><strong>latitude</strong>: 42.360091</li><li><strong>longitude</strong>: -71.09416</li></ul></li><li><strong>related_documents</strong>: <ul><li><a href=\"http://redd.csail.mit.edu\">http://redd.csail.mit.edu</a></li><li>J. Zico Kolter and Matthew J. Johnson. REDD: A public data set for energy disaggregation research. In proceedings of the SustKDD workshop on Data Mining Applications in Sustainability, 2011. <a href=\"http://redd.csail.mit.edu/kolter-kddsust11.pdf\">http://redd.csail.mit.edu/kolter-kddsust11.pdf</a>\n",
       "</li></ul></li><li><strong>schema</strong>: <a href=\"https://github.com/nilmtk/nilm_metadata/tree/v0.2\">https://github.com/nilmtk/nilm_metadata/tree/v0.2</a></li><li><strong>meter_devices</strong>: <ul><li><strong>eMonitor</strong>: <ul><li><strong>model</strong>: eMonitor</li><li><strong>manufacturer</strong>: Powerhouse Dynamics</li><li><strong>manufacturer_url</strong>: <a href=\"http://powerhousedynamics.com\">http://powerhousedynamics.com</a></li><li><strong>description</strong>: Measures circuit-level power demand.  Comes with 24 CTs. This FAQ page suggests the eMonitor measures real (active) power: <a href=\"http://www.energycircle.com/node/14103\">http://www.energycircle.com/node/14103</a>  although the REDD readme.txt says all channels record apparent power.\n",
       "</li><li><strong>sample_period</strong>: 3</li><li><strong>max_sample_period</strong>: 50</li><li><strong>measurements</strong>: <ul><li>{'physical_quantity': 'power', 'type': 'active', 'upper_limit': 5000, 'lower_limit': 0}</li></ul></li><li><strong>wireless</strong>: False</li></ul></li><li><strong>REDD_whole_house</strong>: <ul><li><strong>description</strong>: REDD's DIY power meter used to measure whole-home AC waveforms at high frequency.  To quote from their paper: \"CTs from TED (<a href=\"http://www.theenergydetective.com\">http://www.theenergydetective.com</a>) to measure current in the power mains, a Pico TA041 oscilloscope probe (<a href=\"http://www.picotechnologies.com\">http://www.picotechnologies.com</a>) to measure voltage for one of the two phases in the home, and a National Instruments NI-9239 analog to digital converter to transform both these analog signals to digital readings. This A/D converter has 24 bit resolution with noise of approximately 70 ÂµV, which determines the noise level of our current and voltage readings: the TED CTs are rated for 200 amp circuits and a maximum of 3 volts, so we are able to differentiate between currents of approximately ((200))(70 Ã— 10âˆ’6)/(3) = 4.66mA, corresponding to power changes of about 0.5 watts. Similarly, since we use a 1:100 voltage stepdown in the oscilloscope probe, we can detect voltage differences of about 7mV.\"\n",
       "</li><li><strong>sample_period</strong>: 1</li><li><strong>max_sample_period</strong>: 30</li><li><strong>measurements</strong>: <ul><li>{'physical_quantity': 'power', 'type': 'apparent', 'upper_limit': 50000, 'lower_limit': 0}</li></ul></li><li><strong>wireless</strong>: False</li></ul></li></ul></li></ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Gerar arquivo H5 (Nilmtk) do dataset REDD, caso n exista\n",
    "if not os.path.isfile(arquivo_dataset):\n",
    "    from nilmtk.dataset_converters import convert_redd\n",
    "    \n",
    "    print(\"Gerando arquivo H5 (NILMTK) da base REDD, aguarde...\")\n",
    "    print(\"-----\")\n",
    "    convert_redd(caminho_redd, arquivo_dataset)\n",
    "\n",
    "# Carregando dataset REDD no objeto NILMTK\n",
    "# Exemplo de carregamento da base REDD no NILMTK\n",
    "import h5py # * Evitar erro de incompatibilidade entre h5py e nilmtk\n",
    "from nilmtk import DataSet\n",
    "from nilmtk.utils import print_dict\n",
    "redd = DataSet(arquivo_dataset)\n",
    "print(\"NILMTK -> Detalhes sobre o dataset REDD:\")\n",
    "print_dict(redd.metadata)\n",
    "print()\n",
    "\n",
    "# Parametros dos dados (treino)\n",
    "PARAMETROS_DATASET = {\n",
    "    \"base\":redd,\n",
    "    \"id_residencia\": RESIDENCIA,\n",
    "    \"inicio_intervalo\":'2011-04-16 05:11:30',\n",
    "    \"fim_intervalo\":'2011-04-23 08:43:26',\n",
    "    \"debug\": False    \n",
    "}\n",
    "# print(\"PARÂMETROS DO ESTUDO:\")\n",
    "# pprint(PARAMETROS_DATASET)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:15:45.067662Z",
     "start_time": "2021-03-30T11:15:45.054698Z"
    }
   },
   "outputs": [],
   "source": [
    "def carregar_dados_aparelho(janelas, instancia, aparelho, taxa, tamanho_janela, split_teste=None, eliminar_janelas_vazias=False, debug=False):\n",
    "    # Extrair series divididas em janelas para cada medidor\n",
    "    dados_cargas = janelas.preparar(\n",
    "        taxa_amostral=taxa, \n",
    "        intervalo_medicao=tamanho_janela\n",
    "    )\n",
    "    print()\n",
    "\n",
    "    # Pprearando dados (Serie / Estado)\n",
    "    # X\n",
    "    dados_medidores = janelas.filtrar_cargas(\n",
    "        dados_cargas,\n",
    "        filtros=[\n",
    "            (1, 'site_meter'),\n",
    "            (2, 'site_meter'),    \n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    dados_aparelho = janelas.filtrar_cargas(dados_cargas, filtros=[(instancia, aparelho)])[0]\n",
    "    \n",
    "    # Validar tamanho dos dados de medidores (podem ter mais registros que os aparelhos)\n",
    "    janela_media_medidores = int(np.sum([len(d[\"janelas\"])for d in dados_medidores])/len(dados_medidores))\n",
    "    janela_media_aparelho = len(dados_aparelho[\"janelas\"])#int(np.sum([len(d[\"janelas\"])for d in dados_aparelho])/len(dados_aparelho))\n",
    "\n",
    "    # Ajustando para medidores terem o mesmo shape de janelas dos aparelhos \n",
    "    if janela_media_medidores > janela_media_aparelho:\n",
    "        diferenca = janela_media_medidores-janela_media_aparelho\n",
    "        #if debug: print(\"  -> Diferenca encontrada entre medidores/aparelhos:\", diferenca, \", ajustando..\")\n",
    "        for i in range(len(dados_medidores)):\n",
    "            removidos = 0\n",
    "            while removidos < diferenca:\n",
    "                # Remover ultima janela\n",
    "                dados_medidores[i][\"janelas\"] = dados_medidores[i][\"janelas\"][:-1,:]\n",
    "                removidos += 1\n",
    "    \n",
    "    # Estruturando dados modelagem (X e y)\n",
    "    X = dados_medidores[0][\"janelas\"] + dados_medidores[1][\"janelas\"]\n",
    "\n",
    "    # Selecionando apenas janelas VALIDAS (ocorrencia de ao menos 1 carga)\n",
    "    # TODO: Implementar na biblioteca esta rotina de validacao\n",
    "    if eliminar_janelas_vazias:\n",
    "        idx_janelas_validas = np.where(np.sum(X, axis=1)>0)[0]\n",
    "        X = X[idx_janelas_validas]\n",
    "        #for i in range(len(dados_aparelhos)):\n",
    "        dados_aparelho[\"janelas\"] = dados_aparelho[\"janelas\"][idx_janelas_validas]\n",
    "        rotulos = copy.deepcopy(dados_aparelho[\"rotulos\"])\n",
    "        dados_aparelho[\"rotulos\"][\"estado\"] = rotulos[\"estado\"][idx_janelas_validas]\n",
    "        dados_aparelho[\"rotulos\"][\"media\"]  = rotulos[\"media\"][idx_janelas_validas]\n",
    "        dados_aparelho[\"rotulos\"][\"total\"]  = rotulos[\"total\"][idx_janelas_validas]\n",
    "        if debug:\n",
    "            print(\"   - `{}-{}`: {} => {}\".format(\n",
    "                dados_aparelho[\"carga\"].upper(), \n",
    "                dados_aparelho[\"instancia\"],\n",
    "                Counter(rotulos[\"estado\"]),\n",
    "                Counter(dados_aparelho[\"rotulos\"][\"estado\"])\n",
    "            ))\n",
    "\n",
    "    # y\n",
    "    y = dados_aparelho[\"rotulos\"][\"estado\"]\n",
    "\n",
    "    # <<< Limpando memoria >>>\n",
    "    dados_cargas = None\n",
    "    del dados_cargas\n",
    "    dados_medidores = None\n",
    "    del dados_medidores\n",
    "    dados_aparelho = None\n",
    "    del dados_aparelho\n",
    "    gc.collect()\n",
    "    # <<< Limpando memoria >>>\n",
    "\n",
    "    # Fazendo split dos dados (treino/teste)\n",
    "    if split_teste is None:\n",
    "        return X, y\n",
    "    else:\n",
    "        X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
    "            X, y, \n",
    "            test_size=split_teste,\n",
    "            stratify=y,\n",
    "            random_state=SEED\n",
    "        )\n",
    "        print()\n",
    "\n",
    "        return X_treino, X_teste, y_treino, y_teste        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melhores Combinações de Taxas e Janelas para cada Aparelho (estudo 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:15:49.040666Z",
     "start_time": "2021-03-30T11:15:49.008778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carga</th>\n",
       "      <th>taxa_amostragem</th>\n",
       "      <th>janela</th>\n",
       "      <th>loss</th>\n",
       "      <th>acuracia</th>\n",
       "      <th>precisao</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dish_washer - 9</td>\n",
       "      <td>2</td>\n",
       "      <td>720</td>\n",
       "      <td>0.05</td>\n",
       "      <td>95.33</td>\n",
       "      <td>20.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>22.22</td>\n",
       "      <td>59.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fridge - 7</td>\n",
       "      <td>2</td>\n",
       "      <td>1080</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>microwave - 16</td>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>0.04</td>\n",
       "      <td>95.83</td>\n",
       "      <td>66.67</td>\n",
       "      <td>33.33</td>\n",
       "      <td>44.44</td>\n",
       "      <td>71.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>washer_dryer - 13</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.89</td>\n",
       "      <td>100.00</td>\n",
       "      <td>95.74</td>\n",
       "      <td>97.83</td>\n",
       "      <td>98.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>washer_dryer - 14</td>\n",
       "      <td>3</td>\n",
       "      <td>360</td>\n",
       "      <td>0.02</td>\n",
       "      <td>97.99</td>\n",
       "      <td>100.00</td>\n",
       "      <td>55.56</td>\n",
       "      <td>71.43</td>\n",
       "      <td>85.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               carga  taxa_amostragem  janela  loss  acuracia  precisao  \\\n",
       "0    dish_washer - 9                2     720  0.05     95.33     20.00   \n",
       "1         fridge - 7                2    1080  0.00    100.00    100.00   \n",
       "2     microwave - 16                2     900  0.04     95.83     66.67   \n",
       "3  washer_dryer - 13                2      60  0.00     99.89    100.00   \n",
       "4  washer_dryer - 14                3     360  0.02     97.99    100.00   \n",
       "\n",
       "   recall      f1  f1_macro  \n",
       "0   25.00   22.22     59.91  \n",
       "1  100.00  100.00    100.00  \n",
       "2   33.33   44.44     71.14  \n",
       "3   95.74   97.83     98.88  \n",
       "4   55.56   71.43     85.19  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_melhores_taxas_janelas = pd.read_csv(os.path.join(caminho_dados, \"19\", \"melhores_taxa_janela_aparelhos.csv\"), index_col=0)\n",
    "df_melhores_taxas_janelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T01:46:07.507206Z",
     "start_time": "2021-03-30T01:46:07.496202Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# - Desenvolver módulo da metodologia na lib PyNILM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros de RP dos Aparelhos (estudo 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:17:25.236696Z",
     "start_time": "2021-03-30T11:17:25.120913Z"
    }
   },
   "outputs": [],
   "source": [
    "# Carregando arquivos de parametros, caso n estejam (kernel reiniciado)\n",
    "if not 'parametros_rp_aparelho' in locals():\n",
    "    with open(os.path.join(caminho_dados, \"18\", \"parametros_rp_aparelho.json\"),'r') as arquivo:\n",
    "        parametros_rp_aparelho = json.load(arquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambiente e Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:17:46.285890Z",
     "start_time": "2021-03-30T11:17:38.496646Z"
    }
   },
   "outputs": [],
   "source": [
    "# from PyNILM.dados.janelas import Janelas\n",
    "from PyNILM.dados.janelas import Janelas\n",
    "from PyNILM.avaliacao.metricas import *\n",
    "from PyNILM.avaliacao.graficos import *\n",
    "from PyNILM.avaliacao.analises import *\n",
    "\n",
    "from pyts.image import RecurrencePlot, GramianAngularField\n",
    "\n",
    "# Garantindo reprodutibilidade\n",
    "import random as rn\n",
    "\n",
    "# Constantes dos experimentos\n",
    "SEED = 33\n",
    "FRACAO_TESTE = 0.25\n",
    "EPOCAS = 100\n",
    "TAMANHO_LOTE = 32\n",
    "VERBOSIDADE = 2\n",
    "\n",
    "# Parametros RP (verificado empiricamente)\n",
    "PARAMETROS_RP = {\n",
    "    \"dimension\": 1,\n",
    "    \"time_delay\": 1,\n",
    "    \"threshold\": None,\n",
    "    \"percentage\": 10\n",
    "}\n",
    "TAMANHO_IMAGEM = (32,32)\n",
    "\n",
    "# Travar Seed's\n",
    "np.random.seed(SEED)\n",
    "rn.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "\n",
    "# Habilitando/limitando utilização de GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:17:46.300695Z",
     "start_time": "2021-03-30T11:17:46.288707Z"
    }
   },
   "outputs": [],
   "source": [
    "def instancia_aparelho_residencia(aparelho, residencia, base = redd):\n",
    "    \"\"\"Função para coletar o id/instancia do aparelho na residencia,\n",
    "    permitindo executar os testes independente da residencia\"\"\"\n",
    "    instancia = []\n",
    "    #for e in base.buildings[residencia].elec.all_meters():\n",
    "    for e_i in range(1, len(janelas.base.buildings[residencia].elec.all_meters())):\n",
    "\n",
    "        # Selecionando canal/aparelho\n",
    "        e = janelas.base.buildings[residencia].elec[e_i]\n",
    "        \n",
    "        if not hasattr(e,'meters'):\n",
    "            if e.label().lower().replace(\" \",\"_\") == aparelho:\n",
    "                instancia.append( e.instance() )\n",
    "        else:\n",
    "            for e_ in e.meters:\n",
    "                if e_.label().lower().replace(\" \",\"_\") == aparelho:\n",
    "                    instancia.append( e_.instance() )\n",
    "    return instancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo RQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T11:17:46.564181Z",
     "start_time": "2021-03-30T11:17:46.303668Z"
    }
   },
   "outputs": [],
   "source": [
    "# from pyrqa.time_series import TimeSeries\n",
    "# from pyrqa.settings import Settings\n",
    "# from pyrqa.analysis_type import Classic\n",
    "# from pyrqa.neighbourhood import FixedRadius\n",
    "# from pyrqa.metric import EuclideanMetric\n",
    "# from pyrqa.computation import RQAComputation\n",
    "\n",
    "# def calcular_rqa_amostras(X, rotulo_aparelho, params = PARAMETROS_RP):\n",
    "    \n",
    "#     rqa_data = []\n",
    "\n",
    "#     for x in tqdm_notebook(X):\n",
    "\n",
    "#         # Calculating RQA\n",
    "#         time_series = TimeSeries(x,\n",
    "#                      embedding_dimension=params[\"dimension\"],\n",
    "#                      time_delay=params[\"time_delay\"])\n",
    "#         settings = Settings(time_series,\n",
    "#                             analysis_type=Classic,\n",
    "#                             neighbourhood=FixedRadius(params[\"threshold\"]),\n",
    "#                             similarity_measure=EuclideanMetric)\n",
    "#         computation = RQAComputation.create(settings, verbose=False)\n",
    "#         rqa_result = computation.run()\n",
    "\n",
    "#         rqa_data.append( [aparelho] + list(rqa_result.to_array()) )\n",
    "        \n",
    "#     return rqa_data\n",
    "from pyrqa.time_series import TimeSeries\n",
    "from pyrqa.settings import Settings\n",
    "from pyrqa.analysis_type import Classic\n",
    "from pyrqa.neighbourhood import FixedRadius\n",
    "from pyrqa.metric import EuclideanMetric\n",
    "from pyrqa.computation import RQAComputation\n",
    "\n",
    "def calcular_rqa_amostras(X, Y, rotulo_aparelho, params = PARAMETROS_RP):\n",
    "    \n",
    "    rqa_data = []\n",
    "\n",
    "    for x, y in tqdm_notebook(zip(X, Y), total=Y.shape[0]):\n",
    "\n",
    "        # Calculating RQA\n",
    "        time_series = TimeSeries(x,\n",
    "                     embedding_dimension=params[\"dimension\"],\n",
    "                     time_delay=params[\"time_delay\"])\n",
    "        settings = Settings(time_series,\n",
    "                            analysis_type=Classic,\n",
    "                            neighbourhood=FixedRadius(params[\"percentage\"]/100), \n",
    "                            # PS.: Utilizando percentage ao inves de threshold \n",
    "                            # devido a semanticas distintas entre libs (pyts e pyrqa)\n",
    "                            # bem como distincao entre RPs (cnn) e RQAs (supervisionado).\n",
    "                            similarity_measure=EuclideanMetric)\n",
    "        computation = RQAComputation.create(settings, verbose=False)\n",
    "        rqa_result = computation.run()\n",
    "\n",
    "        rqa_data.append( [rotulo_aparelho, y]  + list(rqa_result.to_array()) )\n",
    "        \n",
    "    return rqa_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T22:36:58.698772Z",
     "start_time": "2021-03-30T22:36:58.685806Z"
    }
   },
   "outputs": [],
   "source": [
    "# Teste da classe\n",
    "janelas_treino = Janelas(\n",
    "    base=redd,\n",
    "    id_residencia=3,\n",
    "    inicio_intervalo='2011-04-16',\n",
    "    fim_intervalo='2011-05-16',\n",
    "    debug = False\n",
    ")\n",
    "\n",
    "janelas_teste = Janelas(\n",
    "    base=redd,\n",
    "    id_residencia=3,\n",
    "    inicio_intervalo='2011-05-17',\n",
    "    fim_intervalo='2011-05-30',\n",
    "    debug = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T21:48:48.132092Z",
     "start_time": "2021-03-30T21:01:35.449713Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# CALCULANDO RQA (BASE TREINO)...\n",
      "\n",
      "* Aparelho DISH_WASHER - 9:\n",
      "\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "   - Carregando dados (taxa=2, janela=720)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 583 amostras (97.5%)\n",
      "      - Classe `1`: 15 amostras (2.5%)\n",
      "\n",
      "* Calculando RQA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305dd89c1dde49d6a52029e50b8b74a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/598 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Aparelho FRIDGE - 7:\n",
      "\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "   - Carregando dados (taxa=2, janela=1080)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `1`: 398 amostras (99.7%)\n",
      "      - Classe `0`: 1 amostras (0.3%)\n",
      "\n",
      "* Calculando RQA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61954ea32764f7bb048bf7aea417618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/399 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Aparelho MICROWAVE - 16:\n",
      "\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "   - Carregando dados (taxa=2, janela=900)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 452 amostras (94.8%)\n",
      "      - Classe `1`: 25 amostras (5.2%)\n",
      "\n",
      "* Calculando RQA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ca918d2b2c4b28bdbff5a7dc130997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/477 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Aparelho WASHER_DRYER - 13:\n",
      "\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "   - Carregando dados (taxa=2, janela=60)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 6912 amostras (97.4%)\n",
      "      - Classe `1`: 187 amostras (2.6%)\n",
      "\n",
      "* Calculando RQA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f0eb53b9d54b1f9cc83446a8778b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   - Carregando dados (taxa=2, janela=60)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 6817 amostras (96.0%)\n",
      "      - Classe `1`: 282 amostras (4.0%)\n",
      "\n",
      "* Calculando RQA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0741f28a87474cb3a711c01eed7827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Aparelho WASHER_DRYER - 14:\n",
      "\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "   - Carregando dados (taxa=3, janela=360)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 766 amostras (96.2%)\n",
      "      - Classe `1`: 30 amostras (3.8%)\n",
      "\n",
      "* Calculando RQA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc9bb5340ac4ae89bb384bfad279377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/796 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   - Carregando dados (taxa=3, janela=360)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 758 amostras (95.2%)\n",
      "      - Classe `1`: 38 amostras (4.8%)\n",
      "\n",
      "* Calculando RQA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6edd2390e11a4baeb8b0a3c34bf793fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/796 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rqa = []\n",
    "\n",
    "janelas = janelas_treino#Janelas(**PARAMETROS_DATASET)\n",
    "\n",
    "print(\"# CALCULANDO RQA (BASE TREINO)...\\n\")\n",
    "\n",
    "for rotulo_aparelho in df_melhores_taxas_janelas.loc[\n",
    "    df_melhores_taxas_janelas[\"carga\"].isin(\n",
    "        ['dish_washer - 9','fridge - 7','microwave - 16','washer_dryer - 13',\n",
    "         'washer_dryer - 14']),\n",
    "    : ][\"carga\"].values:\n",
    "    \n",
    "    print(f\"* Aparelho {rotulo_aparelho.upper()}:\")\n",
    "    print()\n",
    "    \n",
    "    # Informacoes da carga selecionada\n",
    "    CARGA = rotulo_aparelho.split(\" - \")[0]\n",
    "    #INSTANCIA = int(rotulo_aparelho.split(\" - \")[1])\n",
    "\n",
    "    config_aparelho = df_melhores_taxas_janelas[\n",
    "        df_melhores_taxas_janelas[\"carga\"]==rotulo_aparelho\n",
    "    ].to_dict(\"records\")[0]\n",
    "    TAXA = config_aparelho[\"taxa_amostragem\"]\n",
    "    TAMANHO_JANELA = config_aparelho[\"janela\"]\n",
    "    CONFIG_RP_APARELHO = PARAMETROS_RP\n",
    "    \n",
    "    # Percorrer instancias do aparelho na residencia\n",
    "    for INSTANCIA in instancia_aparelho_residencia(CARGA, RESIDENCIA, base = redd):\n",
    "        \n",
    "        # Extrair series divididas em janelas para cada medidor\n",
    "        print(\"   - Carregando dados (taxa={:.0f}, janela={:.0f})...\".format(\n",
    "            TAXA, TAMANHO_JANELA\n",
    "        ))\n",
    "        X, y = carregar_dados_aparelho(\n",
    "            janelas=janelas,\n",
    "            instancia=INSTANCIA,\n",
    "            aparelho=CARGA,\n",
    "            tamanho_janela=TAMANHO_JANELA,\n",
    "            taxa=TAXA,\n",
    "            eliminar_janelas_vazias=True\n",
    "        )\n",
    "        print()\n",
    "        \n",
    "        print(\"   - Detalhes da amostragem (lotes):\")\n",
    "        print(\"   ---\")\n",
    "        for item in Counter(y).items():\n",
    "            print(f\"      - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y)*100,1)}%)\" )\n",
    "        print()\n",
    "        \n",
    "        print(\"* Calculando RQA...\")\n",
    "        rqa.extend( calcular_rqa_amostras(X, y, rotulo_aparelho) )\n",
    "        print()\n",
    "\n",
    "        # Consolidando resultados RQA dataframe...\n",
    "df_rqa = pd.DataFrame(\n",
    "    data = np.nan_to_num(rqa),\n",
    "    columns = [\n",
    "        \"Appliance\", \"State\",\n",
    "        \"Minimum diagonal line length (L_min)\",\n",
    "        \"Minimum vertical line length (V_min)\",\n",
    "        \"Minimum white vertical line length (W_min)\",\n",
    "        \"Recurrence rate (RR)\",\n",
    "        \"Determinism (DET)\",\n",
    "        \"Average diagonal line length (L)\",\n",
    "        \"Longest diagonal line length (L_max)\",\n",
    "        \"Divergence (DIV)\",\n",
    "        \"Entropy diagonal lines (L_entr)\",\n",
    "        \"Laminarity (LAM)\",\n",
    "        \"Trapping time (TT)\",\n",
    "        \"Longest vertical line length (V_max)\",\n",
    "        \"Entropy vertical lines (V_entr)\",\n",
    "        \"Average white vertical line length (W)\",\n",
    "        \"Longest white vertical line length (W_max)\",\n",
    "        \"Longest white vertical line length inverse (W_div)\",\n",
    "        \"Entropy white vertical lines (W_entr)\",\n",
    "        \"Ratio determinism / recurrence rate (DET/RR)\",\n",
    "        \"Ratio laminarity / determinism (LAM/DET)\"\n",
    "    ]\n",
    ")\n",
    "# Incluindo rótulo\n",
    "#df_rqa[\"Y\"] = y\n",
    "\n",
    "\n",
    "# a = input(\"Deseja persistir os dados? [S]im ou [N]ão: \")\n",
    "# if str(a.upper()) == \"S\":\n",
    "df_rqa.to_excel( os.path.join(caminho_dados_notebook, \"df_rqa_treino.xlsx\"), index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T23:06:49.630922Z",
     "start_time": "2021-03-30T22:37:47.758642Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# CALCULANDO RQA (BASE TESTE)...\n",
      "\n",
      "* Aparelho DISH_WASHER - 9:\n",
      "\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "   - Carregando dados (taxa=2, janela=720)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 395 amostras (96.8%)\n",
      "      - Classe `1`: 13 amostras (3.2%)\n",
      "\n",
      "* Calculando RQA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cad4c6a3b4c49b999056c6b5f267865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Aparelho FRIDGE - 7:\n",
      "\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "   - Carregando dados (taxa=2, janela=1080)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `1`: 269 amostras (98.2%)\n",
      "      - Classe `0`: 5 amostras (1.8%)\n",
      "\n",
      "* Calculando RQA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284c460263624d1e8ee15756cfe687e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Aparelho MICROWAVE - 16:\n",
      "\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "   - Carregando dados (taxa=2, janela=900)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 306 amostras (93.9%)\n",
      "      - Classe `1`: 20 amostras (6.1%)\n",
      "\n",
      "* Calculando RQA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243b3e3a3c8a49ffbd7528556cb8d324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Aparelho WASHER_DRYER - 13:\n",
      "\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "   - Carregando dados (taxa=2, janela=60)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 4643 amostras (96.0%)\n",
      "      - Classe `1`: 192 amostras (4.0%)\n",
      "\n",
      "* Calculando RQA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38d1471e23a4c84a9e893f881c75ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4835 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   - Carregando dados (taxa=2, janela=60)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 4582 amostras (94.8%)\n",
      "      - Classe `1`: 253 amostras (5.2%)\n",
      "\n",
      "* Calculando RQA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4f1e84bff049b185f4588fd6b35c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4835 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Aparelho WASHER_DRYER - 14:\n",
      "\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "   - Carregando dados (taxa=3, janela=360)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 514 amostras (94.8%)\n",
      "      - Classe `1`: 28 amostras (5.2%)\n",
      "\n",
      "* Calculando RQA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44d75051bc94e4da62aad820e16dab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   - Carregando dados (taxa=3, janela=360)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 508 amostras (93.7%)\n",
      "      - Classe `1`: 34 amostras (6.3%)\n",
      "\n",
      "* Calculando RQA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d259fae38e4cbea81a39c3e5d7340b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rqa = []\n",
    "\n",
    "janelas = janelas_teste\n",
    "\n",
    "print(\"# CALCULANDO RQA (BASE TESTE)...\\n\")\n",
    "\n",
    "for rotulo_aparelho in df_melhores_taxas_janelas.loc[\n",
    "    df_melhores_taxas_janelas[\"carga\"].isin(\n",
    "        ['dish_washer - 9','fridge - 7','microwave - 16','washer_dryer - 13',\n",
    "         'washer_dryer - 14']),\n",
    "    : ][\"carga\"].values:\n",
    "    \n",
    "    print(f\"* Aparelho {rotulo_aparelho.upper()}:\")\n",
    "    print()\n",
    "    \n",
    "    # Informacoes da carga selecionada\n",
    "    CARGA = rotulo_aparelho.split(\" - \")[0]\n",
    "    #INSTANCIA = int(rotulo_aparelho.split(\" - \")[1])\n",
    "\n",
    "    config_aparelho = df_melhores_taxas_janelas[\n",
    "        df_melhores_taxas_janelas[\"carga\"]==rotulo_aparelho\n",
    "    ].to_dict(\"records\")[0]\n",
    "    TAXA = config_aparelho[\"taxa_amostragem\"]\n",
    "    TAMANHO_JANELA = config_aparelho[\"janela\"]\n",
    "    CONFIG_RP_APARELHO = PARAMETROS_RP\n",
    "    \n",
    "    # Percorrer instancias do aparelho na residencia\n",
    "    for INSTANCIA in instancia_aparelho_residencia(CARGA, RESIDENCIA, base = redd):\n",
    "        \n",
    "        # Extrair series divididas em janelas para cada medidor\n",
    "        print(\"   - Carregando dados (taxa={:.0f}, janela={:.0f})...\".format(\n",
    "            TAXA, TAMANHO_JANELA\n",
    "        ))\n",
    "        X, y = carregar_dados_aparelho(\n",
    "            janelas=janelas,\n",
    "            instancia=INSTANCIA,\n",
    "            aparelho=CARGA,\n",
    "            tamanho_janela=TAMANHO_JANELA,\n",
    "            taxa=TAXA,\n",
    "            eliminar_janelas_vazias=True\n",
    "        )\n",
    "        print()\n",
    "        \n",
    "        print(\"   - Detalhes da amostragem (lotes):\")\n",
    "        print(\"   ---\")\n",
    "        for item in Counter(y).items():\n",
    "            print(f\"      - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y)*100,1)}%)\" )\n",
    "        print()\n",
    "        \n",
    "        print(\"* Calculando RQA...\")\n",
    "        rqa.extend( calcular_rqa_amostras(X, y, rotulo_aparelho) )\n",
    "        print()\n",
    "\n",
    "        # Consolidando resultados RQA dataframe...\n",
    "df_rqa = pd.DataFrame(\n",
    "    data = np.nan_to_num(rqa),\n",
    "    columns = [\n",
    "        \"Appliance\", \"State\",\n",
    "        \"Minimum diagonal line length (L_min)\",\n",
    "        \"Minimum vertical line length (V_min)\",\n",
    "        \"Minimum white vertical line length (W_min)\",\n",
    "        \"Recurrence rate (RR)\",\n",
    "        \"Determinism (DET)\",\n",
    "        \"Average diagonal line length (L)\",\n",
    "        \"Longest diagonal line length (L_max)\",\n",
    "        \"Divergence (DIV)\",\n",
    "        \"Entropy diagonal lines (L_entr)\",\n",
    "        \"Laminarity (LAM)\",\n",
    "        \"Trapping time (TT)\",\n",
    "        \"Longest vertical line length (V_max)\",\n",
    "        \"Entropy vertical lines (V_entr)\",\n",
    "        \"Average white vertical line length (W)\",\n",
    "        \"Longest white vertical line length (W_max)\",\n",
    "        \"Longest white vertical line length inverse (W_div)\",\n",
    "        \"Entropy white vertical lines (W_entr)\",\n",
    "        \"Ratio determinism / recurrence rate (DET/RR)\",\n",
    "        \"Ratio laminarity / determinism (LAM/DET)\"\n",
    "    ]\n",
    ")\n",
    "# Incluindo rótulo\n",
    "#df_rqa[\"Y\"] = y\n",
    "\n",
    "\n",
    "# a = input(\"Deseja persistir os dados? [S]im ou [N]ão: \")\n",
    "# if str(a.upper()) == \"S\":\n",
    "df_rqa.to_excel( os.path.join(caminho_dados_notebook, \"df_rqa_teste.xlsx\"), index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T23:06:49.645926Z",
     "start_time": "2021-03-30T23:06:49.632923Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "\n",
    "resultados = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T23:06:57.695473Z",
     "start_time": "2021-03-30T23:06:49.648881Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rqa_treino = pd.read_excel( os.path.join(caminho_dados_notebook, \"df_rqa_treino.xlsx\"), index=False, engine='openpyxl')\n",
    "df_rqa_teste = pd.read_excel( os.path.join(caminho_dados_notebook, \"df_rqa_teste.xlsx\"), index=False, engine='openpyxl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T23:06:57.711418Z",
     "start_time": "2021-03-30T23:06:57.697410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17264, 21)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rqa_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T23:06:57.727329Z",
     "start_time": "2021-03-30T23:06:57.713367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11762, 21)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rqa_teste.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T23:12:05.458165Z",
     "start_time": "2021-03-30T23:11:57.574284Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Appliance `dish_washer - 9`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       583\n",
      "           1       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.97       598\n",
      "   macro avg       0.49      0.50      0.49       598\n",
      "weighted avg       0.95      0.97      0.96       598\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[583   0]\n",
      " [ 15   0]]\n",
      "\n",
      "* Appliance `fridge - 7`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       359\n",
      "\n",
      "    accuracy                           1.00       359\n",
      "   macro avg       1.00      1.00      1.00       359\n",
      "weighted avg       1.00      1.00      1.00       359\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[359]]\n",
      "\n",
      "* Appliance `microwave - 16`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       452\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.95       477\n",
      "   macro avg       0.47      0.50      0.49       477\n",
      "weighted avg       0.90      0.95      0.92       477\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[452   0]\n",
      " [ 25   0]]\n",
      "\n",
      "* Appliance `washer_dryer - 13`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     13729\n",
      "           1       0.00      0.00      0.00       469\n",
      "\n",
      "    accuracy                           0.97     14198\n",
      "   macro avg       0.48      0.50      0.49     14198\n",
      "weighted avg       0.94      0.97      0.95     14198\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[13729     0]\n",
      " [  469     0]]\n",
      "\n",
      "* Appliance `washer_dryer - 14`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1524\n",
      "           1       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.96      1592\n",
      "   macro avg       0.48      0.50      0.49      1592\n",
      "weighted avg       0.92      0.96      0.94      1592\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[1524    0]\n",
      " [  68    0]]\n",
      "\n",
      "############################## FINAL MODEL RESULTS ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dish_washer - 9</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.968137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.974944</td>\n",
       "      <td>0.008725</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.493648</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.495798</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">fridge - 7</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.981752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">microwave - 16</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.938650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.938650</td>\n",
       "      <td>0.938650</td>\n",
       "      <td>0.484177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.484177</td>\n",
       "      <td>0.484177</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.947651</td>\n",
       "      <td>0.010705</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.486547</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">washer_dryer - 13</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.953981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953981</td>\n",
       "      <td>0.953981</td>\n",
       "      <td>0.488224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488224</td>\n",
       "      <td>0.488224</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.966967</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.967583</td>\n",
       "      <td>0.966878</td>\n",
       "      <td>0.491603</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.491762</td>\n",
       "      <td>0.491580</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">washer_dryer - 14</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.942804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.942804</td>\n",
       "      <td>0.942804</td>\n",
       "      <td>0.485280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.485280</td>\n",
       "      <td>0.485280</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.957288</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.489088</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.490385</td>\n",
       "      <td>0.488746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               acc                                      f1  \\\n",
       "                              mean       std       max       min      mean   \n",
       "appliance         base                                                       \n",
       "dish_washer - 9   teste   0.968137       NaN  0.968137  0.968137  0.491905   \n",
       "                  treino  0.974944  0.008725  0.983333  0.966667  0.493648   \n",
       "fridge - 7        teste   0.981752       NaN  0.981752  0.981752  0.495396   \n",
       "                  treino  1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "microwave - 16    teste   0.938650       NaN  0.938650  0.938650  0.484177   \n",
       "                  treino  0.947651  0.010705  0.958333  0.937500  0.486547   \n",
       "washer_dryer - 13 teste   0.953981       NaN  0.953981  0.953981  0.488224   \n",
       "                  treino  0.966967  0.000216  0.967583  0.966878  0.491603   \n",
       "washer_dryer - 14 teste   0.942804       NaN  0.942804  0.942804  0.485280   \n",
       "                  treino  0.957288  0.002625  0.962264  0.955975  0.489088   \n",
       "\n",
       "                                                        auc                 \n",
       "                               std       max       min mean  std  max  min  \n",
       "appliance         base                                                      \n",
       "dish_washer - 9   teste        NaN  0.491905  0.491905  0.5  NaN  0.5  0.5  \n",
       "                  treino  0.002237  0.495798  0.491525  0.5  0.0  0.5  0.5  \n",
       "fridge - 7        teste        NaN  0.495396  0.495396  0.5  NaN  0.5  0.5  \n",
       "                  treino  0.000000  1.000000  1.000000  0.5  0.0  0.5  0.5  \n",
       "microwave - 16    teste        NaN  0.484177  0.484177  0.5  NaN  0.5  0.5  \n",
       "                  treino  0.002822  0.489362  0.483871  0.5  0.0  0.5  0.5  \n",
       "washer_dryer - 13 teste        NaN  0.488224  0.488224  0.5  NaN  0.5  0.5  \n",
       "                  treino  0.000056  0.491762  0.491580  0.5  0.0  0.5  0.5  \n",
       "washer_dryer - 14 teste        NaN  0.485280  0.485280  0.5  NaN  0.5  0.5  \n",
       "                  treino  0.000684  0.490385  0.488746  0.5  0.0  0.5  0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \"base\": []\n",
    "}\n",
    "\n",
    "for a in df_rqa_treino[\"Appliance\"].unique():\n",
    "    \n",
    "    print(f\"* Appliance `{a}`...\\n\")\n",
    "    \n",
    "    # Base de treino\n",
    "    df_treino = df_rqa_treino[df_rqa_treino[\"Appliance\"]==a]\n",
    "    X = np.nan_to_num(df_treino[[\"Recurrence rate (RR)\",\"Determinism (DET)\"]].values)\n",
    "    y = df_treino[\"State\"].values\n",
    "    \n",
    "    y_true, y_pred  = [], []\n",
    "    \n",
    "    \n",
    "    print(\"   - Evaluation model (CV - 10 folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in enumerate(skf.split(X, y)):\n",
    "\n",
    "        # Preparando lotes\n",
    "        X_treino, X_teste = X[idx_treino], X[idx_teste]\n",
    "        y_treino, y_teste = y[idx_treino], y[idx_teste]\n",
    "        \n",
    "        if len(set(y_treino))>1:\n",
    "        \n",
    "            # Treinando modelo\n",
    "            modelo = SVC(kernel='rbf', random_state=SEED)\n",
    "            modelo.fit(X_treino, y_treino)\n",
    "\n",
    "            # Prevendo conjunto de teste\n",
    "            y_hat = modelo.predict(X_teste)\n",
    "\n",
    "            # Incrementando resultados\n",
    "            resultados_modelo[\"appliance\"].append(a)\n",
    "            resultados_modelo[\"fold\"].append(it+1)\n",
    "            resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "            resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "            resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "            resultados_modelo[\"base\"].append(\"treino\")\n",
    "\n",
    "            # Extendendo rotulos (analise global)\n",
    "            y_true.extend(y_teste)\n",
    "            y_pred.extend(y_hat)\n",
    "        \n",
    "    # Base de teste\n",
    "    df_teste = df_rqa_teste[df_rqa_teste[\"Appliance\"]==a]\n",
    "    X_teste = np.nan_to_num(df_teste[[\"Recurrence rate (RR)\",\"Determinism (DET)\"]].values)\n",
    "    y_teste = df_teste[\"State\"].values\n",
    "    \n",
    "    # Treinando/avaliando modelo\n",
    "    modelo = SVC(kernel='rbf', random_state=SEED)\n",
    "    modelo.fit(X, y)\n",
    "    y_hat = modelo.predict(X_teste)\n",
    "    \n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(a)\n",
    "    resultados_modelo[\"fold\"].append(it+1)\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"teste\")\n",
    "\n",
    "    print()\n",
    "    print(\"   - Final Results:\")\n",
    "    print(\"   ---\")\n",
    "    print()\n",
    "\n",
    "    print(\"      -> Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"      -> Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "# Consolidating DataFrame\n",
    "df_resultados_svm = pd.DataFrame(resultados_modelo)\n",
    "df_resultados_svm.to_excel(os.path.join(caminho_dados_notebook, \"df_resultados_svm.xlsx\"))\n",
    "    \n",
    "print(\"############################## FINAL MODEL RESULTS ##############################\")\n",
    "display(df_resultados_svm.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T19:59:41.720698Z",
     "start_time": "2020-08-31T19:59:41.680673Z"
    }
   },
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T23:12:58.952846Z",
     "start_time": "2021-03-30T23:12:58.943843Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# resultados_modelo = {\n",
    "#     \"appliance\": [], \"fold\": [],\n",
    "#     \"acc\": [], \"f1\": [], \"auc\": []\n",
    "# }\n",
    "\n",
    "# for a in df_rqa[\"Appliance\"].unique():\n",
    "    \n",
    "#     print(f\"* Appliance `{a}`...\\n\")\n",
    "    \n",
    "#     df_ = df_rqa[df_rqa[\"Appliance\"]==a]\n",
    "#     X = np.nan_to_num(df_[[\"Recurrence rate (RR)\",\"Determinism (DET)\"]].values)\n",
    "#     y = df_[\"State\"].values\n",
    "    \n",
    "#     y_true, y_pred  = [], []\n",
    "    \n",
    "    \n",
    "#     print(\"   - Evaluation model (CV - 10 folds)...\\n\")\n",
    "#     for it, (idx_treino, idx_teste) in enumerate(skf.split(X, y)):\n",
    "\n",
    "#         # Preparando lotes\n",
    "#         X_treino, X_teste = X[idx_treino], X[idx_teste]\n",
    "#         y_treino, y_teste = y[idx_treino], y[idx_teste]\n",
    "        \n",
    "#         # Treinando modelo\n",
    "#         modelo = XGBClassifier(random_state=SEED, n_jobs=4)\n",
    "#         modelo.fit(X_treino, y_treino)\n",
    "        \n",
    "#         # Prevendo conjunto de teste\n",
    "#         y_hat = modelo.predict(X_teste)\n",
    "\n",
    "#         # Incrementando resultados\n",
    "#         resultados_modelo[\"appliance\"].append(a)\n",
    "#         resultados_modelo[\"fold\"].append(it+1)\n",
    "#         resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "#         resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "#         resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "        \n",
    "#         # Extendendo rotulos (analise global)\n",
    "#         y_true.extend(y_teste)\n",
    "#         y_pred.extend(y_hat)\n",
    "        \n",
    "#     print()\n",
    "#     print(\"   - Final Results:\")\n",
    "#     print(\"   ---\")\n",
    "#     print()\n",
    "\n",
    "#     print(\"      -> Classification Report:\")\n",
    "#     print()\n",
    "#     print(classification_report(y_true, y_pred))\n",
    "#     print(\"      -> Confusion Matrix:\")\n",
    "#     print()\n",
    "#     print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "#     print()\n",
    "    \n",
    "# # Consolidating DataFrame\n",
    "# df_resultados_xgboost = pd.DataFrame(resultados_modelo)\n",
    "# df_resultados_xgboost.to_excel(os.path.join(caminho_dados_notebook, \"df_resultados_xgboost.xlsx\"))\n",
    "\n",
    "# print(\"############################## FINAL MODEL RESULTS ##############################\")\n",
    "# display(df_resultados_xgboost.groupby(\"appliance\").agg({\n",
    "#     \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "#     \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "#     \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "# }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T23:14:08.881676Z",
     "start_time": "2021-03-30T23:14:03.278682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Appliance `dish_washer - 9`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "[20:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       583\n",
      "           1       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.97       598\n",
      "   macro avg       0.49      0.50      0.49       598\n",
      "weighted avg       0.95      0.97      0.96       598\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[581   2]\n",
      " [ 15   0]]\n",
      "\n",
      "* Appliance `fridge - 7`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "[20:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       359\n",
      "\n",
      "    accuracy                           1.00       359\n",
      "   macro avg       1.00      1.00      1.00       359\n",
      "weighted avg       1.00      1.00      1.00       359\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[359]]\n",
      "\n",
      "* Appliance `microwave - 16`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "[20:14:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:14:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       452\n",
      "           1       0.23      0.12      0.16        25\n",
      "\n",
      "    accuracy                           0.93       477\n",
      "   macro avg       0.59      0.55      0.56       477\n",
      "weighted avg       0.91      0.93      0.92       477\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[442  10]\n",
      " [ 22   3]]\n",
      "\n",
      "* Appliance `washer_dryer - 13`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "[20:14:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     13729\n",
      "           1       0.56      0.08      0.14       469\n",
      "\n",
      "    accuracy                           0.97     14198\n",
      "   macro avg       0.77      0.54      0.56     14198\n",
      "weighted avg       0.96      0.97      0.96     14198\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[13701    28]\n",
      " [  433    36]]\n",
      "\n",
      "* Appliance `washer_dryer - 14`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "[20:14:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:14:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:14:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1524\n",
      "           1       0.85      0.76      0.81        68\n",
      "\n",
      "    accuracy                           0.98      1592\n",
      "   macro avg       0.92      0.88      0.90      1592\n",
      "weighted avg       0.98      0.98      0.98      1592\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[1515    9]\n",
      " [  16   52]]\n",
      "\n",
      "############################## FINAL MODEL RESULTS ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dish_washer - 9</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.965686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.965686</td>\n",
       "      <td>0.965686</td>\n",
       "      <td>0.553750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.553750</td>\n",
       "      <td>0.553750</td>\n",
       "      <td>0.535930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.535930</td>\n",
       "      <td>0.535930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.971582</td>\n",
       "      <td>0.011246</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.492778</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.495798</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.498276</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.491379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">fridge - 7</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.981752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">microwave - 16</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.932515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.932515</td>\n",
       "      <td>0.932515</td>\n",
       "      <td>0.615648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.615648</td>\n",
       "      <td>0.615648</td>\n",
       "      <td>0.590196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590196</td>\n",
       "      <td>0.590196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.932934</td>\n",
       "      <td>0.027670</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.555076</td>\n",
       "      <td>0.129081</td>\n",
       "      <td>0.827839</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>0.555580</td>\n",
       "      <td>0.106782</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.477778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">washer_dryer - 13</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.955222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955222</td>\n",
       "      <td>0.955222</td>\n",
       "      <td>0.572949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.572949</td>\n",
       "      <td>0.572949</td>\n",
       "      <td>0.547704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.547704</td>\n",
       "      <td>0.547704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.967531</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>0.969718</td>\n",
       "      <td>0.966173</td>\n",
       "      <td>0.558220</td>\n",
       "      <td>0.026880</td>\n",
       "      <td>0.615082</td>\n",
       "      <td>0.512596</td>\n",
       "      <td>0.537371</td>\n",
       "      <td>0.016528</td>\n",
       "      <td>0.573376</td>\n",
       "      <td>0.510638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">washer_dryer - 14</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.950185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.950185</td>\n",
       "      <td>0.950185</td>\n",
       "      <td>0.687007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687007</td>\n",
       "      <td>0.687007</td>\n",
       "      <td>0.640269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640269</td>\n",
       "      <td>0.640269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.984292</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.899000</td>\n",
       "      <td>0.052945</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.825083</td>\n",
       "      <td>0.879189</td>\n",
       "      <td>0.061724</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.782425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               acc                                      f1  \\\n",
       "                              mean       std       max       min      mean   \n",
       "appliance         base                                                       \n",
       "dish_washer - 9   teste   0.965686       NaN  0.965686  0.965686  0.553750   \n",
       "                  treino  0.971582  0.011246  0.983333  0.950000  0.492778   \n",
       "fridge - 7        teste   0.981752       NaN  0.981752  0.981752  0.495396   \n",
       "                  treino  1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "microwave - 16    teste   0.932515       NaN  0.932515  0.932515  0.615648   \n",
       "                  treino  0.932934  0.027670  0.978723  0.893617  0.555076   \n",
       "washer_dryer - 13 teste   0.955222       NaN  0.955222  0.955222  0.572949   \n",
       "                  treino  0.967531  0.000969  0.969718  0.966173  0.558220   \n",
       "washer_dryer - 14 teste   0.950185       NaN  0.950185  0.950185  0.687007   \n",
       "                  treino  0.984292  0.008999  1.000000  0.968553  0.899000   \n",
       "\n",
       "                                                             auc            \\\n",
       "                               std       max       min      mean       std   \n",
       "appliance         base                                                       \n",
       "dish_washer - 9   teste        NaN  0.553750  0.553750  0.535930       NaN   \n",
       "                  treino  0.002899  0.495798  0.487179  0.498276  0.003635   \n",
       "fridge - 7        teste        NaN  0.495396  0.495396  0.500000       NaN   \n",
       "                  treino  0.000000  1.000000  1.000000  0.500000  0.000000   \n",
       "microwave - 16    teste        NaN  0.615648  0.615648  0.590196       NaN   \n",
       "                  treino  0.129081  0.827839  0.472527  0.555580  0.106782   \n",
       "washer_dryer - 13 teste        NaN  0.572949  0.572949  0.547704       NaN   \n",
       "                  treino  0.026880  0.615082  0.512596  0.537371  0.016528   \n",
       "washer_dryer - 14 teste        NaN  0.687007  0.687007  0.640269       NaN   \n",
       "                  treino  0.052945  1.000000  0.825083  0.879189  0.061724   \n",
       "\n",
       "                                              \n",
       "                               max       min  \n",
       "appliance         base                        \n",
       "dish_washer - 9   teste   0.535930  0.535930  \n",
       "                  treino  0.500000  0.491379  \n",
       "fridge - 7        teste   0.500000  0.500000  \n",
       "                  treino  0.500000  0.500000  \n",
       "microwave - 16    teste   0.590196  0.590196  \n",
       "                  treino  0.750000  0.477778  \n",
       "washer_dryer - 13 teste   0.547704  0.547704  \n",
       "                  treino  0.573376  0.510638  \n",
       "washer_dryer - 14 teste   0.640269  0.640269  \n",
       "                  treino  1.000000  0.782425  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \"base\": []\n",
    "}\n",
    "\n",
    "for a in df_rqa_treino[\"Appliance\"].unique():\n",
    "    \n",
    "    print(f\"* Appliance `{a}`...\\n\")\n",
    "    \n",
    "    # Base de treino\n",
    "    df_treino = df_rqa_treino[df_rqa_treino[\"Appliance\"]==a]\n",
    "    X = np.nan_to_num(df_treino[[\"Recurrence rate (RR)\",\"Determinism (DET)\"]].values)\n",
    "    y = df_treino[\"State\"].values\n",
    "    \n",
    "    y_true, y_pred  = [], []\n",
    "    \n",
    "    \n",
    "    print(\"   - Evaluation model (CV - 10 folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in enumerate(skf.split(X, y)):\n",
    "\n",
    "        # Preparando lotes\n",
    "        X_treino, X_teste = X[idx_treino], X[idx_teste]\n",
    "        y_treino, y_teste = y[idx_treino], y[idx_teste]\n",
    "        \n",
    "        if len(set(y_treino))>1:\n",
    "        \n",
    "            # Treinando modelo\n",
    "            modelo = XGBClassifier(random_state=SEED, n_jobs=4)\n",
    "            modelo.fit(X_treino, y_treino)\n",
    "\n",
    "            # Prevendo conjunto de teste\n",
    "            y_hat = modelo.predict(X_teste)\n",
    "\n",
    "            # Incrementando resultados\n",
    "            resultados_modelo[\"appliance\"].append(a)\n",
    "            resultados_modelo[\"fold\"].append(it+1)\n",
    "            resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "            resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "            resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "            resultados_modelo[\"base\"].append(\"treino\")\n",
    "\n",
    "            # Extendendo rotulos (analise global)\n",
    "            y_true.extend(y_teste)\n",
    "            y_pred.extend(y_hat)\n",
    "        \n",
    "    # Base de teste\n",
    "    df_teste = df_rqa_teste[df_rqa_teste[\"Appliance\"]==a]\n",
    "    X_teste = np.nan_to_num(df_teste[[\"Recurrence rate (RR)\",\"Determinism (DET)\"]].values)\n",
    "    y_teste = df_teste[\"State\"].values\n",
    "    \n",
    "    # Treinando/avaliando modelo\n",
    "    modelo = XGBClassifier(random_state=SEED, n_jobs=4)\n",
    "    modelo.fit(X, y)\n",
    "    y_hat = modelo.predict(X_teste)\n",
    "    \n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(a)\n",
    "    resultados_modelo[\"fold\"].append(it+1)\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"teste\")\n",
    "\n",
    "    print()\n",
    "    print(\"   - Final Results:\")\n",
    "    print(\"   ---\")\n",
    "    print()\n",
    "\n",
    "    print(\"      -> Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"      -> Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "# Consolidating DataFrame\n",
    "df_resultados_svm = pd.DataFrame(resultados_modelo)\n",
    "df_resultados_svm.to_excel(os.path.join(caminho_dados_notebook, \"df_resultados_xgboost.xlsx\"))\n",
    "    \n",
    "print(\"############################## FINAL MODEL RESULTS ##############################\")\n",
    "display(df_resultados_svm.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T23:14:58.939676Z",
     "start_time": "2021-03-30T23:14:58.934689Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# resultados_modelo = {\n",
    "#     \"appliance\": [], \"fold\": [],\n",
    "#     \"acc\": [], \"f1\": [], \"auc\": []\n",
    "# }\n",
    "\n",
    "# for a in df_rqa[\"Appliance\"].unique():\n",
    "    \n",
    "#     print(f\"* Appliance `{a}`...\\n\")\n",
    "    \n",
    "#     df_ = df_rqa[df_rqa[\"Appliance\"]==a]\n",
    "#     X = np.nan_to_num(df_[[\"Recurrence rate (RR)\",\"Determinism (DET)\"]].values)\n",
    "#     y = df_[\"State\"].values\n",
    "    \n",
    "#     y_true, y_pred  = [], []\n",
    "    \n",
    "    \n",
    "#     print(\"   - Evaluation model (CV - 10 folds)...\\n\")\n",
    "#     for it, (idx_treino, idx_teste) in enumerate(skf.split(X, y)):\n",
    "\n",
    "#         # Preparando lotes\n",
    "#         X_treino, X_teste = X[idx_treino], X[idx_teste]\n",
    "#         y_treino, y_teste = y[idx_treino], y[idx_teste]\n",
    "        \n",
    "#         # Treinando modelo\n",
    "#         modelo = MLPClassifier(alpha=1e-3, hidden_layer_sizes=(10,), random_state=SEED)\n",
    "#         modelo.fit(X_treino, y_treino)\n",
    "        \n",
    "#         # Prevendo conjunto de teste\n",
    "#         y_hat = modelo.predict(X_teste)\n",
    "\n",
    "#         # Incrementando resultados\n",
    "#         resultados_modelo[\"appliance\"].append(a)\n",
    "#         resultados_modelo[\"fold\"].append(it+1)\n",
    "#         resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "#         resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "#         resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "        \n",
    "#         # Extendendo rotulos (analise global)\n",
    "#         y_true.extend(y_teste)\n",
    "#         y_pred.extend(y_hat)\n",
    "        \n",
    "#     print()\n",
    "#     print(\"   - Final Results:\")\n",
    "#     print(\"   ---\")\n",
    "#     print()\n",
    "\n",
    "#     print(\"      -> Classification Report:\")\n",
    "#     print()\n",
    "#     print(classification_report(y_true, y_pred))\n",
    "#     print(\"      -> Confusion Matrix:\")\n",
    "#     print()\n",
    "#     print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "#     print()\n",
    "    \n",
    "# # Consolidating DataFrame\n",
    "# df_resultados_mlp = pd.DataFrame(resultados_modelo)\n",
    "# df_resultados_mlp.to_excel(os.path.join(caminho_dados_notebook, \"df_resultados_mlp.xlsx\"))\n",
    "\n",
    "# print(\"############################## FINAL MODEL RESULTS ##############################\")\n",
    "# display(df_resultados_mlp.groupby(\"appliance\").agg({\n",
    "#     \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "#     \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "#     \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "# }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T23:16:17.802875Z",
     "start_time": "2021-03-30T23:15:44.221866Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Appliance `dish_washer - 9`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       583\n",
      "           1       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.97       598\n",
      "   macro avg       0.49      0.50      0.49       598\n",
      "weighted avg       0.95      0.97      0.96       598\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[583   0]\n",
      " [ 15   0]]\n",
      "\n",
      "* Appliance `fridge - 7`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       359\n",
      "\n",
      "    accuracy                           1.00       359\n",
      "   macro avg       1.00      1.00      1.00       359\n",
      "weighted avg       1.00      1.00      1.00       359\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[359]]\n",
      "\n",
      "* Appliance `microwave - 16`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       452\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.95       477\n",
      "   macro avg       0.47      0.50      0.49       477\n",
      "weighted avg       0.90      0.95      0.92       477\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[452   0]\n",
      " [ 25   0]]\n",
      "\n",
      "* Appliance `washer_dryer - 13`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     13729\n",
      "           1       0.00      0.00      0.00       469\n",
      "\n",
      "    accuracy                           0.97     14198\n",
      "   macro avg       0.48      0.50      0.49     14198\n",
      "weighted avg       0.94      0.97      0.95     14198\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[13729     0]\n",
      " [  469     0]]\n",
      "\n",
      "* Appliance `washer_dryer - 14`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1524\n",
      "           1       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.96      1592\n",
      "   macro avg       0.48      0.50      0.49      1592\n",
      "weighted avg       0.92      0.96      0.94      1592\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[1524    0]\n",
      " [  68    0]]\n",
      "\n",
      "############################## FINAL MODEL RESULTS ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dish_washer - 9</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.968137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.974944</td>\n",
       "      <td>0.008725</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.493648</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.495798</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">fridge - 7</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.981752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">microwave - 16</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.938650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.938650</td>\n",
       "      <td>0.938650</td>\n",
       "      <td>0.484177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.484177</td>\n",
       "      <td>0.484177</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.947651</td>\n",
       "      <td>0.010705</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.486547</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">washer_dryer - 13</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.953981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953981</td>\n",
       "      <td>0.953981</td>\n",
       "      <td>0.488224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488224</td>\n",
       "      <td>0.488224</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.966967</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.967583</td>\n",
       "      <td>0.966878</td>\n",
       "      <td>0.491603</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.491762</td>\n",
       "      <td>0.491580</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">washer_dryer - 14</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.942804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.942804</td>\n",
       "      <td>0.942804</td>\n",
       "      <td>0.485280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.485280</td>\n",
       "      <td>0.485280</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.957288</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.489088</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.490385</td>\n",
       "      <td>0.488746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               acc                                      f1  \\\n",
       "                              mean       std       max       min      mean   \n",
       "appliance         base                                                       \n",
       "dish_washer - 9   teste   0.968137       NaN  0.968137  0.968137  0.491905   \n",
       "                  treino  0.974944  0.008725  0.983333  0.966667  0.493648   \n",
       "fridge - 7        teste   0.981752       NaN  0.981752  0.981752  0.495396   \n",
       "                  treino  1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "microwave - 16    teste   0.938650       NaN  0.938650  0.938650  0.484177   \n",
       "                  treino  0.947651  0.010705  0.958333  0.937500  0.486547   \n",
       "washer_dryer - 13 teste   0.953981       NaN  0.953981  0.953981  0.488224   \n",
       "                  treino  0.966967  0.000216  0.967583  0.966878  0.491603   \n",
       "washer_dryer - 14 teste   0.942804       NaN  0.942804  0.942804  0.485280   \n",
       "                  treino  0.957288  0.002625  0.962264  0.955975  0.489088   \n",
       "\n",
       "                                                        auc                 \n",
       "                               std       max       min mean  std  max  min  \n",
       "appliance         base                                                      \n",
       "dish_washer - 9   teste        NaN  0.491905  0.491905  0.5  NaN  0.5  0.5  \n",
       "                  treino  0.002237  0.495798  0.491525  0.5  0.0  0.5  0.5  \n",
       "fridge - 7        teste        NaN  0.495396  0.495396  0.5  NaN  0.5  0.5  \n",
       "                  treino  0.000000  1.000000  1.000000  0.5  0.0  0.5  0.5  \n",
       "microwave - 16    teste        NaN  0.484177  0.484177  0.5  NaN  0.5  0.5  \n",
       "                  treino  0.002822  0.489362  0.483871  0.5  0.0  0.5  0.5  \n",
       "washer_dryer - 13 teste        NaN  0.488224  0.488224  0.5  NaN  0.5  0.5  \n",
       "                  treino  0.000056  0.491762  0.491580  0.5  0.0  0.5  0.5  \n",
       "washer_dryer - 14 teste        NaN  0.485280  0.485280  0.5  NaN  0.5  0.5  \n",
       "                  treino  0.000684  0.490385  0.488746  0.5  0.0  0.5  0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \"base\": []\n",
    "}\n",
    "\n",
    "for a in df_rqa_treino[\"Appliance\"].unique():\n",
    "    \n",
    "    print(f\"* Appliance `{a}`...\\n\")\n",
    "    \n",
    "    # Base de treino\n",
    "    df_treino = df_rqa_treino[df_rqa_treino[\"Appliance\"]==a]\n",
    "    X = np.nan_to_num(df_treino[[\"Recurrence rate (RR)\",\"Determinism (DET)\"]].values)\n",
    "    y = df_treino[\"State\"].values\n",
    "    \n",
    "    y_true, y_pred  = [], []\n",
    "    \n",
    "    \n",
    "    print(\"   - Evaluation model (CV - 10 folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in enumerate(skf.split(X, y)):\n",
    "\n",
    "        # Preparando lotes\n",
    "        X_treino, X_teste = X[idx_treino], X[idx_teste]\n",
    "        y_treino, y_teste = y[idx_treino], y[idx_teste]\n",
    "        \n",
    "        if len(set(y_treino))>1:\n",
    "        \n",
    "            # Treinando modelo\n",
    "            modelo = MLPClassifier(alpha=1e-3, hidden_layer_sizes=(10,), random_state=SEED)\n",
    "            modelo.fit(X_treino, y_treino)\n",
    "\n",
    "            # Prevendo conjunto de teste\n",
    "            y_hat = modelo.predict(X_teste)\n",
    "\n",
    "            # Incrementando resultados\n",
    "            resultados_modelo[\"appliance\"].append(a)\n",
    "            resultados_modelo[\"fold\"].append(it+1)\n",
    "            resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "            resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "            resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "            resultados_modelo[\"base\"].append(\"treino\")\n",
    "\n",
    "            # Extendendo rotulos (analise global)\n",
    "            y_true.extend(y_teste)\n",
    "            y_pred.extend(y_hat)\n",
    "        \n",
    "    # Base de teste\n",
    "    df_teste = df_rqa_teste[df_rqa_teste[\"Appliance\"]==a]\n",
    "    X_teste = np.nan_to_num(df_teste[[\"Recurrence rate (RR)\",\"Determinism (DET)\"]].values)\n",
    "    y_teste = df_teste[\"State\"].values\n",
    "    \n",
    "    # Treinando/avaliando modelo\n",
    "    modelo = MLPClassifier(alpha=1e-3, hidden_layer_sizes=(10,), random_state=SEED)\n",
    "    modelo.fit(X, y)\n",
    "    y_hat = modelo.predict(X_teste)\n",
    "    \n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(a)\n",
    "    resultados_modelo[\"fold\"].append(it+1)\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"teste\")\n",
    "\n",
    "    print()\n",
    "    print(\"   - Final Results:\")\n",
    "    print(\"   ---\")\n",
    "    print()\n",
    "\n",
    "    print(\"      -> Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"      -> Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "# Consolidating DataFrame\n",
    "df_resultados_svm = pd.DataFrame(resultados_modelo)\n",
    "df_resultados_svm.to_excel(os.path.join(caminho_dados_notebook, \"df_resultados_mlp.xlsx\"))\n",
    "    \n",
    "print(\"############################## FINAL MODEL RESULTS ##############################\")\n",
    "display(df_resultados_svm.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## ELM - Extreme Learning Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T23:19:21.047068Z",
     "start_time": "2021-03-30T23:19:21.013105Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'elm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-9d88119c815a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0melm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mELM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'elm'"
     ]
    }
   ],
   "source": [
    "from elm import ELM\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T01:41:36.720715Z",
     "start_time": "2021-03-30T01:41:36.688817Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Appliance `dish_washer - 9`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ELM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-d98ba8832a62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# Treinando modelo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mmodelo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mELM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhid_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mmodelo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_treino\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_treino\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ELM' is not defined"
     ]
    }
   ],
   "source": [
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": []\n",
    "}\n",
    "\n",
    "for a in df_rqa[\"Appliance\"].unique():\n",
    "    \n",
    "    print(f\"* Appliance `{a}`...\\n\")\n",
    "    \n",
    "    df_ = df_rqa[df_rqa[\"Appliance\"]==a]\n",
    "    X = df_[[\"Recurrence rate (RR)\",\"Determinism (DET)\"]].values\n",
    "    y = df_[\"State\"].values\n",
    "    \n",
    "    y_true, y_pred  = [], []\n",
    "    \n",
    "    \n",
    "    print(\"   - Evaluation model (CV - 10 folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in enumerate(skf.split(X, y)):\n",
    "\n",
    "        # Preparando lotes\n",
    "        X_treino, X_teste = X[idx_treino], X[idx_teste]\n",
    "        y_treino, y_teste = y[idx_treino], y[idx_teste]\n",
    "        \n",
    "        # Treinando modelo\n",
    "        modelo = ELM(hid_num=10)\n",
    "        modelo.fit(normalize(X_treino), y_treino)\n",
    "        \n",
    "        # Prevendo conjunto de teste\n",
    "        y_hat = modelo.predict(normalize(X_teste))\n",
    "        y_hat = (y_hat > 0.5).astype(int)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(a)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "        \n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true.extend(y_teste)\n",
    "        y_pred.extend(y_hat)\n",
    "        \n",
    "    print()\n",
    "    print(\"   - Final Results:\")\n",
    "    print(\"   ---\")\n",
    "    print()\n",
    "\n",
    "    print(\"      -> Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"      -> Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "# Consolidating DataFrame\n",
    "df_resultados_elm = pd.DataFrame(resultados_modelo)\n",
    "df_resultados_elm.to_excel(os.path.join(caminho_dados_notebook, \"df_resultados_elm.xlsx\"))\n",
    "\n",
    "print(\"############################## FINAL MODEL RESULTS ##############################\")\n",
    "display(df_resultados_elm.groupby(\"appliance\").agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise dos Resultados (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T23:20:39.318965Z",
     "start_time": "2021-03-30T23:20:37.047652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Análise por modelo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBOOST</th>\n",
       "      <td>treino</td>\n",
       "      <td>0.970681</td>\n",
       "      <td>0.026105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.694913</td>\n",
       "      <td>0.215395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>0.596003</td>\n",
       "      <td>0.156165</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.477778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBOOST</th>\n",
       "      <td>teste</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>0.018284</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.932515</td>\n",
       "      <td>0.584950</td>\n",
       "      <td>0.071581</td>\n",
       "      <td>0.687007</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.562820</td>\n",
       "      <td>0.053958</td>\n",
       "      <td>0.640269</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>treino</td>\n",
       "      <td>0.968745</td>\n",
       "      <td>0.018680</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.583854</td>\n",
       "      <td>0.199462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>treino</td>\n",
       "      <td>0.968745</td>\n",
       "      <td>0.018680</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.583854</td>\n",
       "      <td>0.199462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>teste</td>\n",
       "      <td>0.957065</td>\n",
       "      <td>0.017917</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.938650</td>\n",
       "      <td>0.488997</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.484177</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>teste</td>\n",
       "      <td>0.957065</td>\n",
       "      <td>0.017917</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.938650</td>\n",
       "      <td>0.488997</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.484177</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           base       acc                                      f1            \\\n",
       "                     mean       std       max       min      mean       std   \n",
       "model                                                                         \n",
       "XGBOOST  treino  0.970681  0.026105  1.000000  0.893617  0.694913  0.215395   \n",
       "XGBOOST   teste  0.957072  0.018284  0.981752  0.932515  0.584950  0.071581   \n",
       "MLP      treino  0.968745  0.018680  1.000000  0.937500  0.583854  0.199462   \n",
       "SVM      treino  0.968745  0.018680  1.000000  0.937500  0.583854  0.199462   \n",
       "MLP       teste  0.957065  0.017917  0.981752  0.938650  0.488997  0.004665   \n",
       "SVM       teste  0.957065  0.017917  0.981752  0.938650  0.488997  0.004665   \n",
       "\n",
       "                                  auc                                \n",
       "              max       min      mean       std       max       min  \n",
       "model                                                                \n",
       "XGBOOST  1.000000  0.472527  0.596003  0.156165  1.000000  0.477778  \n",
       "XGBOOST  0.687007  0.495396  0.562820  0.053958  0.640269  0.500000  \n",
       "MLP      1.000000  0.483871  0.500000  0.000000  0.500000  0.500000  \n",
       "SVM      1.000000  0.483871  0.500000  0.000000  0.500000  0.500000  \n",
       "MLP      0.495396  0.484177  0.500000  0.000000  0.500000  0.500000  \n",
       "SVM      0.495396  0.484177  0.500000  0.000000  0.500000  0.500000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Análise por aparelho/modelo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>model</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dish_washer - 9</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.968137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.974944</td>\n",
       "      <td>0.008725</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.493648</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.495798</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.968137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.974944</td>\n",
       "      <td>0.008725</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.493648</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.495798</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.965686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.965686</td>\n",
       "      <td>0.965686</td>\n",
       "      <td>0.553750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.553750</td>\n",
       "      <td>0.553750</td>\n",
       "      <td>0.535930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.535930</td>\n",
       "      <td>0.535930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.971582</td>\n",
       "      <td>0.011246</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.492778</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.495798</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.498276</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.491379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">fridge - 7</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.981752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.981752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.981752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">microwave - 16</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.938650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.938650</td>\n",
       "      <td>0.938650</td>\n",
       "      <td>0.484177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.484177</td>\n",
       "      <td>0.484177</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.947651</td>\n",
       "      <td>0.010705</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.486547</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.938650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.938650</td>\n",
       "      <td>0.938650</td>\n",
       "      <td>0.484177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.484177</td>\n",
       "      <td>0.484177</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.947651</td>\n",
       "      <td>0.010705</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.486547</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.932515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.932515</td>\n",
       "      <td>0.932515</td>\n",
       "      <td>0.615648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.615648</td>\n",
       "      <td>0.615648</td>\n",
       "      <td>0.590196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590196</td>\n",
       "      <td>0.590196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.932934</td>\n",
       "      <td>0.027670</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.555076</td>\n",
       "      <td>0.129081</td>\n",
       "      <td>0.827839</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>0.555580</td>\n",
       "      <td>0.106782</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.477778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">washer_dryer - 13</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.953981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953981</td>\n",
       "      <td>0.953981</td>\n",
       "      <td>0.488224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488224</td>\n",
       "      <td>0.488224</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.966967</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.967583</td>\n",
       "      <td>0.966878</td>\n",
       "      <td>0.491603</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.491762</td>\n",
       "      <td>0.491580</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.953981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953981</td>\n",
       "      <td>0.953981</td>\n",
       "      <td>0.488224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488224</td>\n",
       "      <td>0.488224</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.966967</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.967583</td>\n",
       "      <td>0.966878</td>\n",
       "      <td>0.491603</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.491762</td>\n",
       "      <td>0.491580</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.955222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955222</td>\n",
       "      <td>0.955222</td>\n",
       "      <td>0.572949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.572949</td>\n",
       "      <td>0.572949</td>\n",
       "      <td>0.547704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.547704</td>\n",
       "      <td>0.547704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.967531</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>0.969718</td>\n",
       "      <td>0.966173</td>\n",
       "      <td>0.558220</td>\n",
       "      <td>0.026880</td>\n",
       "      <td>0.615082</td>\n",
       "      <td>0.512596</td>\n",
       "      <td>0.537371</td>\n",
       "      <td>0.016528</td>\n",
       "      <td>0.573376</td>\n",
       "      <td>0.510638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">washer_dryer - 14</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.942804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.942804</td>\n",
       "      <td>0.942804</td>\n",
       "      <td>0.485280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.485280</td>\n",
       "      <td>0.485280</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.957288</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.489088</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.490385</td>\n",
       "      <td>0.488746</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.942804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.942804</td>\n",
       "      <td>0.942804</td>\n",
       "      <td>0.485280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.485280</td>\n",
       "      <td>0.485280</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.957288</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.489088</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.490385</td>\n",
       "      <td>0.488746</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.950185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.950185</td>\n",
       "      <td>0.950185</td>\n",
       "      <td>0.687007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687007</td>\n",
       "      <td>0.687007</td>\n",
       "      <td>0.640269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640269</td>\n",
       "      <td>0.640269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.984292</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968553</td>\n",
       "      <td>0.899000</td>\n",
       "      <td>0.052945</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.825083</td>\n",
       "      <td>0.879189</td>\n",
       "      <td>0.061724</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.782425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       acc                                \\\n",
       "                                      mean       std       max       min   \n",
       "appliance         model   base                                             \n",
       "dish_washer - 9   MLP     teste   0.968137       NaN  0.968137  0.968137   \n",
       "                          treino  0.974944  0.008725  0.983333  0.966667   \n",
       "                  SVM     teste   0.968137       NaN  0.968137  0.968137   \n",
       "                          treino  0.974944  0.008725  0.983333  0.966667   \n",
       "                  XGBOOST teste   0.965686       NaN  0.965686  0.965686   \n",
       "                          treino  0.971582  0.011246  0.983333  0.950000   \n",
       "fridge - 7        MLP     teste   0.981752       NaN  0.981752  0.981752   \n",
       "                          treino  1.000000  0.000000  1.000000  1.000000   \n",
       "                  SVM     teste   0.981752       NaN  0.981752  0.981752   \n",
       "                          treino  1.000000  0.000000  1.000000  1.000000   \n",
       "                  XGBOOST teste   0.981752       NaN  0.981752  0.981752   \n",
       "                          treino  1.000000  0.000000  1.000000  1.000000   \n",
       "microwave - 16    MLP     teste   0.938650       NaN  0.938650  0.938650   \n",
       "                          treino  0.947651  0.010705  0.958333  0.937500   \n",
       "                  SVM     teste   0.938650       NaN  0.938650  0.938650   \n",
       "                          treino  0.947651  0.010705  0.958333  0.937500   \n",
       "                  XGBOOST teste   0.932515       NaN  0.932515  0.932515   \n",
       "                          treino  0.932934  0.027670  0.978723  0.893617   \n",
       "washer_dryer - 13 MLP     teste   0.953981       NaN  0.953981  0.953981   \n",
       "                          treino  0.966967  0.000216  0.967583  0.966878   \n",
       "                  SVM     teste   0.953981       NaN  0.953981  0.953981   \n",
       "                          treino  0.966967  0.000216  0.967583  0.966878   \n",
       "                  XGBOOST teste   0.955222       NaN  0.955222  0.955222   \n",
       "                          treino  0.967531  0.000969  0.969718  0.966173   \n",
       "washer_dryer - 14 MLP     teste   0.942804       NaN  0.942804  0.942804   \n",
       "                          treino  0.957288  0.002625  0.962264  0.955975   \n",
       "                  SVM     teste   0.942804       NaN  0.942804  0.942804   \n",
       "                          treino  0.957288  0.002625  0.962264  0.955975   \n",
       "                  XGBOOST teste   0.950185       NaN  0.950185  0.950185   \n",
       "                          treino  0.984292  0.008999  1.000000  0.968553   \n",
       "\n",
       "                                        f1                                \\\n",
       "                                      mean       std       max       min   \n",
       "appliance         model   base                                             \n",
       "dish_washer - 9   MLP     teste   0.491905       NaN  0.491905  0.491905   \n",
       "                          treino  0.493648  0.002237  0.495798  0.491525   \n",
       "                  SVM     teste   0.491905       NaN  0.491905  0.491905   \n",
       "                          treino  0.493648  0.002237  0.495798  0.491525   \n",
       "                  XGBOOST teste   0.553750       NaN  0.553750  0.553750   \n",
       "                          treino  0.492778  0.002899  0.495798  0.487179   \n",
       "fridge - 7        MLP     teste   0.495396       NaN  0.495396  0.495396   \n",
       "                          treino  1.000000  0.000000  1.000000  1.000000   \n",
       "                  SVM     teste   0.495396       NaN  0.495396  0.495396   \n",
       "                          treino  1.000000  0.000000  1.000000  1.000000   \n",
       "                  XGBOOST teste   0.495396       NaN  0.495396  0.495396   \n",
       "                          treino  1.000000  0.000000  1.000000  1.000000   \n",
       "microwave - 16    MLP     teste   0.484177       NaN  0.484177  0.484177   \n",
       "                          treino  0.486547  0.002822  0.489362  0.483871   \n",
       "                  SVM     teste   0.484177       NaN  0.484177  0.484177   \n",
       "                          treino  0.486547  0.002822  0.489362  0.483871   \n",
       "                  XGBOOST teste   0.615648       NaN  0.615648  0.615648   \n",
       "                          treino  0.555076  0.129081  0.827839  0.472527   \n",
       "washer_dryer - 13 MLP     teste   0.488224       NaN  0.488224  0.488224   \n",
       "                          treino  0.491603  0.000056  0.491762  0.491580   \n",
       "                  SVM     teste   0.488224       NaN  0.488224  0.488224   \n",
       "                          treino  0.491603  0.000056  0.491762  0.491580   \n",
       "                  XGBOOST teste   0.572949       NaN  0.572949  0.572949   \n",
       "                          treino  0.558220  0.026880  0.615082  0.512596   \n",
       "washer_dryer - 14 MLP     teste   0.485280       NaN  0.485280  0.485280   \n",
       "                          treino  0.489088  0.000684  0.490385  0.488746   \n",
       "                  SVM     teste   0.485280       NaN  0.485280  0.485280   \n",
       "                          treino  0.489088  0.000684  0.490385  0.488746   \n",
       "                  XGBOOST teste   0.687007       NaN  0.687007  0.687007   \n",
       "                          treino  0.899000  0.052945  1.000000  0.825083   \n",
       "\n",
       "                                       auc                                \n",
       "                                      mean       std       max       min  \n",
       "appliance         model   base                                            \n",
       "dish_washer - 9   MLP     teste   0.500000       NaN  0.500000  0.500000  \n",
       "                          treino  0.500000  0.000000  0.500000  0.500000  \n",
       "                  SVM     teste   0.500000       NaN  0.500000  0.500000  \n",
       "                          treino  0.500000  0.000000  0.500000  0.500000  \n",
       "                  XGBOOST teste   0.535930       NaN  0.535930  0.535930  \n",
       "                          treino  0.498276  0.003635  0.500000  0.491379  \n",
       "fridge - 7        MLP     teste   0.500000       NaN  0.500000  0.500000  \n",
       "                          treino  0.500000  0.000000  0.500000  0.500000  \n",
       "                  SVM     teste   0.500000       NaN  0.500000  0.500000  \n",
       "                          treino  0.500000  0.000000  0.500000  0.500000  \n",
       "                  XGBOOST teste   0.500000       NaN  0.500000  0.500000  \n",
       "                          treino  0.500000  0.000000  0.500000  0.500000  \n",
       "microwave - 16    MLP     teste   0.500000       NaN  0.500000  0.500000  \n",
       "                          treino  0.500000  0.000000  0.500000  0.500000  \n",
       "                  SVM     teste   0.500000       NaN  0.500000  0.500000  \n",
       "                          treino  0.500000  0.000000  0.500000  0.500000  \n",
       "                  XGBOOST teste   0.590196       NaN  0.590196  0.590196  \n",
       "                          treino  0.555580  0.106782  0.750000  0.477778  \n",
       "washer_dryer - 13 MLP     teste   0.500000       NaN  0.500000  0.500000  \n",
       "                          treino  0.500000  0.000000  0.500000  0.500000  \n",
       "                  SVM     teste   0.500000       NaN  0.500000  0.500000  \n",
       "                          treino  0.500000  0.000000  0.500000  0.500000  \n",
       "                  XGBOOST teste   0.547704       NaN  0.547704  0.547704  \n",
       "                          treino  0.537371  0.016528  0.573376  0.510638  \n",
       "washer_dryer - 14 MLP     teste   0.500000       NaN  0.500000  0.500000  \n",
       "                          treino  0.500000  0.000000  0.500000  0.500000  \n",
       "                  SVM     teste   0.500000       NaN  0.500000  0.500000  \n",
       "                          treino  0.500000  0.000000  0.500000  0.500000  \n",
       "                  XGBOOST teste   0.640269       NaN  0.640269  0.640269  \n",
       "                          treino  0.879189  0.061724  1.000000  0.782425  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_resultados_svm = pd.read_excel(os.path.join(caminho_dados_notebook, \"df_resultados_svm.xlsx\"), engine='openpyxl')\n",
    "df_resultados_svm[\"model\"] = \"SVM\"\n",
    "\n",
    "df_resultados_xgboost = pd.read_excel(os.path.join(caminho_dados_notebook, \"df_resultados_xgboost.xlsx\"), engine='openpyxl')\n",
    "df_resultados_xgboost[\"model\"] = \"XGBOOST\"\n",
    "\n",
    "df_resultados_mlp = pd.read_excel(os.path.join(caminho_dados_notebook, \"df_resultados_mlp.xlsx\"), engine='openpyxl')\n",
    "df_resultados_mlp[\"model\"] = \"MLP\"\n",
    "\n",
    "# df_resultados_elm = pd.read_excel(os.path.join(caminho_dados_notebook, \"df_resultados_elm.xlsx\"))\n",
    "# df_resultados_elm[\"model\"] = \"ELM\"\n",
    "\n",
    "df_analise = pd.concat([\n",
    "    df_resultados_svm,\n",
    "    df_resultados_xgboost,\n",
    "    df_resultados_mlp, \n",
    "#     df_resultados_elm,  \n",
    "])\n",
    "\n",
    "print(\"* Análise por modelo:\")\n",
    "df_analise_modelo = df_analise.groupby([\"model\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"f1\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"auc\": [\"mean\",\"std\",\"max\",\"min\"]\n",
    "}).reset_index().sort_values(('f1','mean'), ascending=False).set_index(\"model\")\n",
    "display(df_analise_modelo)\n",
    "df_analise_modelo.to_excel(os.path.join(caminho_dados_notebook, \"df_analise_modelo.xlsx\"))\n",
    "\n",
    "print()\n",
    "print(\"* Análise por aparelho/modelo:\")\n",
    "df_analise_aparelho = df_analise.groupby([\"appliance\",\"model\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"f1\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"auc\": [\"mean\",\"std\",\"max\",\"min\"]\n",
    "})#.reset_index().sort_values(('f1','mean'), ascending=False).set_index([\"aparelho\",\"metodologia\"])\n",
    "display(df_analise_aparelho)\n",
    "df_analise_aparelho.to_excel(os.path.join(caminho_dados_notebook, \"df_analise_aparelho.xls\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Fim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T20:24:22.004680Z",
     "start_time": "2020-07-03T20:24:21.943155Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T20:24:36.458476Z",
     "start_time": "2020-07-03T20:24:36.138156Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diego Luiz Cavalca \n",
      "last updated: Fri Jul 03 2020 17:24:36 Hora oficial do Brasil \n",
      "\n",
      "CPython 3.6.7\n",
      "IPython 7.6.1\n",
      "\n",
      "compiler   : MSC v.1900 64 bit (AMD64)\n",
      "system     : Windows\n",
      "release    : 10\n",
      "machine    : AMD64\n",
      "processor  : Intel64 Family 6 Model 158 Stepping 9, GenuineIntel\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      "Git hash   : fe2077f45387300d020bc7d9c113451844efc83a\n"
     ]
    }
   ],
   "source": [
    "%watermark -a \"Diego Luiz Cavalca\" -u -n -t -z -v -m -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

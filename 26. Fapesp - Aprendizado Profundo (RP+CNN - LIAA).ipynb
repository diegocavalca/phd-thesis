{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Defesa - Dataset LIAA - Aprendizado Profundo em Imagens RP (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estruturação de pipeline baseado em aprendizado raso utilizando atributos de alta frequência.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T17:00:00.198228Z",
     "start_time": "2021-05-02T16:59:56.833044Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "from pretty_confusion_matrix import *\n",
    "\n",
    "# TODO: implementar rotina na classe PyNILM.utils\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "def listar_variaveis_memoria(ambiente):\n",
    "    print(\"* Variáveis instanciadas em memória:\")\n",
    "    print(\"---\")\n",
    "    total = 0\n",
    "    for name, size in sorted(((name, sys.getsizeof(value)) for name, value in ambiente.items()),\n",
    "                             key= lambda x: -x[1])[:10]:\n",
    "        total += size\n",
    "        print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))\n",
    "    print(\"---\")\n",
    "    print(\"Total:\", sizeof_fmt(total))\n",
    "    \n",
    "# TODO: implementar na classe utils\n",
    "def highlight_col(x):\n",
    "    r = 'background-color: #D9D9D9'\n",
    "    df1 = pd.DataFrame('', index=x.index, columns=x.columns)\n",
    "    df1.iloc[:, -2] = r\n",
    "    return df1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T17:00:00.322361Z",
     "start_time": "2021-05-02T17:00:00.201233Z"
    }
   },
   "outputs": [],
   "source": [
    "# CONSTANTES FUNDAMENTAIS DE ORGANIZACAO DE PASTAS/ARQUIVOS\n",
    "RESIDENCIA = 3\n",
    "\n",
    "# Path do arquivo H5 (base REDD ja preparada p/ NILMTK) e outros insumos fundamentais\n",
    "caminho_dados = \"D:/Projetos/phd-thesis/datasets/\"\n",
    "\n",
    "# Definir diretorios onde iremos salvar os insumos gerados do notebook (dados, imagens, etc.)\n",
    "caminho_dados_notebook = os.path.join(caminho_dados, \"26\") # Num. notebook\n",
    "if not os.path.isdir(caminho_dados_notebook):\n",
    "    os.makedirs(caminho_dados_notebook)\n",
    "caminho_imagens_notebook = os.path.join(caminho_dados_notebook, \"imagens\") # Num. notebook\n",
    "if not os.path.isdir(caminho_imagens_notebook):\n",
    "    os.makedirs(caminho_imagens_notebook)\n",
    "\n",
    "# Path do arquivo H5 (base REDD ja preparada p/ NILMTK)\n",
    "caminho_redd = os.path.join(caminho_dados, \"REDD/low_freq\")\n",
    "\n",
    "# Path completo do arquivo REDD\n",
    "arquivo_dataset = os.path.join(caminho_redd, \"redd.h5\")\n",
    "\n",
    "# VARIAVEL AUXILIAR\n",
    "# Path dos arquivos relacionados as janelas\n",
    "caminho_janelas = os.path.join(caminho_redd, \"../../phd\")\n",
    "if not os.path.isdir(caminho_janelas):\n",
    "    os.makedirs(caminho_janelas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T17:00:01.903538Z",
     "start_time": "2021-05-02T17:00:00.325362Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from six import iteritems\n",
    "\n",
    "from nilmtk import DataSet, TimeFrame, MeterGroup, HDFDataStore\n",
    "from nilmtk.legacy.disaggregate import CombinatorialOptimisation, FHMM\n",
    "import nilmtk.utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando datasets\n",
    "df_treino = pd.read_csv(os.path.join(caminho_dados_notebook, 'training_windows.txt'))\n",
    "df_validacao = pd.read_csv(os.path.join(caminho_dados_notebook, 'validation_windows.txt'))\n",
    "\n",
    "# Selecionando feature dominio do tempo e frequencia / outputs (status dos aparelhos - dummy)\n",
    "colunas_janela = df_treino.columns[:512]\n",
    "\n",
    "colunas_output = ['LC', 'LI', 'MO', 'MT', 'PC', 'LF']\n",
    "\n",
    "# Preparando dados de treino e validacao\n",
    "X_treino = df_treino[colunas_janela]\n",
    "X_validacao = df_validacao[colunas_janela]\n",
    "\n",
    "y_treino = df_treino[colunas_output].replace(-1, 0)\n",
    "y_validacao = df_validacao[colunas_output].replace(-1, 0)\n",
    "\n",
    "del df_treino\n",
    "del df_validacao\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento e Avaliação dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T17:00:27.268721Z",
     "start_time": "2021-05-02T17:00:16.855220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "# from PyNILM.dados.janelas import Janelas\n",
    "from PyNILM.dados.janelas import Janelas\n",
    "from PyNILM.dados.utils import *\n",
    "\n",
    "from PyNILM.avaliacao.metricas import *\n",
    "from PyNILM.avaliacao.graficos import *\n",
    "from PyNILM.avaliacao.analises import *\n",
    "\n",
    "from PyNILM.modelos.utils import *\n",
    "from PyNILM.modelos.dlafe import DLAFE\n",
    "# from PyNILM.modelos.rqa import RQA\n",
    "\n",
    "# Inicializar uso GPU\n",
    "start_tf_session(memory_limit=int(1024*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T17:00:27.377109Z",
     "start_time": "2021-05-02T17:00:27.271695Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagens RP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37800/37800 [01:57<00:00, 322.86it/s]\n",
      "100%|██████████| 25200/25200 [01:07<00:00, 371.28it/s]\n"
     ]
    }
   ],
   "source": [
    "from pyts.image import RecurrencePlot\n",
    "\n",
    "# Parametros execucao do experimento\n",
    "atributos = \"rp\" \n",
    "\n",
    "# Parametros DTLFE (antigo DLAFE)\n",
    "TAMANHO_IMAGEM_DLAFE = (32, 32, 3)\n",
    "# modelo_extrator = transfer_learning.vgg16.VGG16(\n",
    "#             weights='imagenet', \n",
    "#             include_top=False,\n",
    "#             pooling='avg'\n",
    "#         )\n",
    "# preprocessamento_extrator = transfer_learning.vgg16.preprocess_input\n",
    "\n",
    "def converter_janelas_para_rp(\n",
    "    X,\n",
    "    input_shape=TAMANHO_IMAGEM_DLAFE,\n",
    "    data_type=np.float32,\n",
    "    normalize=False, \n",
    "    standardize=False, \n",
    "    rescale=False,\n",
    "    # preprocessamento_extrator=None,\n",
    "    # modelo_extrator=None,\n",
    "    arquivo=None):\n",
    "    \n",
    "    X_ = np.empty((len(X), * input_shape))\n",
    "        \n",
    "    for i, x in tqdm(enumerate(X), total=X.shape[0]):\n",
    "        \n",
    "        img = RecurrencePlot(**PARAMETROS_RP).fit_transform([x])[0]\n",
    "        img = cv2.resize(\n",
    "                img, \n",
    "                dsize=input_shape[:2], \n",
    "                interpolation=cv2.INTER_CUBIC\n",
    "            ).astype(data_type)\n",
    "\n",
    "        if np.sum(img) > 0:\n",
    "            # TODO: improve fit/predict statistics\n",
    "            # Normalizar\n",
    "            if normalize:\n",
    "                img = (img - img.min()) / (img.max() - img.min()) # MinMax (0,1)\n",
    "                #img = (img - img.mean()) / np.max([img.std(), 1e-4])\n",
    "\n",
    "        #     # centralizar\n",
    "        #     if centralizar:\n",
    "        #         img -= img.mean()\n",
    "\n",
    "            # Padronizar\n",
    "            elif standardize:\n",
    "                img = (img - img.mean())/img.std()#tf.image.per_image_standardization(img).numpy()\n",
    "                \n",
    "            elif rescale:\n",
    "                img = (img - img.min()) / (img.max() - img.min())\n",
    "\n",
    "        # N canais\n",
    "        img = np.stack([img for i in range(input_shape[-1])],axis=-1).astype(data_type)     \n",
    "        \n",
    "        X_[i,] = img\n",
    "    \n",
    "    # X_ = np.array(X_).astype(data_type)\n",
    "\n",
    "    # # Extranindo atributos via DL\n",
    "    # if preprocessamento_extrator:\n",
    "    #     X_ = preprocessamento_extrator(X_).astype(data_type)\n",
    "    # if modelo_extrator:\n",
    "    #     output = modelo_extrator.predict(X_)\n",
    "    # else:\n",
    "    #     output = X_\n",
    "\n",
    "    if arquivo:\n",
    "        if os.path.isfile(arquivo): os.remove(arquivo)\n",
    "        np.save(arquivo, X_)\n",
    "\n",
    "    # return df    \n",
    "    return X_\n",
    "\n",
    "\n",
    "# Carregando dados RQA (treino)\n",
    "arquivo_treino = os.path.join(caminho_dados_notebook, f\"{atributos}_treino.npy\")\n",
    "if os.path.isfile(arquivo_treino):\n",
    "    X_treino = np.load(arquivo_treino)\n",
    "else:\n",
    "    X_treino = converter_janelas_para_rp(\n",
    "        X_treino.values,\n",
    "        input_shape=TAMANHO_IMAGEM_DLAFE,\n",
    "        # preprocessamento_extrator=preprocessamento_extrator,\n",
    "        # modelo_extrator=modelo_extrator,\n",
    "        arquivo=arquivo_treino)\n",
    "\n",
    "# Carregando dados RQA (validacao)\n",
    "arquivo_validacao = os.path.join(caminho_dados_notebook, f\"{atributos}_validacao.npy\")\n",
    "if os.path.isfile(arquivo_validacao):\n",
    "    X_validacao = np.load(arquivo_validacao)\n",
    "else:\n",
    "    X_validacao = converter_janelas_para_rp(\n",
    "        X_validacao.values,\n",
    "        input_shape=TAMANHO_IMAGEM_DLAFE,\n",
    "        # preprocessamento_extrator=preprocessamento_extrator,\n",
    "        # modelo_extrator=modelo_extrator,\n",
    "        arquivo=arquivo_validacao)\n",
    "\n",
    "# # Convertendo Numpy para Dataframe (evitar refatoracao codigo)\n",
    "# X_treino = pd.DataFrame(X_treino)\n",
    "# X_validacao = pd.DataFrame(X_validacao)\n",
    "\n",
    "# Dados agregados (validacao cruzada)\n",
    "X_cv = np.concatenate([X_treino, X_validacao])#.reset_index(drop=True) \n",
    "y_cv = pd.concat([y_treino, y_validacao]).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "def convnet(\n",
    "    input_shape_ = TAMANHO_IMAGEM_DLAFE, \n",
    "    output_dim=1, \n",
    "    optimizer='adam',\n",
    "    loss_function = 'binary_crossentropy', \n",
    "    metrics=['accuracy'],\n",
    "    output_activation = 'sigmoid',\n",
    "    bias_output = None,\n",
    "):\n",
    "    \n",
    "    if bias_output is not None:\n",
    "        bias_output = tf.keras.initializers.Constant(bias_output)\n",
    "        \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\", input_shape=input_shape_))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(output_dim, bias_initializer=bias_output, activation=output_activation))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=[loss_function], metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T22:18:59.268806Z",
     "start_time": "2021-05-02T17:03:12.352604Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "\n",
      "* Aparelho `LC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "1182/1182 [==============================] - 8s 6ms/step - loss: 0.1415 - accuracy: 0.9321\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1a77a7fbc947159a5a0cfd0c0a0d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 7s 5ms/step - loss: 0.0890 - accuracy: 0.9561\n",
      "1575/1575 [==============================] - 8s 5ms/step - loss: 0.0921 - accuracy: 0.9543\n",
      "1575/1575 [==============================] - 9s 5ms/step - loss: 0.1231 - accuracy: 0.9368\n",
      "1575/1575 [==============================] - 8s 5ms/step - loss: 0.1250 - accuracy: 0.9376\n",
      "1575/1575 [==============================] - 7s 4ms/step - loss: 0.1226 - accuracy: 0.9387\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LI`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "1182/1182 [==============================] - 7s 6ms/step - loss: 0.0389 - accuracy: 0.9822\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98     12400\n",
      "           1       1.00      0.95      0.98     12800\n",
      "\n",
      "    accuracy                           0.98     25200\n",
      "   macro avg       0.98      0.98      0.98     25200\n",
      "weighted avg       0.98      0.98      0.98     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [  602 12198]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db4b4433a3d43d08b0b5ed06c71b51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 8s 5ms/step - loss: 0.0264 - accuracy: 0.9882\n",
      "1575/1575 [==============================] - 8s 5ms/step - loss: 0.0211 - accuracy: 0.9918\n",
      "1575/1575 [==============================] - 8s 5ms/step - loss: 0.0200 - accuracy: 0.9922\n",
      "1575/1575 [==============================] - 8s 5ms/step - loss: 0.0274 - accuracy: 0.9884\n",
      "1575/1575 [==============================] - 7s 5ms/step - loss: 0.0188 - accuracy: 0.9927\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MO`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "1182/1182 [==============================] - 6s 5ms/step - loss: 0.3429 - accuracy: 0.8228\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     12400\n",
      "           1       1.00      0.88      0.93     12800\n",
      "\n",
      "    accuracy                           0.94     25200\n",
      "   macro avg       0.94      0.94      0.94     25200\n",
      "weighted avg       0.94      0.94      0.94     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [ 1600 11200]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1b7090747e429596163aabe8961a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 8s 5ms/step - loss: 0.2593 - accuracy: 0.8640: 0s - loss: 0\n",
      "1575/1575 [==============================] - 8s 5ms/step - loss: 0.2526 - accuracy: 0.8742\n",
      "1575/1575 [==============================] - 9s 5ms/step - loss: 0.2753 - accuracy: 0.8570\n",
      "1575/1575 [==============================] - 8s 5ms/step - loss: 0.2663 - accuracy: 0.8649\n",
      "1575/1575 [==============================] - 7s 5ms/step - loss: 0.2671 - accuracy: 0.8628\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     31000\n",
      "           1       1.00      0.99      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [  224 31776]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MT`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "1182/1182 [==============================] - 6s 5ms/step - loss: 0.1432 - accuracy: 0.9331\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7272c33ee3e0400589a21ed2685b0da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 9s 6ms/step - loss: 0.0974 - accuracy: 0.9600\n",
      "1575/1575 [==============================] - 7s 5ms/step - loss: 0.0969 - accuracy: 0.9566\n",
      "1575/1575 [==============================] - 8s 5ms/step - loss: 0.1144 - accuracy: 0.9496\n",
      "1575/1575 [==============================] - 8s 5ms/step - loss: 0.1037 - accuracy: 0.9539\n",
      "1575/1575 [==============================] - 8s 5ms/step - loss: 0.0964 - accuracy: 0.9569\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     31000\n",
      "           1       1.00      0.99      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [  215 31785]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `PC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "1182/1182 [==============================] - 7s 6ms/step - loss: 0.3256 - accuracy: 0.8152\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     12400\n",
      "           1       0.99      1.00      0.99     12800\n",
      "\n",
      "    accuracy                           0.99     25200\n",
      "   macro avg       0.99      0.99      0.99     25200\n",
      "weighted avg       0.99      0.99      0.99     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12250   150]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76065260b41448a839dd3c6f63709b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 8s 5ms/step - loss: 0.1833 - accuracy: 0.8973\n",
      "1575/1575 [==============================] - 8s 5ms/step - loss: 0.2129 - accuracy: 0.8843\n",
      "1575/1575 [==============================] - 9s 6ms/step - loss: 0.2195 - accuracy: 0.8823\n",
      "1575/1575 [==============================] - 8s 5ms/step - loss: 0.2524 - accuracy: 0.8619\n",
      "1575/1575 [==============================] - 8s 5ms/step - loss: 0.2151 - accuracy: 0.8729\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LF`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "1182/1182 [==============================] - 7s 6ms/step - loss: 0.5928 - accuracy: 0.6393\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78     12400\n",
      "           1       0.82      0.70      0.75     12800\n",
      "\n",
      "    accuracy                           0.77     25200\n",
      "   macro avg       0.77      0.77      0.77     25200\n",
      "weighted avg       0.77      0.77      0.77     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[10400  2000]\n",
      " [ 3830  8970]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96cf05aab1154a7c824d9b641a536bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 8s 5ms/step - loss: 0.5139 - accuracy: 0.6967\n",
      "1575/1575 [==============================] - 9s 6ms/step - loss: 0.4651 - accuracy: 0.7327\n",
      "1575/1575 [==============================] - 8s 5ms/step - loss: 0.5455 - accuracy: 0.6707\n",
      "1575/1575 [==============================] - 9s 6ms/step - loss: 0.5143 - accuracy: 0.6978\n",
      "1575/1575 [==============================] - 9s 6ms/step - loss: 0.5278 - accuracy: 0.6843\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85     31000\n",
      "           1       0.89      0.81      0.85     32000\n",
      "\n",
      "    accuracy                           0.85     63000\n",
      "   macro avg       0.85      0.85      0.85     63000\n",
      "weighted avg       0.85      0.85      0.85     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[27706  3294]\n",
      " [ 6172 25828]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LC</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LF</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.849746</td>\n",
       "      <td>0.030841</td>\n",
       "      <td>0.896111</td>\n",
       "      <td>0.824206</td>\n",
       "      <td>0.849000</td>\n",
       "      <td>0.031342</td>\n",
       "      <td>0.895655</td>\n",
       "      <td>0.821143</td>\n",
       "      <td>0.850433</td>\n",
       "      <td>0.030854</td>\n",
       "      <td>0.897387</td>\n",
       "      <td>0.825612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.768651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768651</td>\n",
       "      <td>0.768651</td>\n",
       "      <td>0.767903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.767903</td>\n",
       "      <td>0.767903</td>\n",
       "      <td>0.769745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.769745</td>\n",
       "      <td>0.769745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LI</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.976111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976111</td>\n",
       "      <td>0.976111</td>\n",
       "      <td>0.976110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976110</td>\n",
       "      <td>0.976110</td>\n",
       "      <td>0.976484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976484</td>\n",
       "      <td>0.976484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MO</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.996444</td>\n",
       "      <td>0.007687</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982698</td>\n",
       "      <td>0.996444</td>\n",
       "      <td>0.007687</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982698</td>\n",
       "      <td>0.996500</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.936508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.936508</td>\n",
       "      <td>0.936508</td>\n",
       "      <td>0.936364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.936364</td>\n",
       "      <td>0.936364</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MT</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.996587</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982937</td>\n",
       "      <td>0.996587</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982936</td>\n",
       "      <td>0.996641</td>\n",
       "      <td>0.007512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PC</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.994048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.994048</td>\n",
       "      <td>0.994048</td>\n",
       "      <td>0.994045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.994045</td>\n",
       "      <td>0.994045</td>\n",
       "      <td>0.993952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993952</td>\n",
       "      <td>0.993952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             acc                                      f1  \\\n",
       "                            mean       std       max       min      mean   \n",
       "appliance base                                                             \n",
       "LC        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "LF        cv            0.849746  0.030841  0.896111  0.824206  0.849000   \n",
       "          treino-teste  0.768651       NaN  0.768651  0.768651  0.767903   \n",
       "LI        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  0.976111       NaN  0.976111  0.976111  0.976110   \n",
       "MO        cv            0.996444  0.007687  1.000000  0.982698  0.996444   \n",
       "          treino-teste  0.936508       NaN  0.936508  0.936508  0.936364   \n",
       "MT        cv            0.996587  0.007631  1.000000  0.982937  0.996587   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "PC        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  0.994048       NaN  0.994048  0.994048  0.994045   \n",
       "\n",
       "                                                           auc            \\\n",
       "                             std       max       min      mean       std   \n",
       "appliance base                                                             \n",
       "LC        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "LF        cv            0.031342  0.895655  0.821143  0.850433  0.030854   \n",
       "          treino-teste       NaN  0.767903  0.767903  0.769745       NaN   \n",
       "LI        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  0.976110  0.976110  0.976484       NaN   \n",
       "MO        cv            0.007687  1.000000  0.982698  0.996500  0.007567   \n",
       "          treino-teste       NaN  0.936364  0.936364  0.937500       NaN   \n",
       "MT        cv            0.007631  1.000000  0.982936  0.996641  0.007512   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "PC        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  0.994045  0.994045  0.993952       NaN   \n",
       "\n",
       "                                            \n",
       "                             max       min  \n",
       "appliance base                              \n",
       "LC        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "LF        cv            0.897387  0.825612  \n",
       "          treino-teste  0.769745  0.769745  \n",
       "LI        cv            1.000000  1.000000  \n",
       "          treino-teste  0.976484  0.976484  \n",
       "MO        cv            1.000000  0.982969  \n",
       "          treino-teste  0.937500  0.937500  \n",
       "MT        cv            1.000000  0.983203  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "PC        cv            1.000000  1.000000  \n",
       "          treino-teste  0.993952  0.993952  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nome_modelo = \"cnn\"\n",
    "\n",
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \n",
    "    \"base\": []\n",
    "}\n",
    "\n",
    "for rotulo_aparelho in colunas_output:\n",
    "    \n",
    "    print(\"****************************************************************\\n\")\n",
    "    print(f\"* Aparelho `{rotulo_aparelho}`...\\n\")\n",
    "    \n",
    "    #######################################################################\n",
    "    #                AVALIACAO 1 - Base de treino/validacao               #\n",
    "    #######################################################################\n",
    "\n",
    "    # # Filtrando output/status por aparelho\n",
    "    y_treino_aparelho = y_treino[rotulo_aparelho]\n",
    "    y_validacao_aparelho = y_validacao[rotulo_aparelho]\n",
    "\n",
    "    print(f\"  - Avaliando modelo através da base treino/validacao...\")\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem (lote validacao):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_validacao_aparelho).items():\n",
    "        print(f\"       - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_validacao_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "\n",
    "    # Treinando modelo\n",
    "    print(f\"     -> Treinando modelo...\\n\")\n",
    "    clf = convnet(\n",
    "        input_shape_= TAMANHO_IMAGEM_DLAFE,\n",
    "        output_dim = 1,\n",
    "        loss_function='binary_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "        output_activation='sigmoid'\n",
    "    )\n",
    "\n",
    "        \n",
    "    clf.fit(X_treino, y_treino_aparelho)\n",
    "\n",
    "    # Prevendo conjunto de dados\n",
    "    y_hat = clf.predict(X_validacao).round().astype(np.int16)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "    resultados_modelo[\"fold\"].append(\"-\")\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_validacao_aparelho, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_validacao_aparelho, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_validacao_aparelho, y_hat) if np.unique(y_validacao_aparelho).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"treino-teste\")\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_validacao_aparelho, y_hat))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_validacao_aparelho, y_hat))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    #######################################################################\n",
    "    #                  AVALIACAO 2 - Validacao Cruzada                    #\n",
    "    #######################################################################\n",
    "    \n",
    "    y_true_cv, y_pred_cv  = [], []\n",
    "\n",
    "    print(f\"  - Avaliando através de validação cruzada ({skf.n_splits}-folds)...\")\n",
    "\n",
    "    # Filtrando output/status por aparelho\n",
    "    y_aparelho = y_cv[rotulo_aparelho]\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem:\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_aparelho).items():\n",
    "        print(f\"        - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "    \n",
    "\n",
    "    print(f\"     -> Avaliando modelo (CV - {skf.n_splits} folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in tqdm_notebook(enumerate(skf.split(X_cv, y_aparelho)), total=skf.n_splits):\n",
    "        \n",
    "        # Preparando lotes\n",
    "        X_treino_cv, X_teste_cv = X_cv[idx_treino], X_cv[idx_teste]\n",
    "        y_treino_cv, y_teste_cv = y_aparelho.iloc[idx_treino], y_aparelho.iloc[idx_teste]\n",
    "\n",
    "        # Treinando modelo\n",
    "        clf = convnet(\n",
    "            input_shape_= TAMANHO_IMAGEM_DLAFE,\n",
    "            output_dim = 1,\n",
    "            loss_function='binary_crossentropy',\n",
    "            metrics=['accuracy'],\n",
    "            output_activation='sigmoid'\n",
    "        )\n",
    "        \n",
    "        clf.fit(X_treino_cv, y_treino_cv)\n",
    "\n",
    "        # Prevendo conjunto de dados\n",
    "        y_hat = clf.predict(X_teste_cv).round().astype(np.int16)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste_cv, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste_cv, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste_cv, y_hat) if np.unique(y_teste_cv).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"cv\")\n",
    "\n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true_cv.extend(y_teste_cv)\n",
    "        y_pred_cv.extend(y_hat)\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true_cv, y_pred_cv))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true_cv, y_pred_cv))\n",
    "    print()\n",
    "    print(\"**********************************************\")\n",
    "    print()\n",
    "    \n",
    "# Consolidando DataFrame\n",
    "df_resultados = pd.DataFrame(resultados_modelo)\n",
    "\n",
    "arquivo_resultados = os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_resultados_{nome_modelo}.xlsx\")\n",
    "if os.path.isfile(arquivo_resultados): os.remove(arquivo_resultados)\n",
    "df_resultados.to_excel(arquivo_resultados, index=False)\n",
    "    \n",
    "print(\"############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\")\n",
    "display(df_resultados.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:10:32.077065Z",
     "start_time": "2021-05-03T09:10:31.295643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Análise por aparelho/modelo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LC</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LF</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.849746</td>\n",
       "      <td>0.030841</td>\n",
       "      <td>0.896111</td>\n",
       "      <td>0.824206</td>\n",
       "      <td>0.849000</td>\n",
       "      <td>0.031342</td>\n",
       "      <td>0.895655</td>\n",
       "      <td>0.821143</td>\n",
       "      <td>0.850433</td>\n",
       "      <td>0.030854</td>\n",
       "      <td>0.897387</td>\n",
       "      <td>0.825612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.768651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768651</td>\n",
       "      <td>0.768651</td>\n",
       "      <td>0.767903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.767903</td>\n",
       "      <td>0.767903</td>\n",
       "      <td>0.769745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.769745</td>\n",
       "      <td>0.769745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LI</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.976111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976111</td>\n",
       "      <td>0.976111</td>\n",
       "      <td>0.976110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976110</td>\n",
       "      <td>0.976110</td>\n",
       "      <td>0.976484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976484</td>\n",
       "      <td>0.976484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MO</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.996444</td>\n",
       "      <td>0.007687</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982698</td>\n",
       "      <td>0.996444</td>\n",
       "      <td>0.007687</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982698</td>\n",
       "      <td>0.996500</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.936508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.936508</td>\n",
       "      <td>0.936508</td>\n",
       "      <td>0.936364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.936364</td>\n",
       "      <td>0.936364</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MT</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.996587</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982937</td>\n",
       "      <td>0.996587</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982936</td>\n",
       "      <td>0.996641</td>\n",
       "      <td>0.007512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PC</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.994048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.994048</td>\n",
       "      <td>0.994048</td>\n",
       "      <td>0.994045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.994045</td>\n",
       "      <td>0.994045</td>\n",
       "      <td>0.993952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993952</td>\n",
       "      <td>0.993952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             acc                                      f1  \\\n",
       "                            mean       std       max       min      mean   \n",
       "appliance base                                                             \n",
       "LC        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "LF        cv            0.849746  0.030841  0.896111  0.824206  0.849000   \n",
       "          treino-teste  0.768651       NaN  0.768651  0.768651  0.767903   \n",
       "LI        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  0.976111       NaN  0.976111  0.976111  0.976110   \n",
       "MO        cv            0.996444  0.007687  1.000000  0.982698  0.996444   \n",
       "          treino-teste  0.936508       NaN  0.936508  0.936508  0.936364   \n",
       "MT        cv            0.996587  0.007631  1.000000  0.982937  0.996587   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "PC        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  0.994048       NaN  0.994048  0.994048  0.994045   \n",
       "\n",
       "                                                           auc            \\\n",
       "                             std       max       min      mean       std   \n",
       "appliance base                                                             \n",
       "LC        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "LF        cv            0.031342  0.895655  0.821143  0.850433  0.030854   \n",
       "          treino-teste       NaN  0.767903  0.767903  0.769745       NaN   \n",
       "LI        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  0.976110  0.976110  0.976484       NaN   \n",
       "MO        cv            0.007687  1.000000  0.982698  0.996500  0.007567   \n",
       "          treino-teste       NaN  0.936364  0.936364  0.937500       NaN   \n",
       "MT        cv            0.007631  1.000000  0.982936  0.996641  0.007512   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "PC        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  0.994045  0.994045  0.993952       NaN   \n",
       "\n",
       "                                            \n",
       "                             max       min  \n",
       "appliance base                              \n",
       "LC        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "LF        cv            0.897387  0.825612  \n",
       "          treino-teste  0.769745  0.769745  \n",
       "LI        cv            1.000000  1.000000  \n",
       "          treino-teste  0.976484  0.976484  \n",
       "MO        cv            1.000000  0.982969  \n",
       "          treino-teste  0.937500  0.937500  \n",
       "MT        cv            1.000000  0.983203  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "PC        cv            1.000000  1.000000  \n",
       "          treino-teste  0.993952  0.993952  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_resultados_svm = pd.read_excel(os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_resultados_svm.xlsx\"), engine='openpyxl')\n",
    "# df_resultados_svm[\"model\"] = \"SVM\"\n",
    "\n",
    "# df_resultados_xgboost = pd.read_excel(os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_resultados_xgboost.xlsx\"), engine='openpyxl')\n",
    "# df_resultados_xgboost[\"model\"] = \"XGBOOST\"\n",
    "\n",
    "# df_resultados_mlp = pd.read_excel(os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_resultados_mlp.xlsx\"), engine='openpyxl')\n",
    "# df_resultados_mlp[\"model\"] = \"MLP\"\n",
    "\n",
    "# # df_resultados_elm = pd.read_excel(os.path.join(caminho_dados_notebook, \"df_resultados_elm.xlsx\"))\n",
    "# # df_resultados_elm[\"model\"] = \"ELM\"\n",
    "\n",
    "# df_analise = pd.concat([\n",
    "#     df_resultados_svm,\n",
    "#     df_resultados_xgboost,\n",
    "#     df_resultados_mlp, \n",
    "# #     df_resultados_elm,  \n",
    "# ])\n",
    "\n",
    "# print(\"* Análise por modelo:\")\n",
    "# df_analise_modelo = df_analise.groupby([\"model\",\"base\"]).agg({\n",
    "#     \"acc\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "#     \"f1\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "#     \"auc\": [\"mean\",\"std\",\"max\",\"min\"]\n",
    "# }).reset_index().sort_values(('f1','mean'), ascending=False).set_index(\"model\")\n",
    "# display(df_analise_modelo)\n",
    "# df_analise_modelo.to_excel(os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_analise_modelos.xlsx\"))\n",
    "\n",
    "print()\n",
    "print(\"* Análise por aparelho/modelo:\")\n",
    "df_analise_aparelho = df_resultados.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"f1\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"auc\": [\"mean\",\"std\",\"max\",\"min\"]\n",
    "})#.reset_index().sort_values(('f1','mean'), ascending=False).set_index([\"aparelho\",\"metodologia\"])\n",
    "display(df_analise_aparelho)\n",
    "df_analise_aparelho.to_excel(os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_analise_aparelhos.xls\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:10:32.109285Z",
     "start_time": "2021-05-03T09:10:32.079991Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:10:32.155124Z",
     "start_time": "2021-05-03T09:10:32.113288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Diego Luiz Cavalca\n",
      "\n",
      "Last updated: Mon Jan 24 2022 08:52:41Hora oficial do Brasil\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.8\n",
      "IPython version      : 7.21.0\n",
      "\n",
      "Compiler    : MSC v.1928 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 158 Stepping 9, GenuineIntel\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 5e5bccaaf9e541e11be67706c7eb7d7b39a8be65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -a \"Diego Luiz Cavalca\" -u -n -t -z -v -m -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

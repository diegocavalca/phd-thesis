{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação modelo DTLFE pré-treinado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T15:31:21.873352Z",
     "start_time": "2021-05-02T15:31:20.219102Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import json\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "from pretty_confusion_matrix import *\n",
    "\n",
    "# TODO: implementar rotina na classe PyNILM.utils\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "def listar_variaveis_memoria(ambiente):\n",
    "    print(\"* Variáveis instanciadas em memória:\")\n",
    "    print(\"---\")\n",
    "    total = 0\n",
    "    for name, size in sorted(((name, sys.getsizeof(value)) for name, value in ambiente.items()),\n",
    "                             key= lambda x: -x[1])[:10]:\n",
    "        total += size\n",
    "        print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))\n",
    "    print(\"---\")\n",
    "    print(\"Total:\", sizeof_fmt(total))\n",
    "    \n",
    "# TODO: implementar na classe utils\n",
    "def highlight_col(x):\n",
    "    r = 'background-color: #D9D9D9'\n",
    "    df1 = pd.DataFrame('', index=x.index, columns=x.columns)\n",
    "    df1.iloc[:, -2] = r\n",
    "    return df1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T15:31:21.888343Z",
     "start_time": "2021-05-02T15:31:21.875349Z"
    }
   },
   "outputs": [],
   "source": [
    "# # CONSTANTES FUNDAMENTAIS DE ORGANIZACAO DE PASTAS/ARQUIVOS\n",
    "RESIDENCIA = 3\n",
    "\n",
    "# Path do arquivo H5 (base REDD ja preparada p/ NILMTK) e outros insumos fundamentais\n",
    "caminho_dados = \"D:/Projetos/phd-thesis/datasets/\"\n",
    "\n",
    "# Definir diretorios onde iremos salvar os insumos gerados do notebook (dados, imagens, etc.)\n",
    "caminho_dados_notebook = os.path.join(caminho_dados, \"28\") # Num. notebook\n",
    "if not os.path.isdir(caminho_dados_notebook):\n",
    "    os.makedirs(caminho_dados_notebook)\n",
    "caminho_imagens_notebook = os.path.join(caminho_dados_notebook, \"imagens\") # Num. notebook\n",
    "if not os.path.isdir(caminho_imagens_notebook):\n",
    "    os.makedirs(caminho_imagens_notebook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T15:31:22.702434Z",
     "start_time": "2021-05-02T15:31:21.891310Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse as date_parser\n",
    "\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from six import iteritems\n",
    "\n",
    "from nilmtk import DataSet, TimeFrame, MeterGroup, HDFDataStore\n",
    "from nilmtk.legacy.disaggregate import CombinatorialOptimisation, FHMM\n",
    "import nilmtk.utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base REDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T15:31:22.921813Z",
     "start_time": "2021-05-02T15:31:22.704432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NILMTK -> Detalhes sobre o dataset REDD:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ul><li><strong>name</strong>: REDD</li><li><strong>long_name</strong>: The Reference Energy Disaggregation Data set</li><li><strong>creators</strong>: <ul><li>Kolter, Zico</li><li>Johnson, Matthew</li></ul></li><li><strong>publication_date</strong>: 2011</li><li><strong>institution</strong>: Massachusetts Institute of Technology (MIT)</li><li><strong>contact</strong>: zkolter@cs.cmu.edu</li><li><strong>description</strong>: Several weeks of power data for 6 different homes.</li><li><strong>subject</strong>: Disaggregated power demand from domestic buildings.</li><li><strong>number_of_buildings</strong>: 6</li><li><strong>timezone</strong>: US/Eastern</li><li><strong>geo_location</strong>: <ul><li><strong>locality</strong>: Massachusetts</li><li><strong>country</strong>: US</li><li><strong>latitude</strong>: 42.360091</li><li><strong>longitude</strong>: -71.09416</li></ul></li><li><strong>related_documents</strong>: <ul><li><a href=\"http://redd.csail.mit.edu\">http://redd.csail.mit.edu</a></li><li>J. Zico Kolter and Matthew J. Johnson. REDD: A public data set for energy disaggregation research. In proceedings of the SustKDD workshop on Data Mining Applications in Sustainability, 2011. <a href=\"http://redd.csail.mit.edu/kolter-kddsust11.pdf\">http://redd.csail.mit.edu/kolter-kddsust11.pdf</a>\n",
       "</li></ul></li><li><strong>schema</strong>: <a href=\"https://github.com/nilmtk/nilm_metadata/tree/v0.2\">https://github.com/nilmtk/nilm_metadata/tree/v0.2</a></li><li><strong>meter_devices</strong>: <ul><li><strong>eMonitor</strong>: <ul><li><strong>model</strong>: eMonitor</li><li><strong>manufacturer</strong>: Powerhouse Dynamics</li><li><strong>manufacturer_url</strong>: <a href=\"http://powerhousedynamics.com\">http://powerhousedynamics.com</a></li><li><strong>description</strong>: Measures circuit-level power demand.  Comes with 24 CTs. This FAQ page suggests the eMonitor measures real (active) power: <a href=\"http://www.energycircle.com/node/14103\">http://www.energycircle.com/node/14103</a>  although the REDD readme.txt says all channels record apparent power.\n",
       "</li><li><strong>sample_period</strong>: 3</li><li><strong>max_sample_period</strong>: 50</li><li><strong>measurements</strong>: <ul><li>{'physical_quantity': 'power', 'type': 'active', 'upper_limit': 5000, 'lower_limit': 0}</li></ul></li><li><strong>wireless</strong>: False</li></ul></li><li><strong>REDD_whole_house</strong>: <ul><li><strong>description</strong>: REDD's DIY power meter used to measure whole-home AC waveforms at high frequency.  To quote from their paper: \"CTs from TED (<a href=\"http://www.theenergydetective.com\">http://www.theenergydetective.com</a>) to measure current in the power mains, a Pico TA041 oscilloscope probe (<a href=\"http://www.picotechnologies.com\">http://www.picotechnologies.com</a>) to measure voltage for one of the two phases in the home, and a National Instruments NI-9239 analog to digital converter to transform both these analog signals to digital readings. This A/D converter has 24 bit resolution with noise of approximately 70 ÂµV, which determines the noise level of our current and voltage readings: the TED CTs are rated for 200 amp circuits and a maximum of 3 volts, so we are able to differentiate between currents of approximately ((200))(70 Ã— 10âˆ’6)/(3) = 4.66mA, corresponding to power changes of about 0.5 watts. Similarly, since we use a 1:100 voltage stepdown in the oscilloscope probe, we can detect voltage differences of about 7mV.\"\n",
       "</li><li><strong>sample_period</strong>: 1</li><li><strong>max_sample_period</strong>: 30</li><li><strong>measurements</strong>: <ul><li>{'physical_quantity': 'power', 'type': 'apparent', 'upper_limit': 50000, 'lower_limit': 0}</li></ul></li><li><strong>wireless</strong>: False</li></ul></li></ul></li></ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Path do arquivo H5 (base REDD ja preparada p/ NILMTK)\n",
    "caminho_redd = os.path.join(caminho_dados, \"REDD/low_freq\")\n",
    "caminho_ukdale = os.path.join(caminho_dados, \"UK-DALE\")\n",
    "\n",
    "# Path completo do arquivo REDD/UKDALE\n",
    "arquivo_dataset_redd = os.path.join(caminho_redd, \"redd.h5\")\n",
    "arquivo_dataset_ukdale = os.path.join(caminho_ukdale, \"ukdale.h5\")\n",
    "\n",
    "# VARIAVEL AUXILIAR\n",
    "# Path dos arquivos relacionados as janelas\n",
    "caminho_janelas = os.path.join(caminho_redd, \"../../phd\")\n",
    "if not os.path.isdir(caminho_janelas):\n",
    "    os.makedirs(caminho_janelas)\n",
    "\n",
    "# Gerar arquivo H5 (Nilmtk) do dataset REDD, caso n exista\n",
    "if not os.path.isfile(arquivo_dataset_redd):\n",
    "    from nilmtk.dataset_converters import convert_redd\n",
    "    \n",
    "    print(\"Gerando arquivo H5 (NILMTK) da base REDD, aguarde...\")\n",
    "    print(\"-----\")\n",
    "    convert_redd(caminho_redd, arquivo_dataset_redd)\n",
    "\n",
    "# Carregando dataset REDD no objeto NILMTK\n",
    "# Exemplo de carregamento da base REDD no NILMTK\n",
    "import h5py # * Evitar erro de incompatibilidade entre h5py e nilmtk\n",
    "from nilmtk import DataSet\n",
    "from nilmtk.utils import print_dict\n",
    "\n",
    "redd = DataSet(arquivo_dataset_redd)\n",
    "print(\"NILMTK -> Detalhes sobre o dataset REDD:\")\n",
    "print_dict(redd.metadata)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'REDD',\n",
       " 'long_name': 'The Reference Energy Disaggregation Data set',\n",
       " 'creators': ['Kolter, Zico', 'Johnson, Matthew'],\n",
       " 'publication_date': 2011,\n",
       " 'institution': 'Massachusetts Institute of Technology (MIT)',\n",
       " 'contact': 'zkolter@cs.cmu.edu',\n",
       " 'description': 'Several weeks of power data for 6 different homes.',\n",
       " 'subject': 'Disaggregated power demand from domestic buildings.',\n",
       " 'number_of_buildings': 6,\n",
       " 'timezone': 'US/Eastern',\n",
       " 'geo_location': {'locality': 'Massachusetts',\n",
       "  'country': 'US',\n",
       "  'latitude': 42.360091,\n",
       "  'longitude': -71.09416},\n",
       " 'related_documents': ['http://redd.csail.mit.edu',\n",
       "  'J. Zico Kolter and Matthew J. Johnson. REDD: A public data set for energy disaggregation research. In proceedings of the SustKDD workshop on Data Mining Applications in Sustainability, 2011. http://redd.csail.mit.edu/kolter-kddsust11.pdf\\n'],\n",
       " 'schema': 'https://github.com/nilmtk/nilm_metadata/tree/v0.2',\n",
       " 'meter_devices': {'eMonitor': {'model': 'eMonitor',\n",
       "   'manufacturer': 'Powerhouse Dynamics',\n",
       "   'manufacturer_url': 'http://powerhousedynamics.com',\n",
       "   'description': 'Measures circuit-level power demand.  Comes with 24 CTs. This FAQ page suggests the eMonitor measures real (active) power: http://www.energycircle.com/node/14103  although the REDD readme.txt says all channels record apparent power.\\n',\n",
       "   'sample_period': 3,\n",
       "   'max_sample_period': 50,\n",
       "   'measurements': [{'physical_quantity': 'power',\n",
       "     'type': 'active',\n",
       "     'upper_limit': 5000,\n",
       "     'lower_limit': 0}],\n",
       "   'wireless': False},\n",
       "  'REDD_whole_house': {'description': 'REDD\\'s DIY power meter used to measure whole-home AC waveforms at high frequency.  To quote from their paper: \"CTs from TED (http://www.theenergydetective.com) to measure current in the power mains, a Pico TA041 oscilloscope probe (http://www.picotechnologies.com) to measure voltage for one of the two phases in the home, and a National Instruments NI-9239 analog to digital converter to transform both these analog signals to digital readings. This A/D converter has 24 bit resolution with noise of approximately 70 ÂµV, which determines the noise level of our current and voltage readings: the TED CTs are rated for 200 amp circuits and a maximum of 3 volts, so we are able to differentiate between currents of approximately ((200))(70 Ã— 10âˆ’6)/(3) = 4.66mA, corresponding to power changes of about 0.5 watts. Similarly, since we use a 1:100 voltage stepdown in the oscilloscope probe, we can detect voltage differences of about 7mV.\"\\n',\n",
       "   'sample_period': 1,\n",
       "   'max_sample_period': 30,\n",
       "   'measurements': [{'physical_quantity': 'power',\n",
       "     'type': 'apparent',\n",
       "     'upper_limit': 50000,\n",
       "     'lower_limit': 0}],\n",
       "   'wireless': False}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redd.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base UK-DALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NILMTK -> Detalhes sobre o dataset UK-DALE:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ul><li><strong>contact</strong>: jack.kelly@imperial.ac.uk</li><li><strong>creators</strong>: <ul><li>Kelly, Jack</li></ul></li><li><strong>date</strong>: 2015-01-05</li><li><strong>description</strong>: Appliance-by-appliance and whole-home power demand for 5 UK homes. Appliance power demand was recorded once every 6 seconds. Whole-home power demand was recorded once every 6 seconds for all homes and additionally at 16kHz for homes 1, 2 and 5. Detailed metadata is included.</li><li><strong>description_of_subjects</strong>: 4 MSc students and 1 PhD student.</li><li><strong>funding</strong>: <ul><li>Jack Kelly's PhD is funded by an EPSRC DTA</li><li>Hardware necessary for this project was funded from Jack Kelly's Intel EU PhD Fellowship</li></ul></li><li><strong>geo_location</strong>: <ul><li><strong>country</strong>: GB</li><li><strong>latitude</strong>: 51.464462</li><li><strong>locality</strong>: London</li><li><strong>longitude</strong>: -0.076544</li></ul></li><li><strong>geospatial_coverage</strong>: Southern England</li><li><strong>institution</strong>: Imperial College London</li><li><strong>long_name</strong>: UK Domestic Appliance-Level Electricity</li><li><strong>name</strong>: UK-DALE</li><li><strong>number_of_buildings</strong>: 5</li><li><strong>publisher</strong>: UK Energy Research Centre Energy Data Centre (UKERC EDC)</li><li><strong>related_documents</strong>: <ul><li>Jack Kelly and William Knottenbelt. The UK-DALE dataset, domestic appliance-level electricity demand and whole-house demand from five UK homes.  Scientific Data 2:150007.  DOI:10.1038/sdata.2015.7 arXiv:1404.0284 (2015).</li><li>The 1s and 6s data is available from the UK Energy Research Council's Energy Data Centre: <a href=\"http://data.ukedc.rl.ac.uk/cgi-bin/dataset_catalogue/view.cgi.py?id=20\">http://data.ukedc.rl.ac.uk/cgi-bin/dataset_catalogue/view.cgi.py?id=20</a> DOI:10.5286/UKERC.EDC.000001</li><li>The 16 kHz data is also available from the UK Energy Research Council's Energy Data Centre: <a href=\"http://data.ukedc.rl.ac.uk/cgi-bin/dataset_catalogue//view.cgi.py?id=21\">http://data.ukedc.rl.ac.uk/cgi-bin/dataset_catalogue//view.cgi.py?id=21</a> DOI:10.5286/UKERC.EDC.000002</li><li>All the data is also available for download from <a href=\"http://www.doc.ic.ac.uk/~dk3810/data/.\">http://www.doc.ic.ac.uk/~dk3810/data/.</a> This Imperial repository is likely to receive updates for House 1 data occasionally during 2015 and possibly further into the future.  This Imperial repository may disappear some time after mid-2016.</li></ul></li><li><strong>rights_list</strong>: <ul><li>{'name': 'Creative Commons Attribution 4.0 International (CC BY 4.0)', 'uri': 'http://creativecommons.org/licenses/by/4.0/'}</li></ul></li><li><strong>schema</strong>: <a href=\"https://github.com/nilmtk/nilm_metadata/tree/v0.2\">https://github.com/nilmtk/nilm_metadata/tree/v0.2</a></li><li><strong>subject</strong>: Disaggregated domestic electricity demand</li><li><strong>timeframe</strong>: <ul><li><strong>end</strong>: 2015-01-05T06:26:44+00:00</li><li><strong>start</strong>: 2012-11-09T22:28:15+00:00</li></ul></li><li><strong>timezone</strong>: Europe/London</li><li><strong>meter_devices</strong>: <ul><li><strong>CurrentCostTx</strong>: <ul><li><strong>data_logger</strong>: <ul><li><strong>creators</strong>: <ul><li>Jack Kelly</li></ul></li><li><strong>model</strong>: rfm_ecomanager_logger</li><li><strong>model_url</strong>: <a href=\"https://github.com/JackKelly/rfm_ecomanager_logger\">https://github.com/JackKelly/rfm_ecomanager_logger</a></li></ul></li><li><strong>manufacturer</strong>: Current Cost</li><li><strong>max_sample_period</strong>: 120</li><li><strong>measurements</strong>: <ul><li>{'upper_limit': 25000, 'lower_limit': 0, 'physical_quantity': 'power', 'type': 'apparent'}</li></ul></li><li><strong>model</strong>: CurrentCost Tx</li><li><strong>model_url</strong>: <a href=\"http://www.currentcost.com/product-transmitter.html\">http://www.currentcost.com/product-transmitter.html</a></li><li><strong>sample_period</strong>: 6</li><li><strong>wireless</strong>: True</li><li><strong>wireless_configuration</strong>: <ul><li><strong>base</strong>: creators: [Jack Kelly] model: rfm_edf_ecomanager model_url: <a href=\"https://github.com/JackKelly/rfm_edf_ecomanager/\">https://github.com/JackKelly/rfm_edf_ecomanager/</a>\n",
       "</li><li><strong>protocol</strong>: custom</li><li><strong>carrier_frequency</strong>: 434</li></ul></li></ul></li><li><strong>EcoManagerWholeHouseTx</strong>: <ul><li><strong>brand</strong>: EcoManager</li><li><strong>brand_url</strong>: <a href=\"http://www.edfenergy.com/products-services/for-your-home/ecomanager\">http://www.edfenergy.com/products-services/for-your-home/ecomanager</a></li><li><strong>data_logger</strong>: <ul><li><strong>creators</strong>: <ul><li>Jack Kelly</li></ul></li><li><strong>model</strong>: rfm_ecomanager_logger</li><li><strong>model_url</strong>: <a href=\"https://github.com/JackKelly/rfm_ecomanager_logger\">https://github.com/JackKelly/rfm_ecomanager_logger</a></li></ul></li><li><strong>manufacturer</strong>: Current Cost / Sailwider</li><li><strong>max_sample_period</strong>: 120</li><li><strong>measurements</strong>: <ul><li>{'upper_limit': 25000, 'lower_limit': 0, 'physical_quantity': 'power', 'type': 'apparent'}</li></ul></li><li><strong>model</strong>: EcoManagerWholeHouseTx</li><li><strong>model_url</strong>: <a href=\"https://shop.edfenergy.com/Item.aspx?id=547\">https://shop.edfenergy.com/Item.aspx?id=547</a></li><li><strong>sample_period</strong>: 6</li><li><strong>seller</strong>: EDF Energy</li><li><strong>site_meter</strong>: True</li><li><strong>wireless</strong>: True</li><li><strong>wireless_configuration</strong>: <ul><li><strong>base</strong>: creators: [Jack Kelly] model: rfm_edf_ecomanager model_url: <a href=\"https://github.com/JackKelly/rfm_edf_ecomanager/\">https://github.com/JackKelly/rfm_edf_ecomanager/</a>\n",
       "</li><li><strong>protocol</strong>: custom</li><li><strong>carrier_frequency</strong>: 434</li></ul></li></ul></li><li><strong>EcoManagerTxPlug</strong>: <ul><li><strong>brand</strong>: EcoManager</li><li><strong>brand_url</strong>: <a href=\"http://www.edfenergy.com/products-services/for-your-home/ecomanager\">http://www.edfenergy.com/products-services/for-your-home/ecomanager</a></li><li><strong>data_logger</strong>: <ul><li><strong>creators</strong>: <ul><li>Jack Kelly</li></ul></li><li><strong>model</strong>: rfm_ecomanager_logger</li><li><strong>model_url</strong>: <a href=\"https://github.com/JackKelly/rfm_ecomanager_logger\">https://github.com/JackKelly/rfm_ecomanager_logger</a></li></ul></li><li><strong>manufacturer</strong>: Current Cost / Sailwider</li><li><strong>max_sample_period</strong>: 120</li><li><strong>measurements</strong>: <ul><li>{'upper_limit': 3300, 'lower_limit': 0, 'physical_quantity': 'power', 'type': 'active'}</li></ul></li><li><strong>model</strong>: EcoManagerTxPlug</li><li><strong>model_url</strong>: <a href=\"https://shop.edfenergy.com/Item.aspx?id=540\">https://shop.edfenergy.com/Item.aspx?id=540</a></li><li><strong>sample_period</strong>: 6</li><li><strong>seller</strong>: EDF Energy</li><li><strong>wireless</strong>: True</li><li><strong>wireless_configuration</strong>: <ul><li><strong>base</strong>: creators: [Jack Kelly] model: rfm_edf_ecomanager model_url: <a href=\"https://github.com/JackKelly/rfm_edf_ecomanager/\">https://github.com/JackKelly/rfm_edf_ecomanager/</a>\n",
       "</li><li><strong>protocol</strong>: custom</li><li><strong>carrier_frequency</strong>: 434</li></ul></li></ul></li><li><strong>SoundCardPowerMeter</strong>: <ul><li><strong>manufacturer</strong>: Jack Kelly / Imperial College London</li><li><strong>max_sample_period</strong>: 3</li><li><strong>measurements</strong>: <ul><li>{'upper_limit': 25000, 'lower_limit': 0, 'physical_quantity': 'power', 'type': 'active'}</li><li>{'upper_limit': 25000, 'lower_limit': 0, 'physical_quantity': 'power', 'type': 'apparent'}</li><li>{'description': 'RMS voltage', 'upper_limit': 275, 'lower_limit': 180, 'physical_quantity': 'voltage'}</li></ul></li><li><strong>model</strong>: Sound Card Power Meter</li><li><strong>model_url</strong>: <a href=\"https://github.com/JackKelly/snd_card_power_meter\">https://github.com/JackKelly/snd_card_power_meter</a></li><li><strong>sample_period</strong>: 1</li><li><strong>wireless</strong>: False</li></ul></li></ul></li></ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ukdale = DataSet(arquivo_dataset_ukdale)\n",
    "print(\"NILMTK -> Detalhes sobre o dataset UK-DALE:\")\n",
    "print_dict(ukdale.metadata)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANTE:** O fine-tuning do modelo foi realizado utilizando como dados:\n",
    "\n",
    "1. Base REDD: `30 dias iniciais` de medições de cada aparelho de interesseo;\n",
    "2. Base UK-DALE: `60 dias iniciais` de registros de cada aparelho de interesse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melhores Combinações de Taxas e Janelas para cada Aparelho (estudo 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T15:31:22.951748Z",
     "start_time": "2021-05-02T15:31:22.923787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carga</th>\n",
       "      <th>taxa_amostragem</th>\n",
       "      <th>janela</th>\n",
       "      <th>loss</th>\n",
       "      <th>acuracia</th>\n",
       "      <th>precisao</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dish_washer - 9</td>\n",
       "      <td>2</td>\n",
       "      <td>720</td>\n",
       "      <td>0.05</td>\n",
       "      <td>95.33</td>\n",
       "      <td>20.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>22.22</td>\n",
       "      <td>59.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fridge - 7</td>\n",
       "      <td>2</td>\n",
       "      <td>1080</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>microwave - 16</td>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>0.04</td>\n",
       "      <td>95.83</td>\n",
       "      <td>66.67</td>\n",
       "      <td>33.33</td>\n",
       "      <td>44.44</td>\n",
       "      <td>71.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>washer_dryer - 13</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.89</td>\n",
       "      <td>100.00</td>\n",
       "      <td>95.74</td>\n",
       "      <td>97.83</td>\n",
       "      <td>98.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>washer_dryer - 14</td>\n",
       "      <td>3</td>\n",
       "      <td>360</td>\n",
       "      <td>0.02</td>\n",
       "      <td>97.99</td>\n",
       "      <td>100.00</td>\n",
       "      <td>55.56</td>\n",
       "      <td>71.43</td>\n",
       "      <td>85.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               carga  taxa_amostragem  janela  loss  acuracia  precisao  \\\n",
       "0    dish_washer - 9                2     720  0.05     95.33     20.00   \n",
       "1         fridge - 7                2    1080  0.00    100.00    100.00   \n",
       "2     microwave - 16                2     900  0.04     95.83     66.67   \n",
       "3  washer_dryer - 13                2      60  0.00     99.89    100.00   \n",
       "4  washer_dryer - 14                3     360  0.02     97.99    100.00   \n",
       "\n",
       "   recall      f1  f1_macro  \n",
       "0   25.00   22.22     59.91  \n",
       "1  100.00  100.00    100.00  \n",
       "2   33.33   44.44     71.14  \n",
       "3   95.74   97.83     98.88  \n",
       "4   55.56   71.43     85.19  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_melhores_taxas_janelas = pd.read_csv(os.path.join(caminho_dados, \"19\", \"melhores_taxa_janela_aparelhos.csv\"), index_col=0)\n",
    "df_melhores_taxas_janelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T15:31:22.967651Z",
     "start_time": "2021-05-02T15:31:22.953690Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# - Desenvolver módulo da metodologia na lib PyNILM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros de RP dos Aparelhos (estudo 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T15:31:22.983611Z",
     "start_time": "2021-05-02T15:31:22.969647Z"
    }
   },
   "outputs": [],
   "source": [
    "# Carregando arquivos de parametros, caso n estejam (kernel reiniciado)\n",
    "if not 'parametros_rp_aparelho' in locals():\n",
    "    with open(os.path.join(caminho_dados, \"18\", \"parametros_rp_aparelho.json\"),'r') as arquivo:\n",
    "        parametros_rp_aparelho = json.load(arquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambiente e Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T15:31:25.948700Z",
     "start_time": "2021-05-02T15:31:22.984607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "# from PyNILM.dados.janelas import Janelas\n",
    "from PyNILM.dados.janelas import Janelas\n",
    "from PyNILM.dados.utils import *\n",
    "\n",
    "from PyNILM.avaliacao.metricas import *\n",
    "from PyNILM.avaliacao.graficos import *\n",
    "from PyNILM.avaliacao.analises import *\n",
    "\n",
    "from PyNILM.modelos.utils import *\n",
    "from PyNILM.modelos.dlafe import DLAFE\n",
    "from PyNILM.modelos.rqa import RQA\n",
    "\n",
    "# Inicializar uso GPU\n",
    "start_tf_session(memory_limit=int(1024*4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurações do Experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T15:31:26.340544Z",
     "start_time": "2021-05-02T15:31:25.952689Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "\n",
    "# aparelhos = [\n",
    "#     'dish_washer - 9',\n",
    "#     'fridge - 7',\n",
    "#     'microwave - 16',\n",
    "#     'washer_dryer - 13', \n",
    "#     'washer_dryer - 14'\n",
    "# ]\n",
    "\n",
    "TAXA = 2 # Fixa\n",
    "\n",
    "# IMPORTANTE: Agora o modelo extrator será o pre-treinado\n",
    "# modelo_extrator = transfer_learning.vgg16.VGG16(\n",
    "#             weights='imagenet', \n",
    "#             include_top=False,\n",
    "#             pooling='avg'\n",
    "#         )\n",
    "preprocessamento_extrator = transfer_learning.vgg16.preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://notebook.community/jaduimstra/nilmtk/docs/manual/user_guide/elecmeter_and_metergroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Gerando janelas para cada canal/aparelho...\n",
      "Residencia: Building(instance=3, dataset='REDD')\n",
      "Consumo aparelho sockets: de 2011-05-16 01:11:30-04:00 a 2011-05-30 20:19:36-04:00 | (639243,)\n"
     ]
    }
   ],
   "source": [
    "atraso_inicial = 30\n",
    "periodo = 30\n",
    "\n",
    "residencia = redd.buildings[RESIDENCIA]\n",
    "\n",
    "# Gerar janelas para cada canal/aparelho\n",
    "print(\"* Gerando janelas para cada canal/aparelho...\")\n",
    "\n",
    "# inicio_intervalo =  datetime.strptime(inicio_intervalo, '%Y-%m-%d %H:%M:%S').date()\n",
    "# fim_intervalo = datetime.strptime(fim_intervalo, '%Y-%m-%d %H:%M:%S').date()\n",
    "print('Residencia:', residencia)\n",
    "\n",
    "for e in residencia.elec.all_meters():\n",
    "\n",
    "    # Selecionando canal/aparelho\n",
    "    # e = self.residencia.elec[e_i]\n",
    "\n",
    "    # Normalizar nome aparelho/canal de medicao\n",
    "    aparelho = e.label().lower().replace(\" \", \"_\")\n",
    "\n",
    "    # if not any(map(aparelho.__contains__, aparelhos.keys())) or 'site_meter' in aparelho:\n",
    "    #     continue\n",
    "\n",
    "    tamanho_janela = 1080\n",
    "\n",
    "    # # Extraindo medicoes de energia da carga\n",
    "    # power = np.array(e.power_series_all_data(sample_period=taxa_amostral).values[:limite_serie])\n",
    "    \n",
    "    # Extraindo medicoes de energia da carga (toda a serie)\n",
    "    consumo_aparelho = e.power_series_all_data(sample_period=TAXA).replace(np.nan, 0) # Remover nan (por zero)\n",
    "\n",
    "    # Definindo periodo/janela de analise (consumo individual e agregado)\n",
    "    if aparelho not in 'site_meter':\n",
    "        inicio_periodo = consumo_aparelho.index[0] + timedelta(days=atraso_inicial)\n",
    "        fim_periodo = inicio_periodo + timedelta(days=atraso_inicial+periodo)\n",
    "        \n",
    "        # Selecionando periodo no consumo do aparelho\n",
    "        indices_aparelho = consumo_aparelho.index.to_pydatetime()\n",
    "        consumo_aparelho = consumo_aparelho[(indices_aparelho >= inicio_periodo) & (indices_aparelho <= fim_periodo)]\n",
    "        print(f'Consumo aparelho {aparelho}: de', inicio_periodo, 'a', consumo_aparelho.index[-1],  '|', consumo_aparelho.shape)\n",
    "    \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_dados(\n",
    "    base, taxa_amostral=2, \n",
    "    atraso_inicial=0, periodo=30, \n",
    "    residencias=None, aparelhos=None, \n",
    "    estatisticas=False, metadados=False, \n",
    "    debug=False):\n",
    "    \"\"\"\n",
    "    Função para carregar e preparar as janelas de consumo e ativações dos aparelhos em diferentes residenciais de um dataset.\n",
    "\n",
    "    Retorno:\n",
    "        dados (list): lista com as informações (janelas e metadados) dos aparelhos de interesse.\n",
    "    \"\"\"\n",
    "    dados = []\n",
    "\n",
    "    for r in base.buildings:\n",
    "        \n",
    "        if residencias and r not in residencias:\n",
    "            continue\n",
    "\n",
    "        if debug: print(f\"> Processando residência #{r}...\")\n",
    "        \n",
    "        # dados[b] = {\n",
    "        #     'medidores': [],\n",
    "        #     'aparelhos': []\n",
    "\n",
    "        # }\n",
    "\n",
    "        # Consumo agregado da residencia (serie historica)\n",
    "        # if debug: print(\"* Extraindo dados de consumo agregado da residencia...\")\n",
    "        consumo_agregado = carregar_dados_consumo_agregado(\n",
    "            base, taxa_amostral=taxa_amostral, residencia=r, debug=debug)\n",
    "        indices_agregado = consumo_agregado.index.to_pydatetime()\n",
    "        if debug: print(f'  - Consumo agregado: de', consumo_agregado.index[0], 'a', consumo_agregado.index[-1])\n",
    "\n",
    "        residencia = base.buildings[r]\n",
    "\n",
    "        # Gerar janelas para cada canal/aparelho\n",
    "        if debug: print(\"* Gerando janelas para cada canal/aparelho...\")\n",
    "\n",
    "        # inicio_intervalo =  datetime.strptime(inicio_intervalo, '%Y-%m-%d %H:%M:%S').date()\n",
    "        # fim_intervalo = datetime.strptime(fim_intervalo, '%Y-%m-%d %H:%M:%S').date()\n",
    "        if debug: print('Residencia:', residencia)\n",
    "        \n",
    "        for e in residencia.elec.all_meters():\n",
    "\n",
    "            # Selecionando canal/aparelho\n",
    "            # e = self.residencia.elec[e_i]\n",
    "\n",
    "            # Normalizar nome aparelho/canal de medicao\n",
    "            aparelho = e.label().lower().replace(\" \", \"_\")\n",
    "\n",
    "            if not any(map(aparelho.__contains__, aparelhos.keys())) or 'site_meter' in aparelho:\n",
    "                continue\n",
    "\n",
    "            tamanho_janela = 1080\n",
    "            if aparelhos:\n",
    "                for k, v in aparelhos.items():\n",
    "                    if k in aparelho:\n",
    "                        tamanho_janela = v\n",
    "                        break\n",
    "\n",
    "            try:\n",
    "\n",
    "                # # Extraindo medicoes de energia da carga\n",
    "                # power = np.array(e.power_series_all_data(sample_period=taxa_amostral).values[:limite_serie])\n",
    "                \n",
    "                # Extraindo medicoes de energia da carga (toda a serie)\n",
    "                consumo_aparelho = e.power_series_all_data(sample_period=taxa_amostral).replace(np.nan, 0) # Remover nan (por zero)\n",
    "\n",
    "                # Definindo periodo/janela de analise (consumo individual e agregado)\n",
    "                if aparelho not in 'site_meter':\n",
    "                    inicio_periodo = consumo_aparelho.index[0] + timedelta(days=atraso_inicial)\n",
    "                    fim_periodo = inicio_periodo + timedelta(days=atraso_inicial+periodo)\n",
    "                    \n",
    "                    # Selecionando periodo no consumo do aparelho\n",
    "                    indices_aparelho = consumo_aparelho.index.to_pydatetime()\n",
    "                    consumo_aparelho = consumo_aparelho[(indices_aparelho >= inicio_periodo) & (indices_aparelho <= fim_periodo)]\n",
    "                    if debug: print(f'Consumo aparelho {aparelho}: de', inicio_periodo, 'a', consumo_aparelho.index[-1], \n",
    "                                '|', consumo_aparelho.shape, \n",
    "                                '>>>', consumo_agregado.values.min(), consumo_agregado.values.max(),\n",
    "                                    consumo_agregado.values.mean(), consumo_agregado.values.std())\n",
    "\n",
    "                    # Selecionando periodo no consumo agregado (mesmo range de analise para as janelas)\n",
    "                    consumo_agregado_aparelho = consumo_agregado[(indices_agregado >= inicio_periodo) & (indices_agregado <= fim_periodo)]\n",
    "                    if debug: \n",
    "                        print(f'  - Consumo agregado/aparelho: de ', consumo_agregado_aparelho.index[0], 'a', consumo_agregado_aparelho.index[-1],\n",
    "                                '|', consumo_agregado_aparelho.shape, \n",
    "                                '>>>', consumo_agregado_aparelho.values.min(), consumo_agregado_aparelho.values.max(),\n",
    "                                    consumo_agregado_aparelho.values.mean(), consumo_agregado_aparelho.values.std())\n",
    "                        print(f'  - Shapes sincronizados?', consumo_agregado_aparelho.shape == consumo_aparelho.shape)\n",
    "\n",
    "                    # print(' -', aparelho, '=', inicio_periodo, 'a', fim_periodo, '|', tamanho_janela )\n",
    "\n",
    "                    # TODO: dividir em janelas com indices -> np.array_split(dados, dados.shape[0] // (720 - 1))\n",
    "                    \n",
    "                    # Calculando tamanho máximo da série (padding, dependendo tamanho janeka)\n",
    "                    limite_serie = int(len(consumo_aparelho.values) / tamanho_janela) * tamanho_janela\n",
    "\n",
    "                    # Garantindo limite da serie valido (caber dentro do reshape do tamanho janela)\n",
    "                    while limite_serie % tamanho_janela != 0:\n",
    "                        limite_serie -= 1\n",
    "                    \n",
    "                    # Encaixando medicao dentro do tamanho de janelas (p/ fazer reshape)\n",
    "                    # power = power.values[:limite_serie]\n",
    "                    consumo_aparelho = consumo_aparelho.iloc[:limite_serie]\n",
    "                    consumo_agregado_aparelho = consumo_agregado_aparelho.iloc[:limite_serie]\n",
    "\n",
    "                    # Gerando máscara de status (ativo ou não), considerando ruido da carga\n",
    "                    # ou rede na medição (threshod)\n",
    "                    # status = power > e.on_power_threshold()\n",
    "                    ativacoes = (consumo_aparelho >= e.on_power_threshold()).astype(int)\n",
    "\n",
    "                    # # Dividindo em janelas (consumo energetico individual e agregado, bem como ativacoes)\n",
    "                    # windows_series = power.reshape(-1, tamanho_janela)\n",
    "                    # windows_status = status.reshape(-1, tamanho_janela)\n",
    "                    # janelas_aparelho = np.array_split(consumo_aparelho, consumo_aparelho.shape[0] // (tamanho_janela - 1))\n",
    "                    janelas_consumo_aparelho = np.vstack(\n",
    "                        np.array_split(\n",
    "                            consumo_aparelho, \n",
    "                            consumo_aparelho.shape[0] // tamanho_janela\n",
    "                        )\n",
    "                    )\n",
    "                    janelas_agregado_aparelho = np.vstack(\n",
    "                        np.array_split(\n",
    "                            consumo_agregado_aparelho, \n",
    "                            consumo_agregado_aparelho.shape[0] // tamanho_janela\n",
    "                        )\n",
    "                    )\n",
    "                    janelas_ativacoes = np.vstack(\n",
    "                        np.array_split(\n",
    "                            ativacoes, \n",
    "                            ativacoes.shape[0] // tamanho_janela\n",
    "                            )\n",
    "                    )\n",
    "\n",
    "                    # # # Remover nan (por zero)\n",
    "                    # # windows_series = np.nan_to_num(windows_series)\n",
    "\n",
    "                    # # Extraindo ativacoes\n",
    "                    # windows_status = np.where(\n",
    "                    #     np.sum(windows_status, axis=1) > 0, 1, 0\n",
    "                    # )  # Estado de cada janela, baseado na pré-avaliação da serie\n",
    "                    ativacao_por_janela = []\n",
    "                    for w in janelas_ativacoes:\n",
    "                        ativacao_por_janela.append(1 if w.sum() > 0 else 0)\n",
    "                    \n",
    "\n",
    "                    # #     # Calcular rotulos a partir das janelas\n",
    "                    # #     # Podendo ser:\n",
    "                    # #     #   - `estado` (denotando carga ATIVA [1] ou INATIVA [0]);\n",
    "                    # #     #   - `total`(soma da janela);\n",
    "                    # #     #   - `media`;\n",
    "                    # #     rotulos = {\n",
    "                    # #         \"total\": np.sum(windows_series, axis=1),\n",
    "                    # #         \"media\": np.mean(windows_series, axis=1),\n",
    "                    # #         \"estado\": np.where(\n",
    "                    # #             np.sum(windows_status, axis=1) > 0, 1, 0\n",
    "                    # #         )  # Estado de cada janela, baseado na pré-avaliação da serie\n",
    "                    # #         # completa, considerando ruido\n",
    "                    # #     }\n",
    "\n",
    "                    d = {\n",
    "                        \"aparelho\": aparelho,\n",
    "                        \"instancia\": e.instance(),\n",
    "                        \"residencia\": r,\n",
    "                        \"janelas\": janelas_agregado_aparelho,\n",
    "                        \"consumo\": janelas_consumo_aparelho,\n",
    "                        \"status\": np.array(ativacao_por_janela)\n",
    "                        }\n",
    "\n",
    "                    if estatisticas:\n",
    "                        d[\"estatisticas\"] = {\n",
    "                            \"status\": dict(Counter(ativacao_por_janela)),\n",
    "                            # TODO: validar integridade das janelas (mesmo tamanho) e conversao das janelas para np.array (np.vstack)\n",
    "                            \"consumo_por_janela\": {\n",
    "                                \"min\": janelas_agregado_aparelho.sum(axis=1).min(),\n",
    "                                \"max\": janelas_agregado_aparelho.sum(axis=1).max(),\n",
    "                                \"mean\": janelas_agregado_aparelho.sum(axis=1).mean(),\n",
    "                                \"std\": janelas_agregado_aparelho.sum(axis=1).std()\n",
    "                            },\n",
    "                            \"consumo_historico_aparelho\": {\n",
    "                                \"min\": consumo_aparelho.min(),\n",
    "                                \"max\": consumo_aparelho.max(),\n",
    "                                \"mean\": consumo_aparelho.mean(),\n",
    "                                \"std\": consumo_aparelho.std()\n",
    "                            }\n",
    "                        }\n",
    "                    \n",
    "                    if metadados:\n",
    "                        d[\"metadata\"] = e.metadata\n",
    "\n",
    "                    dados.append(d)\n",
    "\n",
    "                    # TODO: Sincronizar medidor e aparelho (indices)\n",
    "\n",
    "                    #     if self.debug: print(f\"{aparelho} -> {windows_series.shape}\")\n",
    "\n",
    "            except Exception as ex:\n",
    "                if debug: print(f\"{aparelho}-{e.instance()}: erro ao extrair dados -> {str(ex)}\")\n",
    "                # return {\n",
    "                #         \"aparelho\": aparelho,\n",
    "                #         \"instancia\": e.instance(),\n",
    "                #         \"residencia\": r,\n",
    "                #         \"janelas\": janelas_agregado_aparelho,\n",
    "                #         \"consumo\": consumo_aparelho,\n",
    "                #         \"status\": np.array(ativacao_por_janela)\n",
    "                #         }\n",
    "                \n",
    "    return dados\n",
    "\n",
    "def carregar_dados_consumo_agregado(base, taxa_amostral=2, residencia=1, debug=False):\n",
    "    # Consumo agregado = potencia aparente\n",
    "    # COnsumo individual = potencia ativa\n",
    "    dados = []\n",
    "\n",
    "    for b in base.buildings:\n",
    "            \n",
    "        if b != residencia:\n",
    "            continue\n",
    "\n",
    "        residencia = base.buildings[b]\n",
    "\n",
    "        # Gerar janelas para cada canal/aparelho\n",
    "        if debug: print(\"* Extraindo consumo agregado dos medidores...\")\n",
    "\n",
    "        # inicio_intervalo =  datetime.strptime(inicio_intervalo, '%Y-%m-%d %H:%M:%S').date()\n",
    "        # fim_intervalo = datetime.strptime(fim_intervalo, '%Y-%m-%d %H:%M:%S').date()\n",
    "        if debug: print('Residencia:', residencia)\n",
    "        \n",
    "        for e in residencia.elec.all_meters():\n",
    "\n",
    "            # Selecionando canal/aparelho\n",
    "            # e = self.residencia.elec[e_i]\n",
    "\n",
    "            # Normalizar nome aparelho/canal de medicao\n",
    "            aparelho = e.label().lower().replace(\" \", \"_\")\n",
    "\n",
    "            if aparelho != 'site_meter':\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "\n",
    "                # # Extraindo medicoes de energia da carga\n",
    "                # power = np.array(e.power_series_all_data(sample_period=taxa_amostral).values[:limite_serie])\n",
    "                \n",
    "                # Extraindo medicoes de energia da carga (toda a serie)\n",
    "                consumo = e.power_series_all_data(sample_period=taxa_amostral)\n",
    "\n",
    "                # Remover nan (por zero)\n",
    "                consumo = consumo.replace(np.nan, 0)\n",
    "\n",
    "                dados.append({\n",
    "                    \"rotulo\": aparelho,\n",
    "                    \"instancia\": e.instance(),\n",
    "                    \"consumo\": consumo\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                if debug: print(f\"{aparelho}: erro ao extrair dados -> {str(e)}\")\n",
    "\n",
    "    consumo_agregado = pd.concat([c['consumo'] for c in dados], axis=1).sum(1, min_count=1).fillna(0)\n",
    "\n",
    "    return consumo_agregado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_tipo_aparelho(\n",
    "    aparelho, \n",
    "    tipos = {\n",
    "        'dish_washer': 'dish washer',\n",
    "        'fridge': 'fridge',\n",
    "        'fridge_freezer': 'fridge',\n",
    "        'microwave': 'microwave',\n",
    "        'washer_dryer': 'washer_dryer',\n",
    "        'washing_machine': 'washing_machine'\n",
    "    }):\n",
    "    if not any(map(aparelho.__contains__, aparelhos.keys())) or 'site_meter' in aparelho:\n",
    "        return None\n",
    "    else:\n",
    "        return tipos[aparelho]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "from PyNILM.dados.utils import *\n",
    "from PyNILM.modelos.utils import *\n",
    "from pyts.image import RecurrencePlot\n",
    "\n",
    "def converter_serie_para_rp(\n",
    "    serie,\n",
    "    input_shape=TAMANHO_IMAGEM_DLAFE,\n",
    "    data_type=np.float32,\n",
    "    normalize=False, \n",
    "    standardize=False, \n",
    "    rescale=False,\n",
    "    # persistir=True,\n",
    "    # deletar_arquivo_amostra=True\n",
    "    ):\n",
    "    \"\"\"Função de pré-processamento tf.data\"\"\"\n",
    "    # Carregando janelas de consumo (X) e estados da carga (y)\n",
    "    \n",
    "    # import os\n",
    "    # import numpy as np\n",
    "    # from pathlib import Path\n",
    "    # from pyts.image import RecurrencePlot\n",
    "    \n",
    "    # X = np.load(amostra).astype(data_type)\n",
    "    # y = np.int8(Path(str(amostra)).stem.split('-')[-1])\n",
    "\n",
    "    # Transformando janela de consumo em imagem RP\n",
    "    img = RecurrencePlot(**PARAMETROS_RP).fit_transform([serie])[0]\n",
    "    img = cv2.resize(\n",
    "            img, \n",
    "            dsize=input_shape[:2], \n",
    "            interpolation=cv2.INTER_CUBIC\n",
    "        ).astype(data_type)\n",
    "\n",
    "    if np.sum(img) > 0:\n",
    "        # TODO: improve fit/predict statistics\n",
    "        # Normalizar\n",
    "        if normalize:\n",
    "            img = (img - img.min()) / (img.max() - img.min()) # MinMax (0,1)\n",
    "            #img = (img - img.mean()) / np.max([img.std(), 1e-4])\n",
    "\n",
    "        # Padronizar\n",
    "        elif standardize:\n",
    "            img = (img - img.mean())/img.std()#tf.image.per_image_standardization(img).numpy()\n",
    "            \n",
    "        elif rescale:\n",
    "            img = (img - img.min()) / (img.max() - img.min())\n",
    "\n",
    "    # N canais\n",
    "    X_rp = np.stack([img for _ in range(input_shape[-1])],axis=-1).astype(data_type)  \n",
    "\n",
    "    return X_rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Processando residência #1...\n",
      "* Extraindo consumo agregado dos medidores...\n",
      "Residencia: Building(instance=1, dataset='UK-DALE')\n",
      "  - Consumo agregado: de 2012-11-09 22:28:14+00:00 a 2015-01-05 06:27:12+00:00\n",
      "* Gerando janelas para cada canal/aparelho...\n",
      "Residencia: Building(instance=1, dataset='UK-DALE')\n",
      "Consumo aparelho washer_dryer: de 2013-01-08 22:28:18+00:00 a 2013-05-08 23:28:18+01:00 | (5184001,) >>> 0.0 16442.965 613.57794 826.2863\n",
      "  - Consumo agregado/aparelho: de  2013-01-08 22:28:18+00:00 a 2013-05-08 23:28:18+01:00 | (5184001,) >>> 0.0 12559.26 461.54785 708.40137\n",
      "  - Shapes sincronizados? True\n",
      "Consumo aparelho dish_washer: de 2013-01-08 22:28:18+00:00 a 2013-05-08 23:28:18+01:00 | (5184001,) >>> 0.0 16442.965 613.57794 826.2863\n",
      "  - Consumo agregado/aparelho: de  2013-01-08 22:28:18+00:00 a 2013-05-08 23:28:18+01:00 | (5184001,) >>> 0.0 12559.26 461.54785 708.40137\n",
      "  - Shapes sincronizados? True\n",
      "Consumo aparelho fridge_freezer: de 2013-02-12 22:21:32+00:00 a 2013-06-12 23:21:32+01:00 | (5184001,) >>> 0.0 16442.965 613.57794 826.2863\n",
      "  - Consumo agregado/aparelho: de  2013-02-12 22:21:32+00:00 a 2013-06-12 23:21:32+01:00 | (5184001,) >>> 0.0 13843.055 581.7395 766.9331\n",
      "  - Shapes sincronizados? True\n",
      "Consumo aparelho microwave: de 2013-02-12 22:21:32+00:00 a 2013-06-12 23:21:32+01:00 | (5184001,) >>> 0.0 16442.965 613.57794 826.2863\n",
      "  - Consumo agregado/aparelho: de  2013-02-12 22:21:32+00:00 a 2013-06-12 23:21:32+01:00 | (5184001,) >>> 0.0 13843.055 581.7395 766.9331\n",
      "  - Shapes sincronizados? True\n",
      "> Processando residência #2...\n",
      "* Extraindo consumo agregado dos medidores...\n",
      "Residencia: Building(instance=2, dataset='UK-DALE')\n",
      "  - Consumo agregado: de 2013-02-17 16:17:34+00:00 a 2013-10-10 06:16:00+01:00\n",
      "* Gerando janelas para cada canal/aparelho...\n",
      "Residencia: Building(instance=2, dataset='UK-DALE')\n",
      "Consumo aparelho washing_machine: de 2013-07-19 22:28:38+01:00 a 2013-10-10 06:15:20+01:00 | (3556402,) >>> 0.0 16529.0 465.20947 785.4045\n",
      "  - Consumo agregado/aparelho: de  2013-07-19 22:28:38+01:00 a 2013-10-10 06:16:00+01:00 | (3556422,) >>> 0.0 10869.825 403.7626 746.31104\n",
      "  - Shapes sincronizados? False\n",
      "Consumo aparelho dish_washer: de 2013-07-19 22:28:38+01:00 a 2013-10-10 06:15:20+01:00 | (3556402,) >>> 0.0 16529.0 465.20947 785.4045\n",
      "  - Consumo agregado/aparelho: de  2013-07-19 22:28:38+01:00 a 2013-10-10 06:16:00+01:00 | (3556422,) >>> 0.0 10869.825 403.7626 746.31104\n",
      "  - Shapes sincronizados? False\n",
      "Consumo aparelho fridge: de 2013-07-19 22:28:38+01:00 a 2013-10-10 06:15:26+01:00 | (3556405,) >>> 0.0 16529.0 465.20947 785.4045\n",
      "  - Consumo agregado/aparelho: de  2013-07-19 22:28:38+01:00 a 2013-10-10 06:16:00+01:00 | (3556422,) >>> 0.0 10869.825 403.7626 746.31104\n",
      "  - Shapes sincronizados? False\n",
      "Consumo aparelho microwave: de 2013-07-19 22:28:38+01:00 a 2013-10-10 06:15:26+01:00 | (3556405,) >>> 0.0 16529.0 465.20947 785.4045\n",
      "  - Consumo agregado/aparelho: de  2013-07-19 22:28:38+01:00 a 2013-10-10 06:16:00+01:00 | (3556422,) >>> 0.0 10869.825 403.7626 746.31104\n",
      "  - Shapes sincronizados? False\n",
      "> Processando residência #3...\n",
      "* Extraindo consumo agregado dos medidores...\n",
      "Residencia: Building(instance=3, dataset='UK-DALE')\n",
      "  - Consumo agregado: de 2013-02-27 20:35:14+00:00 a 2013-04-08 06:14:52+01:00\n",
      "* Gerando janelas para cada canal/aparelho...\n",
      "Residencia: Building(instance=3, dataset='UK-DALE')\n",
      "> Processando residência #4...\n",
      "* Extraindo consumo agregado dos medidores...\n",
      "Residencia: Building(instance=4, dataset='UK-DALE')\n",
      "  - Consumo agregado: de 2013-03-09 14:40:06+00:00 a 2013-10-01 06:15:06+01:00\n",
      "* Gerando janelas para cada canal/aparelho...\n",
      "Residencia: Building(instance=4, dataset='UK-DALE')\n",
      "Consumo aparelho washing_machine: de 2013-05-08 15:40:12+01:00 a 2013-09-05 15:40:12+01:00 | (5184001,) >>> 0.0 8765.0 323.5873 489.5542\n",
      "  - Consumo agregado/aparelho: de  2013-05-08 15:40:12+01:00 a 2013-09-05 15:40:12+01:00 | (5184001,) >>> 0.0 8765.0 223.11342 404.89386\n",
      "  - Shapes sincronizados? True\n",
      "> Processando residência #5...\n",
      "* Extraindo consumo agregado dos medidores...\n",
      "Residencia: Building(instance=5, dataset='UK-DALE')\n",
      "  - Consumo agregado: de 2014-06-29 17:23:42+01:00 a 2014-11-13 20:35:24+00:00\n",
      "* Gerando janelas para cada canal/aparelho...\n",
      "Residencia: Building(instance=5, dataset='UK-DALE')\n",
      "Consumo aparelho fridge_freezer: de 2014-08-28 17:23:50+01:00 a 2014-11-13 17:58:00+00:00 | (3329226,) >>> 0.0 18060.52 1213.3657 1108.9354\n",
      "  - Consumo agregado/aparelho: de  2014-08-28 17:23:50+01:00 a 2014-11-13 20:35:24+00:00 | (3333948,) >>> 0.0 18060.52 1149.4054 1146.3502\n",
      "  - Shapes sincronizados? False\n",
      "Consumo aparelho dish_washer: de 2014-08-28 17:23:56+01:00 a 2014-11-13 18:00:02+00:00 | (3329284,) >>> 0.0 18060.52 1213.3657 1108.9354\n",
      "  - Consumo agregado/aparelho: de  2014-08-28 17:23:56+01:00 a 2014-11-13 20:35:24+00:00 | (3333945,) >>> 0.0 18060.52 1149.4042 1146.3502\n",
      "  - Shapes sincronizados? False\n",
      "Consumo aparelho microwave: de 2014-08-28 17:23:56+01:00 a 2014-11-13 17:55:14+00:00 | (3329140,) >>> 0.0 18060.52 1213.3657 1108.9354\n",
      "  - Consumo agregado/aparelho: de  2014-08-28 17:23:56+01:00 a 2014-11-13 20:35:24+00:00 | (3333945,) >>> 0.0 18060.52 1149.4042 1146.3502\n",
      "  - Shapes sincronizados? False\n",
      "Consumo aparelho washer_dryer: de 2014-08-28 17:23:56+01:00 a 2014-11-13 17:57:26+00:00 | (3329206,) >>> 0.0 18060.52 1213.3657 1108.9354\n",
      "  - Consumo agregado/aparelho: de  2014-08-28 17:23:56+01:00 a 2014-11-13 20:35:24+00:00 | (3333945,) >>> 0.0 18060.52 1149.4042 1146.3502\n",
      "  - Shapes sincronizados? False\n"
     ]
    }
   ],
   "source": [
    "# Periodo em dias para o estudo\n",
    "PERIODO = 60\n",
    "\n",
    "# Consolidando dados ukdale (pré-treino)\n",
    "dados_ukdale = carregar_dados(\n",
    "    ukdale,  \n",
    "    atraso_inicial=PERIODO, # Contemplar dados nao vistos durante fine-tuning\n",
    "    periodo=PERIODO,\n",
    "    residencias=None,\n",
    "    aparelhos={\n",
    "        'microwave': 900, \n",
    "        'dish': 720, \n",
    "        'washer_dryer': 360, \n",
    "        'washing_machine': 360, \n",
    "        'fridge': 1080\n",
    "        },\n",
    "    estatisticas=False,\n",
    "    metadados=False,\n",
    "    debug=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Processando residência #1...\n",
      "* Extraindo consumo agregado dos medidores...\n",
      "Residencia: Building(instance=1, dataset='REDD')\n",
      "  - Consumo agregado: de 2011-04-18 09:22:08-04:00 a 2011-05-24 15:57:02-04:00\n",
      "* Gerando janelas para cada canal/aparelho...\n",
      "Residencia: Building(instance=1, dataset='REDD')\n",
      "Consumo aparelho fridge: de 2011-05-18 09:22:12-04:00 a 2011-05-24 15:56:34-04:00 | (271032,) >>> 0.0 11870.33 192.70941 584.5038\n",
      "  - Consumo agregado/aparelho: de  2011-05-18 09:22:12-04:00 a 2011-05-24 15:57:02-04:00 | (271046,) >>> 0.0 7344.645 173.13284 643.75323\n",
      "  - Shapes sincronizados? False\n",
      "Consumo aparelho dish_washer: de 2011-05-18 09:22:12-04:00 a 2011-05-24 15:56:34-04:00 | (271032,) >>> 0.0 11870.33 192.70941 584.5038\n",
      "  - Consumo agregado/aparelho: de  2011-05-18 09:22:12-04:00 a 2011-05-24 15:57:02-04:00 | (271046,) >>> 0.0 7344.645 173.13284 643.75323\n",
      "  - Shapes sincronizados? False\n",
      "Consumo aparelho microwave: de 2011-05-18 09:22:12-04:00 a 2011-05-24 15:56:34-04:00 | (271032,) >>> 0.0 11870.33 192.70941 584.5038\n",
      "  - Consumo agregado/aparelho: de  2011-05-18 09:22:12-04:00 a 2011-05-24 15:57:02-04:00 | (271046,) >>> 0.0 7344.645 173.13284 643.75323\n",
      "  - Shapes sincronizados? False\n",
      "> Processando residência #2...\n",
      "* Extraindo consumo agregado dos medidores...\n",
      "Residencia: Building(instance=2, dataset='REDD')\n",
      "  - Consumo agregado: de 2011-04-17 19:18:26-04:00 a 2011-05-22 19:59:16-04:00\n",
      "* Gerando janelas para cada canal/aparelho...\n",
      "Residencia: Building(instance=2, dataset='REDD')\n",
      "Consumo aparelho microwave: de 2011-05-18 01:31:40-04:00 a 2011-05-22 19:59:08-04:00 | (206025,) >>> 0.0 3241.075 91.8629 198.89578\n",
      "  - Consumo agregado/aparelho: de  2011-05-18 01:31:40-04:00 a 2011-05-22 19:59:16-04:00 | (206029,) >>> 0.0 778.66 5.779887 40.1798\n",
      "  - Shapes sincronizados? False\n",
      "Consumo aparelho fridge: de 2011-05-18 01:31:40-04:00 a 2011-05-22 19:59:08-04:00 | (206025,) >>> 0.0 3241.075 91.8629 198.89578\n",
      "  - Consumo agregado/aparelho: de  2011-05-18 01:31:40-04:00 a 2011-05-22 19:59:16-04:00 | (206029,) >>> 0.0 778.66 5.779887 40.1798\n",
      "  - Shapes sincronizados? False\n",
      "Consumo aparelho dish_washer: de 2011-05-18 01:31:40-04:00 a 2011-05-22 19:59:08-04:00 | (206025,) >>> 0.0 3241.075 91.8629 198.89578\n",
      "  - Consumo agregado/aparelho: de  2011-05-18 01:31:40-04:00 a 2011-05-22 19:59:16-04:00 | (206029,) >>> 0.0 778.66 5.779887 40.1798\n",
      "  - Shapes sincronizados? False\n",
      "> Processando residência #3...\n",
      "* Extraindo consumo agregado dos medidores...\n",
      "Residencia: Building(instance=3, dataset='REDD')\n",
      "  - Consumo agregado: de 2011-04-16 01:11:26-04:00 a 2011-05-30 20:19:54-04:00\n",
      "* Gerando janelas para cada canal/aparelho...\n",
      "Residencia: Building(instance=3, dataset='REDD')\n",
      "Consumo aparelho fridge: de 2011-05-16 01:11:30-04:00 a 2011-05-30 20:19:36-04:00 | (639244,) >>> 0.0 7864.84 169.71799 500.4053\n",
      "  - Consumo agregado/aparelho: de  2011-05-16 01:11:30-04:00 a 2011-05-30 20:19:54-04:00 | (639253,) >>> 0.0 7613.465 206.8014 572.342\n",
      "  - Shapes sincronizados? False\n",
      "Consumo aparelho dish_washer: de 2011-05-16 01:11:30-04:00 a 2011-05-30 20:19:36-04:00 | (639244,) >>> 0.0 7864.84 169.71799 500.4053\n",
      "  - Consumo agregado/aparelho: de  2011-05-16 01:11:30-04:00 a 2011-05-30 20:19:54-04:00 | (639253,) >>> 0.0 7613.465 206.8014 572.342\n",
      "  - Shapes sincronizados? False\n",
      "Consumo aparelho microwave: de 2011-05-16 01:11:30-04:00 a 2011-05-30 20:19:36-04:00 | (639244,) >>> 0.0 7864.84 169.71799 500.4053\n",
      "  - Consumo agregado/aparelho: de  2011-05-16 01:11:30-04:00 a 2011-05-30 20:19:54-04:00 | (639253,) >>> 0.0 7613.465 206.8014 572.342\n",
      "  - Shapes sincronizados? False\n",
      "> Processando residência #4...\n",
      "* Extraindo consumo agregado dos medidores...\n",
      "Residencia: Building(instance=4, dataset='REDD')\n",
      "  - Consumo agregado: de 2011-04-16 21:16:18-04:00 a 2011-06-03 20:45:44-04:00\n",
      "* Gerando janelas para cada canal/aparelho...\n",
      "Residencia: Building(instance=4, dataset='REDD')\n",
      "Consumo aparelho dish_washer: de 2011-05-16 21:16:32-04:00 a 2011-06-03 20:45:38-04:00 | (776674,) >>> 0.0 3593.345 142.36928 264.6693\n",
      "  - Consumo agregado/aparelho: de  2011-05-16 21:16:32-04:00 a 2011-06-03 20:45:44-04:00 | (776677,) >>> 0.0 2507.2449 94.36634 169.6459\n",
      "  - Shapes sincronizados? False\n",
      "> Processando residência #5...\n",
      "* Extraindo consumo agregado dos medidores...\n",
      "Residencia: Building(instance=5, dataset='REDD')\n",
      "  - Consumo agregado: de 2011-04-18 00:24:02-04:00 a 2011-05-31 20:20:20-04:00\n",
      "* Gerando janelas para cada canal/aparelho...\n",
      "Residencia: Building(instance=5, dataset='REDD')\n",
      "Consumo aparelho microwave: de 2011-05-18 00:24:06-04:00 a 2011-05-31 20:20:14-04:00 | (597485,) >>> 0.0 12291.36 52.869717 337.93918\n",
      "  - Consumo agregado/aparelho: de  2011-05-18 00:24:06-04:00 a 2011-05-31 20:20:20-04:00 | (597488,) >>> 0.0 12291.36 122.50082 566.5721\n",
      "  - Shapes sincronizados? False\n",
      "Consumo aparelho fridge: de 2011-05-18 00:24:06-04:00 a 2011-05-31 20:20:14-04:00 | (597485,) >>> 0.0 12291.36 52.869717 337.93918\n",
      "  - Consumo agregado/aparelho: de  2011-05-18 00:24:06-04:00 a 2011-05-31 20:20:20-04:00 | (597488,) >>> 0.0 12291.36 122.50082 566.5721\n",
      "  - Shapes sincronizados? False\n",
      "Consumo aparelho dish_washer: de 2011-05-18 00:24:06-04:00 a 2011-05-31 20:20:14-04:00 | (597485,) >>> 0.0 12291.36 52.869717 337.93918\n",
      "  - Consumo agregado/aparelho: de  2011-05-18 00:24:06-04:00 a 2011-05-31 20:20:20-04:00 | (597488,) >>> 0.0 12291.36 122.50082 566.5721\n",
      "  - Shapes sincronizados? False\n",
      "> Processando residência #6...\n",
      "* Extraindo consumo agregado dos medidores...\n",
      "Residencia: Building(instance=6, dataset='REDD')\n",
      "  - Consumo agregado: de 2011-05-21 15:39:18-04:00 a 2011-06-14 01:31:44-04:00\n",
      "* Gerando janelas para cada canal/aparelho...\n",
      "Residencia: Building(instance=6, dataset='REDD')\n",
      "fridge-8: erro ao extrair dados -> index -1 is out of bounds for axis 0 with size 0\n",
      "dish_washer-9: erro ao extrair dados -> index -1 is out of bounds for axis 0 with size 0\n"
     ]
    }
   ],
   "source": [
    "# Exportando base de teste (redd)\n",
    "dados_redd = carregar_dados(\n",
    "    redd,  \n",
    "    atraso_inicial=30,\n",
    "    periodo=30,\n",
    "    residencias=None,\n",
    "    aparelhos={\n",
    "        'microwave': 900, \n",
    "        'dish': 720, \n",
    "        'washer dryer': 360, \n",
    "        'washing machine': 360, \n",
    "        'fridge': 1080\n",
    "        },\n",
    "    estatisticas=False,\n",
    "    metadados=False,\n",
    "    debug=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Apagando registros\n",
    "# if dados_ukdale: del dados_ukdale\n",
    "# if dados_redd: del dados_redd\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design Experimental\n",
    "---\n",
    "\n",
    "Pré-treinar os modelos com base nos dados de UK-DALE e testar com dados REDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "washer_dryer 5 (14400, 360)\n",
      "dish_washer 6 (7200, 720)\n",
      "fridge_freezer 12 (4800, 1080)\n",
      "microwave 13 (5760, 900)\n",
      "washing_machine 12 (9878, 360)\n",
      "dish_washer 13 (4939, 720)\n",
      "fridge 14 (3292, 1080)\n",
      "microwave 15 (3951, 900)\n",
      "washing_machine 6 (14400, 360)\n",
      "fridge_freezer 19 (3082, 1080)\n",
      "dish_washer 22 (4624, 720)\n",
      "microwave 23 (3699, 900)\n",
      "washer_dryer 24 (9247, 360)\n"
     ]
    }
   ],
   "source": [
    "for d in dados_ukdale:\n",
    "    print(d['aparelho'], d['instancia'], d['janelas'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fridge 5 (250, 1080)\n",
      "dish_washer 6 (376, 720)\n",
      "microwave 11 (301, 900)\n",
      "microwave 6 (228, 900)\n",
      "fridge 9 (190, 1080)\n",
      "dish_washer 10 (286, 720)\n",
      "fridge 7 (591, 1080)\n",
      "dish_washer 9 (887, 720)\n",
      "microwave 16 (710, 900)\n",
      "dish_washer 15 (1078, 720)\n",
      "microwave 3 (663, 900)\n",
      "fridge 18 (553, 1080)\n",
      "dish_washer 20 (829, 720)\n"
     ]
    }
   ],
   "source": [
    "for d in dados_redd:\n",
    "    print(d['aparelho'], d['instancia'], d['janelas'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metodologia DLAFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Teste da classe\n",
    "janelas_treino = Janelas(\n",
    "    base=DataSet(arquivo_dataset_redd),\n",
    "    id_residencia=3,\n",
    "    inicio_intervalo='2011-04-16 00:00:00',\n",
    "    fim_intervalo='2011-05-16 23:59:59',\n",
    "    debug = False\n",
    ")\n",
    "\n",
    "janelas_teste = Janelas(\n",
    "    base=DataSet(arquivo_dataset_redd),\n",
    "    id_residencia=3,\n",
    "    inicio_intervalo='2011-05-17 00:00:00',\n",
    "    fim_intervalo='2011-05-30 23:59:59',\n",
    "    debug = False\n",
    ")\n",
    "\n",
    "aparelhos = [\n",
    "    'dish_washer - 9',\n",
    "    'fridge - 7',\n",
    "    'microwave - 16',\n",
    "    'washer_dryer - 13', \n",
    "    'washer_dryer - 14'\n",
    "]\n",
    "\n",
    "TAXA = 2 # Fixa\n",
    "\n",
    "modelo_extrator = transfer_learning.vgg16.VGG16(\n",
    "            weights='imagenet', \n",
    "            include_top=False,\n",
    "            pooling='avg'\n",
    "        )\n",
    "preprocessamento_extrator = transfer_learning.vgg16.preprocess_input\n",
    "\n",
    "def carregar_modelo_pretreinado(\n",
    "    aparelho,\n",
    "    caminho_modelos_salvos=r'H:\\Meu Drive\\phd-thesis\\datasets\\transfer-learning\\periodo-60\\modelos_salvos',\n",
    "    debug=False):\n",
    "    from glob import glob\n",
    "\n",
    "    caminho_modelo = glob(os.path.join(caminho_modelos_salvos, f'*{aparelho[:4]}*-final*'))[0]\n",
    "    if debug: print('Modelo persistido no arquivo:', caminho_modelo)\n",
    "\n",
    "    modelo = tf.keras.models.load_model(caminho_modelo)\n",
    "    # return modelo\n",
    "    return tf.keras.models.Model(\n",
    "        modelo.input, \n",
    "        modelo.layers[-2].output\n",
    "        )\n",
    "\n",
    "    # Removendo camadas adicionais (extra-vgg16), incluidas no fine-tuning\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste de carregamento de modelo pré-treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dish_washer - 9\n"
     ]
    }
   ],
   "source": [
    "for rotulo_aparelho in aparelhos:\n",
    "    \n",
    "    print(rotulo_aparelho)#, glob(os.path.join(caminho_modelos_pretreinados, f'*{rotulo_aparelho[:4]}*-final*')) )\n",
    "    modelo = carregar_modelo_pretreinado(rotulo_aparelho)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 1, 1, 512)         14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T15:52:09.652081Z",
     "start_time": "2021-05-02T15:31:26.669113Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Aparelho `dish_washer - 9`...\n",
      "\n",
      "   - Base de TREINO\n",
      "\n",
      "     -> Carregando dados (taxa=2, janela=720)...\n",
      "Loading data for meter ElecMeterID(instance=14, building=3, dataset='REDD')     \n",
      "Done loading data all meters for this chunk.\n",
      "\n",
      "     -> Detalhes da amostragem (lotes):\n",
      "     ---\n",
      "        - Classe `0`: 623 amostras (97.5%)\n",
      "        - Classe `1`: 16 amostras (2.5%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 10 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d959a694954f7f99d51b359a84a742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "modelo = SVC(kernel='rbf', random_state=SEED)\n",
    "\n",
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \n",
    "    \"base\": []\n",
    "}\n",
    "\n",
    "for rotulo_aparelho in aparelhos:\n",
    "    \n",
    "    print(f\"* Aparelho `{rotulo_aparelho}`...\\n\")\n",
    "\n",
    "    # MOdelo extrator pré-treinado para aparelho\n",
    "    modelo_extrator = carregar_modelo_pretreinado(rotulo_aparelho)\n",
    "    \n",
    "    # Informacoes da carga selecionada\n",
    "    CARGA = rotulo_aparelho.split(\" - \")[0]\n",
    "    INSTANCIA = int(rotulo_aparelho.split(\" - \")[1])\n",
    "    config_aparelho = df_melhores_taxas_janelas[\n",
    "        df_melhores_taxas_janelas[\"carga\"]==rotulo_aparelho\n",
    "    ].to_dict(\"records\")[0]\n",
    "    TAMANHO_JANELA = config_aparelho[\"janela\"]\n",
    "\n",
    "    #######################################################################\n",
    "    #                AVALIACAO 1 - Base de treino / CV                    #\n",
    "    #######################################################################\n",
    "    # Extrair series divididas em janelas para cada medidor\n",
    "    print(\"   - Base de TREINO\\n\")\n",
    "    print(\"     -> Carregando dados (taxa={:.0f}, janela={:.0f})...\".format(\n",
    "        TAXA, TAMANHO_JANELA\n",
    "    ))\n",
    "    X, y = carregar_dados_aparelho(\n",
    "        janelas=janelas_treino,\n",
    "        instancia=INSTANCIA,\n",
    "        aparelho=CARGA,\n",
    "        tamanho_janela=TAMANHO_JANELA,\n",
    "        taxa=TAXA,\n",
    "        eliminar_janelas_vazias=True\n",
    "    )\n",
    "    print(\"     -> Detalhes da amostragem (lotes):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y).items():\n",
    "        print(f\"        - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y)*100,1)}%)\" )\n",
    "    print()\n",
    "    \n",
    "    y_true, y_pred  = [], []\n",
    "\n",
    "    print(f\"     -> Avaliando modelo (CV - {skf.n_splits} folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in tqdm_notebook(enumerate(skf.split(X, y)), total=skf.n_splits):\n",
    "\n",
    "        # Preparando lotes\n",
    "        X_treino, X_teste = X[idx_treino], X[idx_teste]\n",
    "        y_treino, y_teste = y[idx_treino], y[idx_teste]\n",
    "\n",
    "        # Treinando modelo\n",
    "        dlafe = DLAFE(\n",
    "            feature_extractor=modelo_extrator,\n",
    "            preprocess_input=preprocessamento_extrator,\n",
    "            classifier=clone(modelo),\n",
    "            rp_params = PARAMETROS_RP,\n",
    "            input_shape = modelo_extrator.input_shape[1:], # TAMANHO_IMAGEM_DLAFE,\n",
    "            normalize=False\n",
    "        )\n",
    "        dlafe.fit(X_treino, y_treino)\n",
    "\n",
    "        # Prevendo conjunto de teste\n",
    "        y_hat = dlafe.predict(X_teste)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"treino\")\n",
    "        \n",
    "        reset_tf_session(model_name='dlafe')\n",
    "\n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true.extend(y_teste)\n",
    "        y_pred.extend(y_hat)\n",
    "        \n",
    "    #######################################################################\n",
    "    #                 AVALIACAO 2 - Base de teste / CV                    #\n",
    "    #######################################################################\n",
    "    print(\"   - Base de TESTE\\n\")\n",
    "    print(\"     -> Carregando dados (taxa={:.0f}, janela={:.0f})...\".format(\n",
    "        TAXA, TAMANHO_JANELA\n",
    "    ))\n",
    "\n",
    "    # Avaliar na base de teste\n",
    "    X_teste, y_teste = carregar_dados_aparelho(\n",
    "        janelas=janelas_teste,\n",
    "        instancia=INSTANCIA,\n",
    "        aparelho=CARGA,\n",
    "        tamanho_janela=TAMANHO_JANELA,\n",
    "        taxa=TAXA,\n",
    "        eliminar_janelas_vazias=True\n",
    "    )\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem (lotes):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_teste).items():\n",
    "        print(f\"       - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_teste)*100,1)}%)\" )\n",
    "    print()\n",
    "\n",
    "    # Treinando modelo\n",
    "    dlafe = DLAFE(\n",
    "        feature_extractor=modelo_extrator,\n",
    "        preprocess_input=preprocessamento_extrator,\n",
    "        classifier=clone(modelo),\n",
    "        rp_params = PARAMETROS_RP,\n",
    "        input_shape = TAMANHO_IMAGEM_DLAFE,\n",
    "        normalize=False\n",
    "    )\n",
    "    dlafe.fit(X, y)\n",
    "\n",
    "    # Prevendo conjunto de teste\n",
    "    y_hat = dlafe.predict(X_teste)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "    resultados_modelo[\"fold\"].append(it+1)\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"teste\")\n",
    "    \n",
    "    reset_tf_session(model_name='dlafe')\n",
    "    \n",
    "    print()\n",
    "    print(\"   - Final Results:\")\n",
    "    print(\"   ---\")\n",
    "    print()\n",
    "    \n",
    "    print(\"***** TRAIN *****\")\n",
    "    print(\"      -> Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"      -> Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print()\n",
    "    \n",
    "    print(\"***** TEST *****\")\n",
    "    print(\"      -> Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_teste, y_hat))\n",
    "    print(\"      -> Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_teste, y_hat))\n",
    "    print()\n",
    "    \n",
    "# Consolidating DataFrame\n",
    "df_resultados = pd.DataFrame(resultados_modelo)\n",
    "df_resultados.to_excel(os.path.join(caminho_dados_notebook, \"df_resultados_svm.xlsx\"))\n",
    "    \n",
    "print(\"############################## FINAL MODEL RESULTS ##############################\")\n",
    "display(df_resultados.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T19:59:41.720698Z",
     "start_time": "2020-08-31T19:59:41.680673Z"
    }
   },
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T15:52:09.666828Z",
     "start_time": "2021-05-02T15:52:09.659062Z"
    }
   },
   "outputs": [],
   "source": [
    "def pos_weight(y):\n",
    "    try:\n",
    "        counter = Counter(y)\n",
    "        return counter[0]/counter[1]\n",
    "    except:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T16:13:07.455616Z",
     "start_time": "2021-05-02T15:52:09.670455Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Aparelho `dish_washer - 9`...\n",
      "\n",
      "   - Base de TREINO\n",
      "\n",
      "     -> Carregando dados (taxa=2, janela=720)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "     -> Detalhes da amostragem (lotes):\n",
      "     ---\n",
      "        - Classe `0`: 623 amostras (97.5%)\n",
      "        - Classe `1`: 16 amostras (2.5%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 10 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7371e1164b9341818b42f9d5988eaa6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:52:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:52:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:52:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:52:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:52:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:53:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:53:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:53:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:53:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:53:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "   - Base de TESTE\n",
      "\n",
      "     -> Carregando dados (taxa=2, janela=720)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "     -> Detalhes da amostragem (lotes):\n",
      "     ---\n",
      "       - Classe `0`: 395 amostras (96.8%)\n",
      "       - Classe `1`: 13 amostras (3.2%)\n",
      "\n",
      "[12:53:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "***** TRAIN *****\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       623\n",
      "           1       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.97       639\n",
      "   macro avg       0.49      0.50      0.49       639\n",
      "weighted avg       0.95      0.97      0.96       639\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[622   1]\n",
      " [ 16   0]]\n",
      "\n",
      "***** TEST *****\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       395\n",
      "           1       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.97       408\n",
      "   macro avg       0.48      0.50      0.49       408\n",
      "weighted avg       0.94      0.97      0.95       408\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[395   0]\n",
      " [ 13   0]]\n",
      "\n",
      "* Aparelho `fridge - 7`...\n",
      "\n",
      "   - Base de TREINO\n",
      "\n",
      "     -> Carregando dados (taxa=2, janela=1080)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "     -> Detalhes da amostragem (lotes):\n",
      "     ---\n",
      "        - Classe `1`: 425 amostras (99.5%)\n",
      "        - Classe `0`: 2 amostras (0.5%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 10 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da38de429294d46a7c66da1ae9725c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:54:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:54:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:54:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:54:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:54:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:54:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:54:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:55:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:55:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:55:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "   - Base de TESTE\n",
      "\n",
      "     -> Carregando dados (taxa=2, janela=1080)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "     -> Detalhes da amostragem (lotes):\n",
      "     ---\n",
      "       - Classe `1`: 269 amostras (98.2%)\n",
      "       - Classe `0`: 5 amostras (1.8%)\n",
      "\n",
      "[12:55:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "***** TRAIN *****\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       1.00      1.00      1.00       425\n",
      "\n",
      "    accuracy                           1.00       427\n",
      "   macro avg       0.50      0.50      0.50       427\n",
      "weighted avg       0.99      1.00      0.99       427\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[  0   2]\n",
      " [  0 425]]\n",
      "\n",
      "***** TEST *****\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.98      1.00      0.99       269\n",
      "\n",
      "    accuracy                           0.98       274\n",
      "   macro avg       0.49      0.50      0.50       274\n",
      "weighted avg       0.96      0.98      0.97       274\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[  0   5]\n",
      " [  0 269]]\n",
      "\n",
      "* Aparelho `microwave - 16`...\n",
      "\n",
      "   - Base de TREINO\n",
      "\n",
      "     -> Carregando dados (taxa=2, janela=900)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "     -> Detalhes da amostragem (lotes):\n",
      "     ---\n",
      "        - Classe `0`: 483 amostras (94.5%)\n",
      "        - Classe `1`: 28 amostras (5.5%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 10 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23864a19d4448939ca5272ddbb7d98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:55:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:55:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:56:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:56:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:56:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:56:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:56:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:56:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:56:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:56:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "   - Base de TESTE\n",
      "\n",
      "     -> Carregando dados (taxa=2, janela=900)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "     -> Detalhes da amostragem (lotes):\n",
      "     ---\n",
      "       - Classe `0`: 306 amostras (93.9%)\n",
      "       - Classe `1`: 20 amostras (6.1%)\n",
      "\n",
      "[12:57:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "***** TRAIN *****\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       483\n",
      "           1       0.67      0.36      0.47        28\n",
      "\n",
      "    accuracy                           0.95       511\n",
      "   macro avg       0.82      0.67      0.72       511\n",
      "weighted avg       0.95      0.95      0.95       511\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[478   5]\n",
      " [ 18  10]]\n",
      "\n",
      "***** TEST *****\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       306\n",
      "           1       0.73      0.55      0.63        20\n",
      "\n",
      "    accuracy                           0.96       326\n",
      "   macro avg       0.85      0.77      0.80       326\n",
      "weighted avg       0.96      0.96      0.96       326\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[302   4]\n",
      " [  9  11]]\n",
      "\n",
      "* Aparelho `washer_dryer - 13`...\n",
      "\n",
      "   - Base de TREINO\n",
      "\n",
      "     -> Carregando dados (taxa=2, janela=60)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "     -> Detalhes da amostragem (lotes):\n",
      "     ---\n",
      "        - Classe `0`: 7353 amostras (97.5%)\n",
      "        - Classe `1`: 187 amostras (2.5%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 10 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a0d303277d435a830a59df522ed82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:58:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[12:59:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[13:00:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[13:01:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[13:02:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[13:03:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[13:05:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[13:06:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[13:07:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[13:08:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "   - Base de TESTE\n",
      "\n",
      "     -> Carregando dados (taxa=2, janela=60)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "     -> Detalhes da amostragem (lotes):\n",
      "     ---\n",
      "       - Classe `0`: 4643 amostras (96.0%)\n",
      "       - Classe `1`: 192 amostras (4.0%)\n",
      "\n",
      "[13:09:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "***** TRAIN *****\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7353\n",
      "           1       0.99      0.95      0.97       187\n",
      "\n",
      "    accuracy                           1.00      7540\n",
      "   macro avg       0.99      0.97      0.98      7540\n",
      "weighted avg       1.00      1.00      1.00      7540\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[7351    2]\n",
      " [  10  177]]\n",
      "\n",
      "***** TEST *****\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4643\n",
      "           1       0.99      0.95      0.97       192\n",
      "\n",
      "    accuracy                           1.00      4835\n",
      "   macro avg       1.00      0.97      0.98      4835\n",
      "weighted avg       1.00      1.00      1.00      4835\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[4642    1]\n",
      " [  10  182]]\n",
      "\n",
      "* Aparelho `washer_dryer - 14`...\n",
      "\n",
      "   - Base de TREINO\n",
      "\n",
      "     -> Carregando dados (taxa=2, janela=360)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "     -> Detalhes da amostragem (lotes):\n",
      "     ---\n",
      "        - Classe `0`: 1216 amostras (95.7%)\n",
      "        - Classe `1`: 54 amostras (4.3%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 10 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c15bc88a1b47628222ce965598f29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:10:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[13:10:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[13:11:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[13:11:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[13:11:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[13:11:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[13:11:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[13:12:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[13:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "[13:12:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "   - Base de TESTE\n",
      "\n",
      "     -> Carregando dados (taxa=2, janela=360)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "     -> Detalhes da amostragem (lotes):\n",
      "     ---\n",
      "       - Classe `0`: 762 amostras (94.1%)\n",
      "       - Classe `1`: 48 amostras (5.9%)\n",
      "\n",
      "[13:12:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Virtual devices cannot be modified after being initialized\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "***** TRAIN *****\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1216\n",
      "           1       0.97      0.72      0.83        54\n",
      "\n",
      "    accuracy                           0.99      1270\n",
      "   macro avg       0.98      0.86      0.91      1270\n",
      "weighted avg       0.99      0.99      0.99      1270\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[1215    1]\n",
      " [  15   39]]\n",
      "\n",
      "***** TEST *****\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       762\n",
      "           1       1.00      0.79      0.88        48\n",
      "\n",
      "    accuracy                           0.99       810\n",
      "   macro avg       0.99      0.90      0.94       810\n",
      "weighted avg       0.99      0.99      0.99       810\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[762   0]\n",
      " [ 10  38]]\n",
      "\n",
      "############################## FINAL MODEL RESULTS ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dish_washer - 9</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.968137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.973413</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.493257</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.496063</td>\n",
       "      <td>0.492063</td>\n",
       "      <td>0.499206</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.492063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">fridge - 7</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.981752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.995349</td>\n",
       "      <td>0.009806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.898824</td>\n",
       "      <td>0.213299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">microwave - 16</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.960123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.960123</td>\n",
       "      <td>0.960123</td>\n",
       "      <td>0.803751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.803751</td>\n",
       "      <td>0.803751</td>\n",
       "      <td>0.768464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768464</td>\n",
       "      <td>0.768464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.955015</td>\n",
       "      <td>0.022662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.701603</td>\n",
       "      <td>0.178837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.479592</td>\n",
       "      <td>0.678189</td>\n",
       "      <td>0.167578</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.479592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">washer_dryer - 13</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.997725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997725</td>\n",
       "      <td>0.997725</td>\n",
       "      <td>0.984742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.984742</td>\n",
       "      <td>0.984742</td>\n",
       "      <td>0.973851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.973851</td>\n",
       "      <td>0.973851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.998408</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997347</td>\n",
       "      <td>0.982962</td>\n",
       "      <td>0.009378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969910</td>\n",
       "      <td>0.972817</td>\n",
       "      <td>0.018423</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">washer_dryer - 14</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.987654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.938601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.938601</td>\n",
       "      <td>0.938601</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.895833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.987402</td>\n",
       "      <td>0.007607</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976378</td>\n",
       "      <td>0.905937</td>\n",
       "      <td>0.066179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.779641</td>\n",
       "      <td>0.861257</td>\n",
       "      <td>0.089757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               acc                                      f1  \\\n",
       "                              mean       std       max       min      mean   \n",
       "appliance         base                                                       \n",
       "dish_washer - 9   teste   0.968137       NaN  0.968137  0.968137  0.491905   \n",
       "                  treino  0.973413  0.007508  0.984375  0.968750  0.493257   \n",
       "fridge - 7        teste   0.981752       NaN  0.981752  0.981752  0.495396   \n",
       "                  treino  0.995349  0.009806  1.000000  0.976744  0.898824   \n",
       "microwave - 16    teste   0.960123       NaN  0.960123  0.960123  0.803751   \n",
       "                  treino  0.955015  0.022662  1.000000  0.921569  0.701603   \n",
       "washer_dryer - 13 teste   0.997725       NaN  0.997725  0.997725  0.984742   \n",
       "                  treino  0.998408  0.000839  1.000000  0.997347  0.982962   \n",
       "washer_dryer - 14 teste   0.987654       NaN  0.987654  0.987654  0.938601   \n",
       "                  treino  0.987402  0.007607  1.000000  0.976378  0.905937   \n",
       "\n",
       "                                                             auc            \\\n",
       "                               std       max       min      mean       std   \n",
       "appliance         base                                                       \n",
       "dish_washer - 9   teste        NaN  0.491905  0.491905  0.500000       NaN   \n",
       "                  treino  0.001922  0.496063  0.492063  0.499206  0.002510   \n",
       "fridge - 7        teste        NaN  0.495396  0.495396  0.500000       NaN   \n",
       "                  treino  0.213299  1.000000  0.494118  0.500000  0.000000   \n",
       "microwave - 16    teste        NaN  0.803751  0.803751  0.768464       NaN   \n",
       "                  treino  0.178837  1.000000  0.479592  0.678189  0.167578   \n",
       "washer_dryer - 13 teste        NaN  0.984742  0.984742  0.973851       NaN   \n",
       "                  treino  0.009378  1.000000  0.969910  0.972817  0.018423   \n",
       "washer_dryer - 14 teste        NaN  0.938601  0.938601  0.895833       NaN   \n",
       "                  treino  0.066179  1.000000  0.779641  0.861257  0.089757   \n",
       "\n",
       "                                              \n",
       "                               max       min  \n",
       "appliance         base                        \n",
       "dish_washer - 9   teste   0.500000  0.500000  \n",
       "                  treino  0.500000  0.492063  \n",
       "fridge - 7        teste   0.500000  0.500000  \n",
       "                  treino  0.500000  0.500000  \n",
       "microwave - 16    teste   0.768464  0.768464  \n",
       "                  treino  1.000000  0.479592  \n",
       "washer_dryer - 13 teste   0.973851  0.973851  \n",
       "                  treino  1.000000  0.944444  \n",
       "washer_dryer - 14 teste   0.895833  0.895833  \n",
       "                  treino  1.000000  0.700000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo = XGBClassifier(random_state=SEED, n_jobs=4)\n",
    "\n",
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \n",
    "    \"base\": []\n",
    "}\n",
    "\n",
    "for rotulo_aparelho in aparelhos:\n",
    "    \n",
    "    print(f\"* Aparelho `{rotulo_aparelho}`...\\n\")\n",
    "    \n",
    "    # Informacoes da carga selecionada\n",
    "    CARGA = rotulo_aparelho.split(\" - \")[0]\n",
    "    INSTANCIA = int(rotulo_aparelho.split(\" - \")[1])\n",
    "    config_aparelho = df_melhores_taxas_janelas[\n",
    "        df_melhores_taxas_janelas[\"carga\"]==rotulo_aparelho\n",
    "    ].to_dict(\"records\")[0]\n",
    "    TAMANHO_JANELA = config_aparelho[\"janela\"]\n",
    "\n",
    "    #######################################################################\n",
    "    #                AVALIACAO 1 - Base de treino / CV                    #\n",
    "    #######################################################################\n",
    "    # Extrair series divididas em janelas para cada medidor\n",
    "    print(\"   - Base de TREINO\\n\")\n",
    "    print(\"     -> Carregando dados (taxa={:.0f}, janela={:.0f})...\".format(\n",
    "        TAXA, TAMANHO_JANELA\n",
    "    ))\n",
    "    X, y = carregar_dados_aparelho(\n",
    "        janelas=janelas_treino,\n",
    "        instancia=INSTANCIA,\n",
    "        aparelho=CARGA,\n",
    "        tamanho_janela=TAMANHO_JANELA,\n",
    "        taxa=TAXA,\n",
    "        eliminar_janelas_vazias=True\n",
    "    )\n",
    "    print(\"     -> Detalhes da amostragem (lotes):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y).items():\n",
    "        print(f\"        - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y)*100,1)}%)\" )\n",
    "    print()\n",
    "    \n",
    "    y_true, y_pred  = [], []\n",
    "\n",
    "    print(f\"     -> Avaliando modelo (CV - {skf.n_splits} folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in tqdm_notebook(enumerate(skf.split(X, y)), total=skf.n_splits):\n",
    "\n",
    "        # Preparando lotes\n",
    "        X_treino, X_teste = X[idx_treino], X[idx_teste]\n",
    "        y_treino, y_teste = y[idx_treino], y[idx_teste]\n",
    "\n",
    "        # Treinando modelo\n",
    "        dlafe = DLAFE(\n",
    "            feature_extractor=modelo_extrator,\n",
    "            preprocess_input=preprocessamento_extrator,\n",
    "            classifier=clone(modelo),#.set_params(**{'scale_pos_weight': pos_weight(y)}),\n",
    "            rp_params = PARAMETROS_RP,\n",
    "            input_shape = modelo_extrator.input_shape[1:], #TAMANHO_IMAGEM_DLAFE,\n",
    "            normalize=False\n",
    "        )\n",
    "        dlafe.fit(X_treino, y_treino)\n",
    "\n",
    "        # Prevendo conjunto de teste\n",
    "        y_hat = dlafe.predict(X_teste)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"treino\")\n",
    "        \n",
    "        reset_tf_session(model_name='dlafe')\n",
    "\n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true.extend(y_teste)\n",
    "        y_pred.extend(y_hat)\n",
    "        \n",
    "    #######################################################################\n",
    "    #                 AVALIACAO 2 - Base de teste / CV                    #\n",
    "    #######################################################################\n",
    "    print(\"   - Base de TESTE\\n\")\n",
    "    print(\"     -> Carregando dados (taxa={:.0f}, janela={:.0f})...\".format(\n",
    "        TAXA, TAMANHO_JANELA\n",
    "    ))\n",
    "\n",
    "    # Avaliar na base de teste\n",
    "    X_teste, y_teste = carregar_dados_aparelho(\n",
    "        janelas=janelas_teste,\n",
    "        instancia=INSTANCIA,\n",
    "        aparelho=CARGA,\n",
    "        tamanho_janela=TAMANHO_JANELA,\n",
    "        taxa=TAXA,\n",
    "        eliminar_janelas_vazias=True\n",
    "    )\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem (lotes):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_teste).items():\n",
    "        print(f\"       - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_teste)*100,1)}%)\" )\n",
    "    print()\n",
    "\n",
    "    # Treinando modelo\n",
    "    dlafe = DLAFE(\n",
    "        feature_extractor=modelo_extrator,\n",
    "        preprocess_input=preprocessamento_extrator,\n",
    "        classifier=clone(modelo),#.set_params(**{'scale_pos_weight': pos_weight(y)}),\n",
    "        rp_params = PARAMETROS_RP,\n",
    "        input_shape = TAMANHO_IMAGEM_DLAFE,\n",
    "        normalize=False\n",
    "    )\n",
    "    dlafe.fit(X, y)\n",
    "\n",
    "    # Prevendo conjunto de teste\n",
    "    y_hat = dlafe.predict(X_teste)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "    resultados_modelo[\"fold\"].append(it+1)\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"teste\")\n",
    "    \n",
    "    reset_tf_session(model_name='dlafe')\n",
    "    \n",
    "    print()\n",
    "    print(\"   - Final Results:\")\n",
    "    print(\"   ---\")\n",
    "    print()\n",
    "    \n",
    "    print(\"***** TRAIN *****\")\n",
    "    print(\"      -> Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"      -> Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print()\n",
    "    \n",
    "    print(\"***** TEST *****\")\n",
    "    print(\"      -> Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_teste, y_hat))\n",
    "    print(\"      -> Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_teste, y_hat))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "# Consolidating DataFrame\n",
    "df_resultados = pd.DataFrame(resultados_modelo)\n",
    "df_resultados.to_excel(os.path.join(caminho_dados_notebook, \"df_resultados_xgboost.xlsx\"))\n",
    "    \n",
    "print(\"############################## FINAL MODEL RESULTS ##############################\")\n",
    "display(df_resultados.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T16:13:07.471525Z",
     "start_time": "2021-05-02T16:13:07.459549Z"
    }
   },
   "outputs": [],
   "source": [
    "def class_weight(y, debug=False):\n",
    "    \n",
    "    # Classes distribution\n",
    "    neg, pos = np.bincount(y)\n",
    "    total = neg + pos\n",
    "\n",
    "    # Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "    # The sum of the weights of all examples stays the same.\n",
    "    w_0 = (1 / neg)*(total)/2.0 \n",
    "    w_1 = (1 / pos)*(total)/2.0\n",
    "\n",
    "    class_weight = {0: w_0, 1: w_1}\n",
    "\n",
    "    print('Weight for class 0: {:.2f}'.format(w_0))\n",
    "    print('Weight for class 1: {:.2f}'.format(w_1))\n",
    "    \n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T16:13:07.581878Z",
     "start_time": "2021-05-02T16:13:07.473511Z"
    }
   },
   "outputs": [],
   "source": [
    "def mlp(\n",
    "    input_shape=TAMANHO_IMAGEM_DLAFE,\n",
    "    metrics=[\n",
    "        tf.keras.metrics.TruePositives(name='tp'),\n",
    "        tf.keras.metrics.FalsePositives(name='fp'),\n",
    "        tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "        tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "        tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "    ], \n",
    "    output_bias=None\n",
    "):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "        \n",
    "    model = keras.Sequential([\n",
    "      keras.layers.Dense(10, activation='relu', input_shape=input_shape),\n",
    "      # keras.layers.Dropout(0.5),\n",
    "      keras.layers.Dense(1, activation='sigmoid', bias_initializer=output_bias),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "      optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=metrics\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T16:36:13.046049Z",
     "start_time": "2021-05-02T16:13:07.584850Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Aparelho `dish_washer - 9`...\n",
      "\n",
      "   - Base de TREINO\n",
      "\n",
      "     -> Carregando dados (taxa=2, janela=720)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "     -> Detalhes da amostragem (lotes):\n",
      "     ---\n",
      "        - Classe `0`: 623 amostras (97.5%)\n",
      "        - Classe `1`: 16 amostras (2.5%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 10 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e78d9537ab4772b06352ea24cd08d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "   - Base de TESTE\n",
      "\n",
      "     -> Carregando dados (taxa=2, janela=720)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "     -> Detalhes da amostragem (lotes):\n",
      "     ---\n",
      "       - Classe `0`: 395 amostras (61.8%)\n",
      "       - Classe `1`: 13 amostras (2.0%)\n",
      "\n",
      "Virtual devices cannot be modified after being initialized\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "***** TRAIN *****\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       623\n",
      "           1       0.14      0.06      0.09        16\n",
      "\n",
      "    accuracy                           0.97       639\n",
      "   macro avg       0.56      0.53      0.54       639\n",
      "weighted avg       0.96      0.97      0.96       639\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[617   6]\n",
      " [ 15   1]]\n",
      "\n",
      "***** TEST *****\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       395\n",
      "           1       0.50      0.08      0.13        13\n",
      "\n",
      "    accuracy                           0.97       408\n",
      "   macro avg       0.74      0.54      0.56       408\n",
      "weighted avg       0.96      0.97      0.96       408\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[394   1]\n",
      " [ 12   1]]\n",
      "\n",
      "* Aparelho `fridge - 7`...\n",
      "\n",
      "   - Base de TREINO\n",
      "\n",
      "     -> Carregando dados (taxa=2, janela=1080)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "     -> Detalhes da amostragem (lotes):\n",
      "     ---\n",
      "        - Classe `1`: 425 amostras (99.5%)\n",
      "        - Classe `0`: 2 amostras (0.5%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 10 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7142a6c281d249ca98f76641bf03b572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "   - Base de TESTE\n",
      "\n",
      "     -> Carregando dados (taxa=2, janela=1080)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "     -> Detalhes da amostragem (lotes):\n",
      "     ---\n",
      "       - Classe `1`: 269 amostras (63.0%)\n",
      "       - Classe `0`: 5 amostras (1.2%)\n",
      "\n",
      "Virtual devices cannot be modified after being initialized\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "***** TRAIN *****\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       1.00      1.00      1.00       425\n",
      "\n",
      "    accuracy                           1.00       427\n",
      "   macro avg       1.00      0.75      0.83       427\n",
      "weighted avg       1.00      1.00      1.00       427\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[  1   1]\n",
      " [  0 425]]\n",
      "\n",
      "***** TEST *****\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.20      0.29         5\n",
      "           1       0.99      1.00      0.99       269\n",
      "\n",
      "    accuracy                           0.98       274\n",
      "   macro avg       0.74      0.60      0.64       274\n",
      "weighted avg       0.98      0.98      0.98       274\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[  1   4]\n",
      " [  1 268]]\n",
      "\n",
      "* Aparelho `microwave - 16`...\n",
      "\n",
      "   - Base de TREINO\n",
      "\n",
      "     -> Carregando dados (taxa=2, janela=900)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "     -> Detalhes da amostragem (lotes):\n",
      "     ---\n",
      "        - Classe `0`: 483 amostras (94.5%)\n",
      "        - Classe `1`: 28 amostras (5.5%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 10 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4ee8e208714c99834c26f4cb7c3110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "   - Base de TESTE\n",
      "\n",
      "     -> Carregando dados (taxa=2, janela=900)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "     -> Detalhes da amostragem (lotes):\n",
      "     ---\n",
      "       - Classe `0`: 306 amostras (59.9%)\n",
      "       - Classe `1`: 20 amostras (3.9%)\n",
      "\n",
      "Virtual devices cannot be modified after being initialized\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "***** TRAIN *****\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       483\n",
      "           1       0.50      0.43      0.46        28\n",
      "\n",
      "    accuracy                           0.95       511\n",
      "   macro avg       0.73      0.70      0.72       511\n",
      "weighted avg       0.94      0.95      0.94       511\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[471  12]\n",
      " [ 16  12]]\n",
      "\n",
      "***** TEST *****\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       306\n",
      "           1       0.79      0.55      0.65        20\n",
      "\n",
      "    accuracy                           0.96       326\n",
      "   macro avg       0.88      0.77      0.81       326\n",
      "weighted avg       0.96      0.96      0.96       326\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[303   3]\n",
      " [  9  11]]\n",
      "\n",
      "* Aparelho `washer_dryer - 13`...\n",
      "\n",
      "   - Base de TREINO\n",
      "\n",
      "     -> Carregando dados (taxa=2, janela=60)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "     -> Detalhes da amostragem (lotes):\n",
      "     ---\n",
      "        - Classe `0`: 7353 amostras (97.5%)\n",
      "        - Classe `1`: 187 amostras (2.5%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 10 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b41df3af83a4f8191beb8107722ff26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "   - Base de TESTE\n",
      "\n",
      "     -> Carregando dados (taxa=2, janela=60)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "     -> Detalhes da amostragem (lotes):\n",
      "     ---\n",
      "       - Classe `0`: 4643 amostras (61.6%)\n",
      "       - Classe `1`: 192 amostras (2.5%)\n",
      "\n",
      "Virtual devices cannot be modified after being initialized\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "***** TRAIN *****\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7353\n",
      "           1       0.91      0.89      0.90       187\n",
      "\n",
      "    accuracy                           1.00      7540\n",
      "   macro avg       0.95      0.94      0.95      7540\n",
      "weighted avg       1.00      1.00      1.00      7540\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[7337   16]\n",
      " [  21  166]]\n",
      "\n",
      "***** TEST *****\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4643\n",
      "           1       0.91      0.88      0.90       192\n",
      "\n",
      "    accuracy                           0.99      4835\n",
      "   macro avg       0.95      0.94      0.95      4835\n",
      "weighted avg       0.99      0.99      0.99      4835\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[4627   16]\n",
      " [  23  169]]\n",
      "\n",
      "* Aparelho `washer_dryer - 14`...\n",
      "\n",
      "   - Base de TREINO\n",
      "\n",
      "     -> Carregando dados (taxa=2, janela=360)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "     -> Detalhes da amostragem (lotes):\n",
      "     ---\n",
      "        - Classe `0`: 1216 amostras (95.7%)\n",
      "        - Classe `1`: 54 amostras (4.3%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 10 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3ca1f93a7847e2984afba1e3b43869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "Virtual devices cannot be modified after being initialized\n",
      "   - Base de TESTE\n",
      "\n",
      "     -> Carregando dados (taxa=2, janela=360)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "     -> Detalhes da amostragem (lotes):\n",
      "     ---\n",
      "       - Classe `0`: 762 amostras (60.0%)\n",
      "       - Classe `1`: 48 amostras (3.8%)\n",
      "\n",
      "Virtual devices cannot be modified after being initialized\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "***** TRAIN *****\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1216\n",
      "           1       0.74      0.48      0.58        54\n",
      "\n",
      "    accuracy                           0.97      1270\n",
      "   macro avg       0.86      0.74      0.78      1270\n",
      "weighted avg       0.97      0.97      0.97      1270\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[1207    9]\n",
      " [  28   26]]\n",
      "\n",
      "***** TEST *****\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       762\n",
      "           1       0.90      0.54      0.68        48\n",
      "\n",
      "    accuracy                           0.97       810\n",
      "   macro avg       0.93      0.77      0.83       810\n",
      "weighted avg       0.97      0.97      0.97       810\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[759   3]\n",
      " [ 22  26]]\n",
      "\n",
      "############################## FINAL MODEL RESULTS ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dish_washer - 9</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.968137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.558552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.558552</td>\n",
       "      <td>0.558552</td>\n",
       "      <td>0.537196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537196</td>\n",
       "      <td>0.537196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.967163</td>\n",
       "      <td>0.015508</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.524952</td>\n",
       "      <td>0.107013</td>\n",
       "      <td>0.829333</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.520200</td>\n",
       "      <td>0.081007</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.483871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">fridge - 7</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.981752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.638236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638236</td>\n",
       "      <td>0.638236</td>\n",
       "      <td>0.598141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.598141</td>\n",
       "      <td>0.598141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.997674</td>\n",
       "      <td>0.007354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.949412</td>\n",
       "      <td>0.159974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.158114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">microwave - 16</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.963190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.963190</td>\n",
       "      <td>0.963190</td>\n",
       "      <td>0.813821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813821</td>\n",
       "      <td>0.813821</td>\n",
       "      <td>0.770098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.770098</td>\n",
       "      <td>0.770098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.945173</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.696472</td>\n",
       "      <td>0.137656</td>\n",
       "      <td>0.894845</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.695918</td>\n",
       "      <td>0.129340</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.489796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">washer_dryer - 13</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.991934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991934</td>\n",
       "      <td>0.991934</td>\n",
       "      <td>0.946178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.946178</td>\n",
       "      <td>0.946178</td>\n",
       "      <td>0.938381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.938381</td>\n",
       "      <td>0.938381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.995093</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.997347</td>\n",
       "      <td>0.992042</td>\n",
       "      <td>0.948597</td>\n",
       "      <td>0.023468</td>\n",
       "      <td>0.973004</td>\n",
       "      <td>0.914629</td>\n",
       "      <td>0.942625</td>\n",
       "      <td>0.029441</td>\n",
       "      <td>0.973004</td>\n",
       "      <td>0.893376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">washer_dryer - 14</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.969136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.969136</td>\n",
       "      <td>0.969136</td>\n",
       "      <td>0.829561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.829561</td>\n",
       "      <td>0.829561</td>\n",
       "      <td>0.768865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768865</td>\n",
       "      <td>0.768865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.970866</td>\n",
       "      <td>0.011166</td>\n",
       "      <td>0.992126</td>\n",
       "      <td>0.952756</td>\n",
       "      <td>0.774468</td>\n",
       "      <td>0.101951</td>\n",
       "      <td>0.942404</td>\n",
       "      <td>0.632736</td>\n",
       "      <td>0.739631</td>\n",
       "      <td>0.116070</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.595902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               acc                                      f1  \\\n",
       "                              mean       std       max       min      mean   \n",
       "appliance         base                                                       \n",
       "dish_washer - 9   teste   0.968137       NaN  0.968137  0.968137  0.558552   \n",
       "                  treino  0.967163  0.015508  0.984375  0.937500  0.524952   \n",
       "fridge - 7        teste   0.981752       NaN  0.981752  0.981752  0.638236   \n",
       "                  treino  0.997674  0.007354  1.000000  0.976744  0.949412   \n",
       "microwave - 16    teste   0.963190       NaN  0.963190  0.963190  0.813821   \n",
       "                  treino  0.945173  0.022321  0.980392  0.901961  0.696472   \n",
       "washer_dryer - 13 teste   0.991934       NaN  0.991934  0.991934  0.946178   \n",
       "                  treino  0.995093  0.002259  0.997347  0.992042  0.948597   \n",
       "washer_dryer - 14 teste   0.969136       NaN  0.969136  0.969136  0.829561   \n",
       "                  treino  0.970866  0.011166  0.992126  0.952756  0.774468   \n",
       "\n",
       "                                                             auc            \\\n",
       "                               std       max       min      mean       std   \n",
       "appliance         base                                                       \n",
       "dish_washer - 9   teste        NaN  0.558552  0.558552  0.537196       NaN   \n",
       "                  treino  0.107013  0.829333  0.483871  0.520200  0.081007   \n",
       "fridge - 7        teste        NaN  0.638236  0.638236  0.598141       NaN   \n",
       "                  treino  0.159974  1.000000  0.494118  0.550000  0.158114   \n",
       "microwave - 16    teste        NaN  0.813821  0.813821  0.770098       NaN   \n",
       "                  treino  0.137656  0.894845  0.484848  0.695918  0.129340   \n",
       "washer_dryer - 13 teste        NaN  0.946178  0.946178  0.938381       NaN   \n",
       "                  treino  0.023468  0.973004  0.914629  0.942625  0.029441   \n",
       "washer_dryer - 14 teste        NaN  0.829561  0.829561  0.768865       NaN   \n",
       "                  treino  0.101951  0.942404  0.632736  0.739631  0.116070   \n",
       "\n",
       "                                              \n",
       "                               max       min  \n",
       "appliance         base                        \n",
       "dish_washer - 9   teste   0.537196  0.537196  \n",
       "                  treino  0.750000  0.483871  \n",
       "fridge - 7        teste   0.598141  0.598141  \n",
       "                  treino  1.000000  0.500000  \n",
       "microwave - 16    teste   0.770098  0.770098  \n",
       "                  treino  0.833333  0.489796  \n",
       "washer_dryer - 13 teste   0.938381  0.938381  \n",
       "                  treino  0.973004  0.893376  \n",
       "washer_dryer - 14 teste   0.768865  0.768865  \n",
       "                  treino  0.900000  0.595902  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo = MLPClassifier(alpha=1e-3, hidden_layer_sizes=(10,), random_state=SEED)\n",
    "\n",
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \n",
    "    \"base\": []\n",
    "}\n",
    "\n",
    "for rotulo_aparelho in aparelhos:\n",
    "    \n",
    "    print(f\"* Aparelho `{rotulo_aparelho}`...\\n\")\n",
    "    \n",
    "    # Informacoes da carga selecionada\n",
    "    CARGA = rotulo_aparelho.split(\" - \")[0]\n",
    "    INSTANCIA = int(rotulo_aparelho.split(\" - \")[1])\n",
    "    config_aparelho = df_melhores_taxas_janelas[\n",
    "        df_melhores_taxas_janelas[\"carga\"]==rotulo_aparelho\n",
    "    ].to_dict(\"records\")[0]\n",
    "    TAMANHO_JANELA = config_aparelho[\"janela\"]\n",
    "\n",
    "    #######################################################################\n",
    "    #                AVALIACAO 1 - Base de treino / CV                    #\n",
    "    #######################################################################\n",
    "    # Extrair series divididas em janelas para cada medidor\n",
    "    print(\"   - Base de TREINO\\n\")\n",
    "    print(\"     -> Carregando dados (taxa={:.0f}, janela={:.0f})...\".format(\n",
    "        TAXA, TAMANHO_JANELA\n",
    "    ))\n",
    "    X, y = carregar_dados_aparelho(\n",
    "        janelas=janelas_treino,\n",
    "        instancia=INSTANCIA,\n",
    "        aparelho=CARGA,\n",
    "        tamanho_janela=TAMANHO_JANELA,\n",
    "        taxa=TAXA,\n",
    "        eliminar_janelas_vazias=True\n",
    "    )\n",
    "    print(\"     -> Detalhes da amostragem (lotes):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y).items():\n",
    "        print(f\"        - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y)*100,1)}%)\" )\n",
    "    print()\n",
    "    \n",
    "    y_true, y_pred  = [], []\n",
    "\n",
    "    print(f\"     -> Avaliando modelo (CV - {skf.n_splits} folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in tqdm_notebook(enumerate(skf.split(X, y)), total=skf.n_splits):\n",
    "\n",
    "        # Preparando lotes\n",
    "        X_treino, X_teste = X[idx_treino], X[idx_teste]\n",
    "        y_treino, y_teste = y[idx_treino], y[idx_teste]\n",
    "\n",
    "        # Treinando modelo\n",
    "        dlafe = DLAFE(\n",
    "            feature_extractor=modelo_extrator,\n",
    "            preprocess_input=preprocessamento_extrator,\n",
    "            classifier=clone(modelo),\n",
    "            rp_params = PARAMETROS_RP,\n",
    "            input_shape = TAMANHO_IMAGEM_DLAFE,\n",
    "            normalize=False\n",
    "        )\n",
    "        dlafe.fit(X_treino, y_treino)\n",
    "\n",
    "        # Prevendo conjunto de teste\n",
    "        y_hat = dlafe.predict(X_teste)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"treino\")\n",
    "        \n",
    "        reset_tf_session(model_name='dlafe')\n",
    "\n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true.extend(y_teste)\n",
    "        y_pred.extend(y_hat)\n",
    "        \n",
    "    #######################################################################\n",
    "    #                 AVALIACAO 2 - Base de teste / CV                    #\n",
    "    #######################################################################\n",
    "    print(\"   - Base de TESTE\\n\")\n",
    "    print(\"     -> Carregando dados (taxa={:.0f}, janela={:.0f})...\".format(\n",
    "        TAXA, TAMANHO_JANELA\n",
    "    ))\n",
    "\n",
    "    # Avaliar na base de teste\n",
    "    X_teste, y_teste = carregar_dados_aparelho(\n",
    "        janelas=janelas_teste,\n",
    "        instancia=INSTANCIA,\n",
    "        aparelho=CARGA,\n",
    "        tamanho_janela=TAMANHO_JANELA,\n",
    "        taxa=TAXA,\n",
    "        eliminar_janelas_vazias=True\n",
    "    )\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem (lotes):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_teste).items():\n",
    "        print(f\"       - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y)*100,1)}%)\" )\n",
    "    print()\n",
    "\n",
    "    # Treinando modelo\n",
    "    dlafe = DLAFE(\n",
    "        feature_extractor=modelo_extrator,\n",
    "        preprocess_input=preprocessamento_extrator,\n",
    "        classifier=clone(modelo),\n",
    "        rp_params = PARAMETROS_RP,\n",
    "        input_shape = TAMANHO_IMAGEM_DLAFE,\n",
    "        normalize=False\n",
    "    )\n",
    "    dlafe.fit(X, y)\n",
    "\n",
    "    # Prevendo conjunto de teste\n",
    "    y_hat = dlafe.predict(X_teste)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "    resultados_modelo[\"fold\"].append(it+1)\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"teste\")\n",
    "    \n",
    "    reset_tf_session(model_name='dlafe')\n",
    "    \n",
    "    print()\n",
    "    print(\"   - Final Results:\")\n",
    "    print(\"   ---\")\n",
    "    print()\n",
    "    \n",
    "    print(\"***** TRAIN *****\")\n",
    "    print(\"      -> Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"      -> Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print()\n",
    "    \n",
    "    print(\"***** TEST *****\")\n",
    "    print(\"      -> Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_teste, y_hat))\n",
    "    print(\"      -> Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_teste, y_hat))\n",
    "    print()\n",
    "    \n",
    "# Consolidating DataFrame\n",
    "df_resultados = pd.DataFrame(resultados_modelo)\n",
    "df_resultados.to_excel(os.path.join(caminho_dados_notebook, \"df_resultados_mlp.xlsx\"))\n",
    "    \n",
    "print(\"############################## FINAL MODEL RESULTS ##############################\")\n",
    "display(df_resultados.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise dos Resultados (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T16:36:14.548200Z",
     "start_time": "2021-05-02T16:36:13.053030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Análise por modelo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBOOST</th>\n",
       "      <td>treino</td>\n",
       "      <td>0.981917</td>\n",
       "      <td>0.019850</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.217562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.479592</td>\n",
       "      <td>0.702294</td>\n",
       "      <td>0.209000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.479592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>treino</td>\n",
       "      <td>0.975194</td>\n",
       "      <td>0.023544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.778780</td>\n",
       "      <td>0.196613</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.689675</td>\n",
       "      <td>0.186874</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.483871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>treino</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.019488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.763340</td>\n",
       "      <td>0.231737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.675331</td>\n",
       "      <td>0.210834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>teste</td>\n",
       "      <td>0.974830</td>\n",
       "      <td>0.011760</td>\n",
       "      <td>0.991934</td>\n",
       "      <td>0.963190</td>\n",
       "      <td>0.757269</td>\n",
       "      <td>0.156339</td>\n",
       "      <td>0.946178</td>\n",
       "      <td>0.558552</td>\n",
       "      <td>0.722536</td>\n",
       "      <td>0.158763</td>\n",
       "      <td>0.938381</td>\n",
       "      <td>0.537196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBOOST</th>\n",
       "      <td>teste</td>\n",
       "      <td>0.979078</td>\n",
       "      <td>0.015062</td>\n",
       "      <td>0.997725</td>\n",
       "      <td>0.960123</td>\n",
       "      <td>0.742879</td>\n",
       "      <td>0.237037</td>\n",
       "      <td>0.984742</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.727630</td>\n",
       "      <td>0.220349</td>\n",
       "      <td>0.973851</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>teste</td>\n",
       "      <td>0.977727</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.997104</td>\n",
       "      <td>0.953988</td>\n",
       "      <td>0.719217</td>\n",
       "      <td>0.234460</td>\n",
       "      <td>0.980825</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.701324</td>\n",
       "      <td>0.225873</td>\n",
       "      <td>0.976024</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           base       acc                                      f1            \\\n",
       "                     mean       std       max       min      mean       std   \n",
       "model                                                                         \n",
       "XGBOOST  treino  0.981917  0.019850  1.000000  0.921569  0.796517  0.217562   \n",
       "MLP      treino  0.975194  0.023544  1.000000  0.901961  0.778780  0.196613   \n",
       "SVM      treino  0.980913  0.019488  1.000000  0.941176  0.763340  0.231737   \n",
       "MLP       teste  0.974830  0.011760  0.991934  0.963190  0.757269  0.156339   \n",
       "XGBOOST   teste  0.979078  0.015062  0.997725  0.960123  0.742879  0.237037   \n",
       "SVM       teste  0.977727  0.016924  0.997104  0.953988  0.719217  0.234460   \n",
       "\n",
       "                                  auc                                \n",
       "              max       min      mean       std       max       min  \n",
       "model                                                                \n",
       "XGBOOST  1.000000  0.479592  0.702294  0.209000  1.000000  0.479592  \n",
       "MLP      1.000000  0.483871  0.689675  0.186874  1.000000  0.483871  \n",
       "SVM      1.000000  0.484848  0.675331  0.210834  1.000000  0.500000  \n",
       "MLP      0.946178  0.558552  0.722536  0.158763  0.938381  0.537196  \n",
       "XGBOOST  0.984742  0.491905  0.727630  0.220349  0.973851  0.500000  \n",
       "SVM      0.980825  0.491905  0.701324  0.225873  0.976024  0.500000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Análise por aparelho/modelo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>model</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dish_washer - 9</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.968137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.558552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.558552</td>\n",
       "      <td>0.558552</td>\n",
       "      <td>0.537196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537196</td>\n",
       "      <td>0.537196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.967163</td>\n",
       "      <td>0.015508</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.524952</td>\n",
       "      <td>0.107013</td>\n",
       "      <td>0.829333</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.520200</td>\n",
       "      <td>0.081007</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.483871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.968137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.974975</td>\n",
       "      <td>0.008037</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.493657</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.496063</td>\n",
       "      <td>0.492063</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.968137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.973413</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.493257</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.496063</td>\n",
       "      <td>0.492063</td>\n",
       "      <td>0.499206</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.492063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">fridge - 7</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.981752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.638236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638236</td>\n",
       "      <td>0.638236</td>\n",
       "      <td>0.598141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.598141</td>\n",
       "      <td>0.598141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.997674</td>\n",
       "      <td>0.007354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.949412</td>\n",
       "      <td>0.159974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.158114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.981752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.995349</td>\n",
       "      <td>0.009806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.898824</td>\n",
       "      <td>0.213299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.981752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.995349</td>\n",
       "      <td>0.009806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.898824</td>\n",
       "      <td>0.213299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">microwave - 16</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.963190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.963190</td>\n",
       "      <td>0.963190</td>\n",
       "      <td>0.813821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813821</td>\n",
       "      <td>0.813821</td>\n",
       "      <td>0.770098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.770098</td>\n",
       "      <td>0.770098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.945173</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.696472</td>\n",
       "      <td>0.137656</td>\n",
       "      <td>0.894845</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.695918</td>\n",
       "      <td>0.129340</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.489796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.953988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953988</td>\n",
       "      <td>0.953988</td>\n",
       "      <td>0.688038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.688038</td>\n",
       "      <td>0.688038</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.949095</td>\n",
       "      <td>0.010225</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.536889</td>\n",
       "      <td>0.107016</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.070273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.960123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.960123</td>\n",
       "      <td>0.960123</td>\n",
       "      <td>0.803751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.803751</td>\n",
       "      <td>0.803751</td>\n",
       "      <td>0.768464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768464</td>\n",
       "      <td>0.768464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.955015</td>\n",
       "      <td>0.022662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.701603</td>\n",
       "      <td>0.178837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.479592</td>\n",
       "      <td>0.678189</td>\n",
       "      <td>0.167578</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.479592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">washer_dryer - 13</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.991934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991934</td>\n",
       "      <td>0.991934</td>\n",
       "      <td>0.946178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.946178</td>\n",
       "      <td>0.946178</td>\n",
       "      <td>0.938381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.938381</td>\n",
       "      <td>0.938381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.995093</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.997347</td>\n",
       "      <td>0.992042</td>\n",
       "      <td>0.948597</td>\n",
       "      <td>0.023468</td>\n",
       "      <td>0.973004</td>\n",
       "      <td>0.914629</td>\n",
       "      <td>0.942625</td>\n",
       "      <td>0.029441</td>\n",
       "      <td>0.973004</td>\n",
       "      <td>0.893376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.997104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997104</td>\n",
       "      <td>0.997104</td>\n",
       "      <td>0.980825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.980825</td>\n",
       "      <td>0.980825</td>\n",
       "      <td>0.976024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976024</td>\n",
       "      <td>0.976024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.997745</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996021</td>\n",
       "      <td>0.976258</td>\n",
       "      <td>0.011943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956125</td>\n",
       "      <td>0.972477</td>\n",
       "      <td>0.018534</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.997725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997725</td>\n",
       "      <td>0.997725</td>\n",
       "      <td>0.984742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.984742</td>\n",
       "      <td>0.984742</td>\n",
       "      <td>0.973851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.973851</td>\n",
       "      <td>0.973851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.998408</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997347</td>\n",
       "      <td>0.982962</td>\n",
       "      <td>0.009378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969910</td>\n",
       "      <td>0.972817</td>\n",
       "      <td>0.018423</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">washer_dryer - 14</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.969136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.969136</td>\n",
       "      <td>0.969136</td>\n",
       "      <td>0.829561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.829561</td>\n",
       "      <td>0.829561</td>\n",
       "      <td>0.768865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768865</td>\n",
       "      <td>0.768865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.970866</td>\n",
       "      <td>0.011166</td>\n",
       "      <td>0.992126</td>\n",
       "      <td>0.952756</td>\n",
       "      <td>0.774468</td>\n",
       "      <td>0.101951</td>\n",
       "      <td>0.942404</td>\n",
       "      <td>0.632736</td>\n",
       "      <td>0.739631</td>\n",
       "      <td>0.116070</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.595902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.987654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.939918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.939918</td>\n",
       "      <td>0.939918</td>\n",
       "      <td>0.905594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.905594</td>\n",
       "      <td>0.905594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.987402</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976378</td>\n",
       "      <td>0.911071</td>\n",
       "      <td>0.049782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827211</td>\n",
       "      <td>0.870844</td>\n",
       "      <td>0.073708</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.987654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.938601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.938601</td>\n",
       "      <td>0.938601</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.895833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.987402</td>\n",
       "      <td>0.007607</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976378</td>\n",
       "      <td>0.905937</td>\n",
       "      <td>0.066179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.779641</td>\n",
       "      <td>0.861257</td>\n",
       "      <td>0.089757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       acc                                \\\n",
       "                                      mean       std       max       min   \n",
       "appliance         model   base                                             \n",
       "dish_washer - 9   MLP     teste   0.968137       NaN  0.968137  0.968137   \n",
       "                          treino  0.967163  0.015508  0.984375  0.937500   \n",
       "                  SVM     teste   0.968137       NaN  0.968137  0.968137   \n",
       "                          treino  0.974975  0.008037  0.984375  0.968750   \n",
       "                  XGBOOST teste   0.968137       NaN  0.968137  0.968137   \n",
       "                          treino  0.973413  0.007508  0.984375  0.968750   \n",
       "fridge - 7        MLP     teste   0.981752       NaN  0.981752  0.981752   \n",
       "                          treino  0.997674  0.007354  1.000000  0.976744   \n",
       "                  SVM     teste   0.981752       NaN  0.981752  0.981752   \n",
       "                          treino  0.995349  0.009806  1.000000  0.976744   \n",
       "                  XGBOOST teste   0.981752       NaN  0.981752  0.981752   \n",
       "                          treino  0.995349  0.009806  1.000000  0.976744   \n",
       "microwave - 16    MLP     teste   0.963190       NaN  0.963190  0.963190   \n",
       "                          treino  0.945173  0.022321  0.980392  0.901961   \n",
       "                  SVM     teste   0.953988       NaN  0.953988  0.953988   \n",
       "                          treino  0.949095  0.010225  0.961538  0.941176   \n",
       "                  XGBOOST teste   0.960123       NaN  0.960123  0.960123   \n",
       "                          treino  0.955015  0.022662  1.000000  0.921569   \n",
       "washer_dryer - 13 MLP     teste   0.991934       NaN  0.991934  0.991934   \n",
       "                          treino  0.995093  0.002259  0.997347  0.992042   \n",
       "                  SVM     teste   0.997104       NaN  0.997104  0.997104   \n",
       "                          treino  0.997745  0.001092  1.000000  0.996021   \n",
       "                  XGBOOST teste   0.997725       NaN  0.997725  0.997725   \n",
       "                          treino  0.998408  0.000839  1.000000  0.997347   \n",
       "washer_dryer - 14 MLP     teste   0.969136       NaN  0.969136  0.969136   \n",
       "                          treino  0.970866  0.011166  0.992126  0.952756   \n",
       "                  SVM     teste   0.987654       NaN  0.987654  0.987654   \n",
       "                          treino  0.987402  0.006640  1.000000  0.976378   \n",
       "                  XGBOOST teste   0.987654       NaN  0.987654  0.987654   \n",
       "                          treino  0.987402  0.007607  1.000000  0.976378   \n",
       "\n",
       "                                        f1                                \\\n",
       "                                      mean       std       max       min   \n",
       "appliance         model   base                                             \n",
       "dish_washer - 9   MLP     teste   0.558552       NaN  0.558552  0.558552   \n",
       "                          treino  0.524952  0.107013  0.829333  0.483871   \n",
       "                  SVM     teste   0.491905       NaN  0.491905  0.491905   \n",
       "                          treino  0.493657  0.002057  0.496063  0.492063   \n",
       "                  XGBOOST teste   0.491905       NaN  0.491905  0.491905   \n",
       "                          treino  0.493257  0.001922  0.496063  0.492063   \n",
       "fridge - 7        MLP     teste   0.638236       NaN  0.638236  0.638236   \n",
       "                          treino  0.949412  0.159974  1.000000  0.494118   \n",
       "                  SVM     teste   0.495396       NaN  0.495396  0.495396   \n",
       "                          treino  0.898824  0.213299  1.000000  0.494118   \n",
       "                  XGBOOST teste   0.495396       NaN  0.495396  0.495396   \n",
       "                          treino  0.898824  0.213299  1.000000  0.494118   \n",
       "microwave - 16    MLP     teste   0.813821       NaN  0.813821  0.813821   \n",
       "                          treino  0.696472  0.137656  0.894845  0.484848   \n",
       "                  SVM     teste   0.688038       NaN  0.688038  0.688038   \n",
       "                          treino  0.536889  0.107016  0.740000  0.484848   \n",
       "                  XGBOOST teste   0.803751       NaN  0.803751  0.803751   \n",
       "                          treino  0.701603  0.178837  1.000000  0.479592   \n",
       "washer_dryer - 13 MLP     teste   0.946178       NaN  0.946178  0.946178   \n",
       "                          treino  0.948597  0.023468  0.973004  0.914629   \n",
       "                  SVM     teste   0.980825       NaN  0.980825  0.980825   \n",
       "                          treino  0.976258  0.011943  1.000000  0.956125   \n",
       "                  XGBOOST teste   0.984742       NaN  0.984742  0.984742   \n",
       "                          treino  0.982962  0.009378  1.000000  0.969910   \n",
       "washer_dryer - 14 MLP     teste   0.829561       NaN  0.829561  0.829561   \n",
       "                          treino  0.774468  0.101951  0.942404  0.632736   \n",
       "                  SVM     teste   0.939918       NaN  0.939918  0.939918   \n",
       "                          treino  0.911071  0.049782  1.000000  0.827211   \n",
       "                  XGBOOST teste   0.938601       NaN  0.938601  0.938601   \n",
       "                          treino  0.905937  0.066179  1.000000  0.779641   \n",
       "\n",
       "                                       auc                                \n",
       "                                      mean       std       max       min  \n",
       "appliance         model   base                                            \n",
       "dish_washer - 9   MLP     teste   0.537196       NaN  0.537196  0.537196  \n",
       "                          treino  0.520200  0.081007  0.750000  0.483871  \n",
       "                  SVM     teste   0.500000       NaN  0.500000  0.500000  \n",
       "                          treino  0.500000  0.000000  0.500000  0.500000  \n",
       "                  XGBOOST teste   0.500000       NaN  0.500000  0.500000  \n",
       "                          treino  0.499206  0.002510  0.500000  0.492063  \n",
       "fridge - 7        MLP     teste   0.598141       NaN  0.598141  0.598141  \n",
       "                          treino  0.550000  0.158114  1.000000  0.500000  \n",
       "                  SVM     teste   0.500000       NaN  0.500000  0.500000  \n",
       "                          treino  0.500000  0.000000  0.500000  0.500000  \n",
       "                  XGBOOST teste   0.500000       NaN  0.500000  0.500000  \n",
       "                          treino  0.500000  0.000000  0.500000  0.500000  \n",
       "microwave - 16    MLP     teste   0.770098       NaN  0.770098  0.770098  \n",
       "                          treino  0.695918  0.129340  0.833333  0.489796  \n",
       "                  SVM     teste   0.625000       NaN  0.625000  0.625000  \n",
       "                          treino  0.533333  0.070273  0.666667  0.500000  \n",
       "                  XGBOOST teste   0.768464       NaN  0.768464  0.768464  \n",
       "                          treino  0.678189  0.167578  1.000000  0.479592  \n",
       "washer_dryer - 13 MLP     teste   0.938381       NaN  0.938381  0.938381  \n",
       "                          treino  0.942625  0.029441  0.973004  0.893376  \n",
       "                  SVM     teste   0.976024       NaN  0.976024  0.976024  \n",
       "                          treino  0.972477  0.018534  1.000000  0.943765  \n",
       "                  XGBOOST teste   0.973851       NaN  0.973851  0.973851  \n",
       "                          treino  0.972817  0.018423  1.000000  0.944444  \n",
       "washer_dryer - 14 MLP     teste   0.768865       NaN  0.768865  0.768865  \n",
       "                          treino  0.739631  0.116070  0.900000  0.595902  \n",
       "                  SVM     teste   0.905594       NaN  0.905594  0.905594  \n",
       "                          treino  0.870844  0.073708  1.000000  0.750000  \n",
       "                  XGBOOST teste   0.895833       NaN  0.895833  0.895833  \n",
       "                          treino  0.861257  0.089757  1.000000  0.700000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_resultados_svm = pd.read_excel(os.path.join(caminho_dados_notebook, \"df_resultados_svm.xlsx\"), engine=\"openpyxl\")\n",
    "df_resultados_svm[\"model\"] = \"SVM\"\n",
    "\n",
    "df_resultados_xgboost = pd.read_excel(os.path.join(caminho_dados_notebook, \"df_resultados_xgboost.xlsx\"), engine=\"openpyxl\")\n",
    "df_resultados_xgboost[\"model\"] = \"XGBOOST\"\n",
    "\n",
    "df_resultados_mlp = pd.read_excel(os.path.join(caminho_dados_notebook, \"df_resultados_mlp.xlsx\"), engine=\"openpyxl\")\n",
    "df_resultados_mlp[\"model\"] = \"MLP\"\n",
    "\n",
    "# df_resultados_elm = pd.read_excel(os.path.join(caminho_dados_notebook, \"df_resultados_elm.xlsx\"), engine=\"openpyxl)\n",
    "# df_resultados_elm[\"model\"] = \"ELM\"\n",
    "\n",
    "df_analise = pd.concat([\n",
    "    df_resultados_svm,\n",
    "    df_resultados_xgboost,\n",
    "    df_resultados_mlp, \n",
    "#     df_resultados_elm,  \n",
    "])\n",
    "\n",
    "print(\"* Análise por modelo:\")\n",
    "df_analise_modelo = df_analise.groupby([\"model\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"f1\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"auc\": [\"mean\",\"std\",\"max\",\"min\"]\n",
    "}).reset_index().sort_values(('f1','mean'), ascending=False).set_index(\"model\")\n",
    "display(df_analise_modelo)\n",
    "df_analise_modelo.to_excel(os.path.join(caminho_dados_notebook, \"df_analise_modelo.xlsx\"))\n",
    "\n",
    "print()\n",
    "print(\"* Análise por aparelho/modelo:\")\n",
    "df_analise_aparelho = df_analise.groupby([\"appliance\",\"model\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"f1\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"auc\": [\"mean\",\"std\",\"max\",\"min\"]\n",
    "})#.reset_index().sort_values(('f1','mean'), ascending=False).set_index([\"aparelho\",\"metodologia\"])\n",
    "display(df_analise_aparelho)\n",
    "df_analise_aparelho.to_excel(os.path.join(caminho_dados_notebook, \"df_analise_aparelho.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T16:36:14.612080Z",
     "start_time": "2021-05-02T16:36:14.551192Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T16:36:15.496447Z",
     "start_time": "2021-05-02T16:36:14.614073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Diego Luiz Cavalca\n",
      "\n",
      "Last updated: Sun May 02 2021 13:36:14Hora oficial do Brasil\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.8\n",
      "IPython version      : 7.21.0\n",
      "\n",
      "Compiler    : MSC v.1928 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 158 Stepping 9, GenuineIntel\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: a29eb3e98689f89f3597358428a2cab6bb3ab9b0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -a \"Diego Luiz Cavalca\" -u -n -t -z -v -m -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "interpreter": {
   "hash": "edadf20adbb432455c8f4e9b4b599932ab57901956f052dc6c0a0268128421d2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('doutorado')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

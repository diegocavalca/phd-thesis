{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Defesa - Dataset LIAA - Aprendizado Profundo em Atributos DTLFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estruturação de pipeline baseado em aprendizado raso utilizando atributos de alta frequência.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T17:00:00.198228Z",
     "start_time": "2021-05-02T16:59:56.833044Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "from pretty_confusion_matrix import *\n",
    "\n",
    "# TODO: implementar rotina na classe PyNILM.utils\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "def listar_variaveis_memoria(ambiente):\n",
    "    print(\"* Variáveis instanciadas em memória:\")\n",
    "    print(\"---\")\n",
    "    total = 0\n",
    "    for name, size in sorted(((name, sys.getsizeof(value)) for name, value in ambiente.items()),\n",
    "                             key= lambda x: -x[1])[:10]:\n",
    "        total += size\n",
    "        print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))\n",
    "    print(\"---\")\n",
    "    print(\"Total:\", sizeof_fmt(total))\n",
    "    \n",
    "# TODO: implementar na classe utils\n",
    "def highlight_col(x):\n",
    "    r = 'background-color: #D9D9D9'\n",
    "    df1 = pd.DataFrame('', index=x.index, columns=x.columns)\n",
    "    df1.iloc[:, -2] = r\n",
    "    return df1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T17:00:00.322361Z",
     "start_time": "2021-05-02T17:00:00.201233Z"
    }
   },
   "outputs": [],
   "source": [
    "# CONSTANTES FUNDAMENTAIS DE ORGANIZACAO DE PASTAS/ARQUIVOS\n",
    "RESIDENCIA = 3\n",
    "\n",
    "# Path do arquivo H5 (base REDD ja preparada p/ NILMTK) e outros insumos fundamentais\n",
    "caminho_dados = \"D:/Projetos/phd-thesis/datasets/\"\n",
    "\n",
    "# Definir diretorios onde iremos salvar os insumos gerados do notebook (dados, imagens, etc.)\n",
    "caminho_dados_notebook = os.path.join(caminho_dados, \"28\") # Num. notebook\n",
    "if not os.path.isdir(caminho_dados_notebook):\n",
    "    os.makedirs(caminho_dados_notebook)\n",
    "caminho_imagens_notebook = os.path.join(caminho_dados_notebook, \"imagens\") # Num. notebook\n",
    "if not os.path.isdir(caminho_imagens_notebook):\n",
    "    os.makedirs(caminho_imagens_notebook)\n",
    "\n",
    "# Path do arquivo H5 (base REDD ja preparada p/ NILMTK)\n",
    "caminho_redd = os.path.join(caminho_dados, \"REDD/low_freq\")\n",
    "\n",
    "# Path completo do arquivo REDD\n",
    "arquivo_dataset = os.path.join(caminho_redd, \"redd.h5\")\n",
    "\n",
    "# VARIAVEL AUXILIAR\n",
    "# Path dos arquivos relacionados as janelas\n",
    "caminho_janelas = os.path.join(caminho_redd, \"../../phd\")\n",
    "if not os.path.isdir(caminho_janelas):\n",
    "    os.makedirs(caminho_janelas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T17:00:01.903538Z",
     "start_time": "2021-05-02T17:00:00.325362Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from six import iteritems\n",
    "\n",
    "from nilmtk import DataSet, TimeFrame, MeterGroup, HDFDataStore\n",
    "from nilmtk.legacy.disaggregate import CombinatorialOptimisation, FHMM\n",
    "import nilmtk.utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando datasets\n",
    "df_treino = pd.read_csv(os.path.join(caminho_dados_notebook, 'training_windows.txt'))\n",
    "df_validacao = pd.read_csv(os.path.join(caminho_dados_notebook, 'validation_windows.txt'))\n",
    "\n",
    "# Selecionando feature dominio do tempo e frequencia / outputs (status dos aparelhos - dummy)\n",
    "colunas_janela = df_treino.columns[:512]\n",
    "\n",
    "colunas_output = ['LC', 'LI', 'MO', 'MT', 'PC', 'LF']\n",
    "\n",
    "# Preparando dados de treino e validacao\n",
    "X_treino = df_treino[colunas_janela]\n",
    "X_validacao = df_validacao[colunas_janela]\n",
    "\n",
    "y_treino = df_treino[colunas_output].replace(-1, 0)\n",
    "y_validacao = df_validacao[colunas_output].replace(-1, 0)\n",
    "\n",
    "del df_treino\n",
    "del df_validacao\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento e Avaliação dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T17:00:27.268721Z",
     "start_time": "2021-05-02T17:00:16.855220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "# from PyNILM.dados.janelas import Janelas\n",
    "from PyNILM.dados.janelas import Janelas\n",
    "from PyNILM.dados.utils import *\n",
    "\n",
    "from PyNILM.avaliacao.metricas import *\n",
    "from PyNILM.avaliacao.graficos import *\n",
    "from PyNILM.avaliacao.analises import *\n",
    "\n",
    "from PyNILM.modelos.utils import *\n",
    "from PyNILM.modelos.dlafe import DLAFE\n",
    "# from PyNILM.modelos.rqa import RQA\n",
    "\n",
    "# Inicializar uso GPU\n",
    "start_tf_session(memory_limit=int(1024*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T17:00:27.377109Z",
     "start_time": "2021-05-02T17:00:27.271695Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atributos DTLFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37800/37800 [01:45<00:00, 359.60it/s]\n",
      "100%|██████████| 25200/25200 [01:10<00:00, 358.64it/s]\n"
     ]
    }
   ],
   "source": [
    "from pyts.image import RecurrencePlot\n",
    "\n",
    "# Parametros execucao do experimento\n",
    "atributos = \"dtlfe\" \n",
    "\n",
    "# Parametros DTLFE (antigo DLAFE)\n",
    "TAMANHO_IMAGEM_DLAFE = (32, 32, 3)\n",
    "modelo_extrator = transfer_learning.vgg16.VGG16(\n",
    "            weights='imagenet', \n",
    "            include_top=False,\n",
    "            pooling='avg'\n",
    "        )\n",
    "preprocessamento_extrator = transfer_learning.vgg16.preprocess_input\n",
    "\n",
    "def converter_janelas_para_dtlfe(\n",
    "    X,\n",
    "    input_shape=TAMANHO_IMAGEM_DLAFE,\n",
    "    data_type=np.float32,\n",
    "    normalize=False, \n",
    "    standardize=False, \n",
    "    rescale=False,\n",
    "    preprocessamento_extrator=None,\n",
    "    modelo_extrator=None,\n",
    "    arquivo=None):\n",
    "    \n",
    "    X_ = np.empty((len(X), * input_shape))\n",
    "        \n",
    "    for i, x in tqdm(enumerate(X), total=X.shape[0]):\n",
    "        \n",
    "        img = RecurrencePlot(**PARAMETROS_RP).fit_transform([x])[0]\n",
    "        img = cv2.resize(\n",
    "                img, \n",
    "                dsize=input_shape[:2], \n",
    "                interpolation=cv2.INTER_CUBIC\n",
    "            ).astype(data_type)\n",
    "\n",
    "        if np.sum(img) > 0:\n",
    "            # TODO: improve fit/predict statistics\n",
    "            # Normalizar\n",
    "            if normalize:\n",
    "                img = (img - img.min()) / (img.max() - img.min()) # MinMax (0,1)\n",
    "                #img = (img - img.mean()) / np.max([img.std(), 1e-4])\n",
    "\n",
    "        #     # centralizar\n",
    "        #     if centralizar:\n",
    "        #         img -= img.mean()\n",
    "\n",
    "            # Padronizar\n",
    "            elif standardize:\n",
    "                img = (img - img.mean())/img.std()#tf.image.per_image_standardization(img).numpy()\n",
    "                \n",
    "            elif rescale:\n",
    "                img = (img - img.min()) / (img.max() - img.min())\n",
    "\n",
    "        # N canais\n",
    "        img = np.stack([img for i in range(input_shape[-1])],axis=-1).astype(data_type)     \n",
    "        \n",
    "        X_[i,] = img\n",
    "    \n",
    "    # X_ = np.array(X_).astype(data_type)\n",
    "\n",
    "    # Extranindo atributos via DL\n",
    "    if preprocessamento_extrator:\n",
    "        X_ = preprocessamento_extrator(X_).astype(data_type)\n",
    "    if modelo_extrator:\n",
    "        output = modelo_extrator.predict(X_)\n",
    "    else:\n",
    "        output = X_\n",
    "\n",
    "    if arquivo:\n",
    "        if os.path.isfile(arquivo): os.remove(arquivo)\n",
    "        np.save(arquivo, output)\n",
    "\n",
    "    # return df    \n",
    "    return output\n",
    "\n",
    "\n",
    "# Carregando dados RQA (treino)\n",
    "arquivo_treino = os.path.join(caminho_dados_notebook, f\"{atributos}_treino.npy\")\n",
    "if os.path.isfile(arquivo_treino):\n",
    "    X_treino = np.load(arquivo_treino)\n",
    "else:\n",
    "    X_treino = converter_janelas_para_dtlfe(\n",
    "        X_treino.values,\n",
    "        input_shape=TAMANHO_IMAGEM_DLAFE,\n",
    "        preprocessamento_extrator=preprocessamento_extrator,\n",
    "        modelo_extrator=modelo_extrator,\n",
    "        arquivo=arquivo_treino)\n",
    "\n",
    "# Carregando dados RQA (validacao)\n",
    "arquivo_validacao = os.path.join(caminho_dados_notebook, f\"{atributos}_validacao.npy\")\n",
    "if os.path.isfile(arquivo_validacao):\n",
    "    X_validacao = np.load(arquivo_validacao)\n",
    "else:\n",
    "    X_validacao = converter_janelas_para_dtlfe(\n",
    "        X_validacao.values,\n",
    "        input_shape=TAMANHO_IMAGEM_DLAFE,\n",
    "        preprocessamento_extrator=preprocessamento_extrator,\n",
    "        modelo_extrator=modelo_extrator,\n",
    "        arquivo=arquivo_validacao)\n",
    "\n",
    "# Convertendo Numpy para Dataframe (evitar refatoracao codigo)\n",
    "X_treino = pd.DataFrame(X_treino)\n",
    "X_validacao = pd.DataFrame(X_validacao)\n",
    "\n",
    "# Dados agregados (validacao cruzada)\n",
    "X_cv = pd.concat([X_treino, X_validacao]).reset_index(drop=True) \n",
    "y_cv = pd.concat([y_treino, y_validacao]).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T22:18:59.268806Z",
     "start_time": "2021-05-02T17:03:12.352604Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "\n",
      "* Aparelho `LC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.81      0.88     12400\n",
      "           1       0.84      0.97      0.90     12800\n",
      "\n",
      "    accuracy                           0.89     25200\n",
      "   macro avg       0.90      0.89      0.89     25200\n",
      "weighted avg       0.90      0.89      0.89     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[10000  2400]\n",
      " [  400 12400]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22016c66d7554e38b1bf1b77aa42e3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90     31000\n",
      "           1       0.86      0.97      0.91     32000\n",
      "\n",
      "    accuracy                           0.91     63000\n",
      "   macro avg       0.91      0.91      0.91     63000\n",
      "weighted avg       0.91      0.91      0.91     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[26126  4874]\n",
      " [ 1000 31000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LI`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26cda7353be54893aefc1e7992fc020c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MO`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e99e99039344789b8966f11816f96a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MT`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992ac852c29140bdb52644a0632a97af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `PC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92fae554cb54e6b8899f513083ea6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LF`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.84      0.74     12400\n",
      "           1       0.79      0.59      0.68     12800\n",
      "\n",
      "    accuracy                           0.71     25200\n",
      "   macro avg       0.73      0.72      0.71     25200\n",
      "weighted avg       0.73      0.71      0.71     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[10400  2000]\n",
      " [ 5200  7600]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53bf8b42e02947d2bc60a6367f781bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.94      0.79     31000\n",
      "           1       0.90      0.56      0.70     32000\n",
      "\n",
      "    accuracy                           0.75     63000\n",
      "   macro avg       0.79      0.75      0.74     63000\n",
      "weighted avg       0.79      0.75      0.74     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[29103  1897]\n",
      " [13931 18069]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LC</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.906762</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.904841</td>\n",
       "      <td>0.906200</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.908224</td>\n",
       "      <td>0.904230</td>\n",
       "      <td>0.905762</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.907780</td>\n",
       "      <td>0.903800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.887872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.887872</td>\n",
       "      <td>0.887872</td>\n",
       "      <td>0.887601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.887601</td>\n",
       "      <td>0.887601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LF</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.748762</td>\n",
       "      <td>0.007253</td>\n",
       "      <td>0.758968</td>\n",
       "      <td>0.741270</td>\n",
       "      <td>0.740807</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.750905</td>\n",
       "      <td>0.732748</td>\n",
       "      <td>0.751731</td>\n",
       "      <td>0.007258</td>\n",
       "      <td>0.762016</td>\n",
       "      <td>0.744292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.710714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710714</td>\n",
       "      <td>0.710714</td>\n",
       "      <td>0.716230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716230</td>\n",
       "      <td>0.716230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LI</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MO</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MT</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PC</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             acc                                      f1  \\\n",
       "                            mean       std       max       min      mean   \n",
       "appliance base                                                             \n",
       "LC        cv            0.906762  0.001764  0.908730  0.904841  0.906200   \n",
       "          treino-teste  0.888889       NaN  0.888889  0.888889  0.887872   \n",
       "LF        cv            0.748762  0.007253  0.758968  0.741270  0.740807   \n",
       "          treino-teste  0.714286       NaN  0.714286  0.714286  0.710714   \n",
       "LI        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "MO        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "MT        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "PC        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "\n",
       "                                                           auc            \\\n",
       "                             std       max       min      mean       std   \n",
       "appliance base                                                             \n",
       "LC        cv            0.001793  0.908224  0.904230  0.905762  0.001785   \n",
       "          treino-teste       NaN  0.887872  0.887872  0.887601       NaN   \n",
       "LF        cv            0.007481  0.750905  0.732748  0.751731  0.007258   \n",
       "          treino-teste       NaN  0.710714  0.710714  0.716230       NaN   \n",
       "LI        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "MO        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "MT        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "PC        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "\n",
       "                                            \n",
       "                             max       min  \n",
       "appliance base                              \n",
       "LC        cv            0.907780  0.903800  \n",
       "          treino-teste  0.887601  0.887601  \n",
       "LF        cv            0.762016  0.744292  \n",
       "          treino-teste  0.716230  0.716230  \n",
       "LI        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "MO        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "MT        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "PC        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo = SVC(kernel='rbf', random_state=SEED)\n",
    "nome_modelo = \"svm\"\n",
    "\n",
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \n",
    "    \"base\": []\n",
    "}\n",
    "\n",
    "for rotulo_aparelho in colunas_output:\n",
    "    \n",
    "    print(\"****************************************************************\\n\")\n",
    "    print(f\"* Aparelho `{rotulo_aparelho}`...\\n\")\n",
    "    \n",
    "    #######################################################################\n",
    "    #                AVALIACAO 1 - Base de treino/validacao               #\n",
    "    #######################################################################\n",
    "\n",
    "    # # Filtrando output/status por aparelho\n",
    "    y_treino_aparelho = y_treino[rotulo_aparelho]\n",
    "    y_validacao_aparelho = y_validacao[rotulo_aparelho]\n",
    "\n",
    "    print(f\"  - Avaliando modelo através da base treino/validacao...\")\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem (lote validacao):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_validacao_aparelho).items():\n",
    "        print(f\"       - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_validacao_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "\n",
    "    # Treinando modelo\n",
    "    print(f\"     -> Treinando modelo...\\n\")\n",
    "    clf = clone(modelo)\n",
    "        \n",
    "    clf.fit(X_treino.values, y_treino_aparelho)\n",
    "\n",
    "    # Prevendo conjunto de dados\n",
    "    y_hat = clf.predict(X_validacao)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "    resultados_modelo[\"fold\"].append(\"-\")\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_validacao_aparelho, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_validacao_aparelho, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_validacao_aparelho, y_hat) if np.unique(y_validacao_aparelho).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"treino-teste\")\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_validacao_aparelho, y_hat))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_validacao_aparelho, y_hat))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    #######################################################################\n",
    "    #                  AVALIACAO 2 - Validacao Cruzada                    #\n",
    "    #######################################################################\n",
    "    \n",
    "    y_true_cv, y_pred_cv  = [], []\n",
    "\n",
    "    print(f\"  - Avaliando através de validação cruzada ({skf.n_splits}-folds)...\")\n",
    "\n",
    "    # Filtrando output/status por aparelho\n",
    "    y_aparelho = y_cv[rotulo_aparelho]\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem:\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_aparelho).items():\n",
    "        print(f\"        - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "    \n",
    "\n",
    "    print(f\"     -> Avaliando modelo (CV - {skf.n_splits} folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in tqdm_notebook(enumerate(skf.split(X_cv, y_aparelho)), total=skf.n_splits):\n",
    "        \n",
    "        # Preparando lotes\n",
    "        X_treino_cv, X_teste_cv = X_cv.iloc[idx_treino], X_cv.iloc[idx_teste]\n",
    "        y_treino_cv, y_teste_cv = y_aparelho.iloc[idx_treino], y_aparelho.iloc[idx_teste]\n",
    "\n",
    "        # Treinando modelo\n",
    "        clf = clone(modelo)\n",
    "        \n",
    "        clf.fit(X_treino_cv, y_treino_cv)\n",
    "\n",
    "        # Prevendo conjunto de dados\n",
    "        y_hat = clf.predict(X_teste_cv)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste_cv, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste_cv, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste_cv, y_hat) if np.unique(y_teste_cv).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"cv\")\n",
    "\n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true_cv.extend(y_teste_cv)\n",
    "        y_pred_cv.extend(y_hat)\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true_cv, y_pred_cv))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true_cv, y_pred_cv))\n",
    "    print()\n",
    "    print(\"**********************************************\")\n",
    "    print()\n",
    "    \n",
    "# Consolidando DataFrame\n",
    "df_resultados = pd.DataFrame(resultados_modelo)\n",
    "\n",
    "arquivo_resultados = os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_resultados_{nome_modelo}.xlsx\")\n",
    "if os.path.isfile(arquivo_resultados): os.remove(arquivo_resultados)\n",
    "df_resultados.to_excel(arquivo_resultados, index=False)\n",
    "    \n",
    "print(\"############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\")\n",
    "display(df_resultados.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T19:59:41.720698Z",
     "start_time": "2020-08-31T19:59:41.680673Z"
    }
   },
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T03:52:19.841404Z",
     "start_time": "2021-05-02T22:19:01.487888Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "\n",
      "* Aparelho `LC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f049329d2d468db9b2c7e00add67ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LI`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5aec720d6d44fb2a1543e080e143f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MO`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710616b8240b4b75a130e77d4ad99f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MT`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e703e847c64c02aae14cfd9c33b3d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `PC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e9fd1d50024816b30926ab41cc646c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LF`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2468093f66452eb5e016dafcc96dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LC</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LF</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LI</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MO</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MT</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PC</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        acc                  f1                 auc            \\\n",
       "                       mean  std  max  min mean  std  max  min mean  std  max   \n",
       "appliance base                                                                  \n",
       "LC        cv            1.0  0.0  1.0  1.0  1.0  0.0  1.0  1.0  1.0  0.0  1.0   \n",
       "          treino-teste  1.0  NaN  1.0  1.0  1.0  NaN  1.0  1.0  1.0  NaN  1.0   \n",
       "LF        cv            1.0  0.0  1.0  1.0  1.0  0.0  1.0  1.0  1.0  0.0  1.0   \n",
       "          treino-teste  1.0  NaN  1.0  1.0  1.0  NaN  1.0  1.0  1.0  NaN  1.0   \n",
       "LI        cv            1.0  0.0  1.0  1.0  1.0  0.0  1.0  1.0  1.0  0.0  1.0   \n",
       "          treino-teste  1.0  NaN  1.0  1.0  1.0  NaN  1.0  1.0  1.0  NaN  1.0   \n",
       "MO        cv            1.0  0.0  1.0  1.0  1.0  0.0  1.0  1.0  1.0  0.0  1.0   \n",
       "          treino-teste  1.0  NaN  1.0  1.0  1.0  NaN  1.0  1.0  1.0  NaN  1.0   \n",
       "MT        cv            1.0  0.0  1.0  1.0  1.0  0.0  1.0  1.0  1.0  0.0  1.0   \n",
       "          treino-teste  1.0  NaN  1.0  1.0  1.0  NaN  1.0  1.0  1.0  NaN  1.0   \n",
       "PC        cv            1.0  0.0  1.0  1.0  1.0  0.0  1.0  1.0  1.0  0.0  1.0   \n",
       "          treino-teste  1.0  NaN  1.0  1.0  1.0  NaN  1.0  1.0  1.0  NaN  1.0   \n",
       "\n",
       "                             \n",
       "                        min  \n",
       "appliance base               \n",
       "LC        cv            1.0  \n",
       "          treino-teste  1.0  \n",
       "LF        cv            1.0  \n",
       "          treino-teste  1.0  \n",
       "LI        cv            1.0  \n",
       "          treino-teste  1.0  \n",
       "MO        cv            1.0  \n",
       "          treino-teste  1.0  \n",
       "MT        cv            1.0  \n",
       "          treino-teste  1.0  \n",
       "PC        cv            1.0  \n",
       "          treino-teste  1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo = XGBClassifier(eval_metric='error', random_state=SEED, n_jobs=4)\n",
    "nome_modelo = \"xgboost\"\n",
    "\n",
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \n",
    "    \"base\": []\n",
    "}\n",
    "\n",
    "for rotulo_aparelho in colunas_output:\n",
    "    \n",
    "    print(\"****************************************************************\\n\")\n",
    "    print(f\"* Aparelho `{rotulo_aparelho}`...\\n\")\n",
    "    \n",
    "    #######################################################################\n",
    "    #                AVALIACAO 1 - Base de treino/validacao               #\n",
    "    #######################################################################\n",
    "\n",
    "    # # Filtrando output/status por aparelho\n",
    "    y_treino_aparelho = y_treino[rotulo_aparelho]\n",
    "    y_validacao_aparelho = y_validacao[rotulo_aparelho]\n",
    "\n",
    "    print(f\"  - Avaliando modelo através da base treino/validacao...\")\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem (lote validacao):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_validacao_aparelho).items():\n",
    "        print(f\"       - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_validacao_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "\n",
    "    # Treinando modelo\n",
    "    print(f\"     -> Treinando modelo...\\n\")\n",
    "    clf = clone(modelo)\n",
    "        \n",
    "    clf.fit(X_treino, y_treino_aparelho)\n",
    "\n",
    "    # Prevendo conjunto de dados\n",
    "    y_hat = clf.predict(X_validacao)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "    resultados_modelo[\"fold\"].append(\"-\")\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_validacao_aparelho, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_validacao_aparelho, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_validacao_aparelho, y_hat) if np.unique(y_validacao_aparelho).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"treino-teste\")\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_validacao_aparelho, y_hat))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_validacao_aparelho, y_hat))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    #######################################################################\n",
    "    #                  AVALIACAO 2 - Validacao Cruzada                    #\n",
    "    #######################################################################\n",
    "    \n",
    "    y_true_cv, y_pred_cv  = [], []\n",
    "\n",
    "    print(f\"  - Avaliando através de validação cruzada ({skf.n_splits}-folds)...\")\n",
    "\n",
    "    # Filtrando output/status por aparelho\n",
    "    y_aparelho = y_cv[rotulo_aparelho]\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem:\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_aparelho).items():\n",
    "        print(f\"        - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "    \n",
    "\n",
    "    print(f\"     -> Avaliando modelo (CV - {skf.n_splits} folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in tqdm_notebook(enumerate(skf.split(X_cv, y_aparelho)), total=skf.n_splits):\n",
    "        \n",
    "        # Preparando lotes\n",
    "        X_treino_cv, X_teste_cv = X_cv.iloc[idx_treino], X_cv.iloc[idx_teste]\n",
    "        y_treino_cv, y_teste_cv = y_aparelho.iloc[idx_treino], y_aparelho.iloc[idx_teste]\n",
    "\n",
    "        # Treinando modelo\n",
    "        clf = clone(modelo)\n",
    "        \n",
    "        clf.fit(X_treino_cv, y_treino_cv)\n",
    "\n",
    "        # Prevendo conjunto de dados\n",
    "        y_hat = clf.predict(X_teste_cv)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste_cv, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste_cv, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste_cv, y_hat) if np.unique(y_teste_cv).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"cv\")\n",
    "\n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true_cv.extend(y_teste_cv)\n",
    "        y_pred_cv.extend(y_hat)\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true_cv, y_pred_cv))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true_cv, y_pred_cv))\n",
    "    print()\n",
    "    print(\"**********************************************\")\n",
    "    print()\n",
    "    \n",
    "# Consolidando DataFrame\n",
    "df_resultados = pd.DataFrame(resultados_modelo)\n",
    "\n",
    "arquivo_resultados = os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_resultados_{nome_modelo}.xlsx\")\n",
    "if os.path.isfile(arquivo_resultados): os.remove(arquivo_resultados)\n",
    "df_resultados.to_excel(arquivo_resultados, index=False)\n",
    "    \n",
    "print(\"############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\")\n",
    "display(df_resultados.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:10:29.051087Z",
     "start_time": "2021-05-03T03:52:22.146464Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "\n",
      "* Aparelho `LC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2daf59bd51fd4ccbb8ccc6a90eabf937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LI`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8769446119340a690502d9d1ed707a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MO`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59829c3e97b46b58c5d2cda72e66572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MT`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af83c5f19f14fe28fcd8bfe68cbca7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `PC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042cae5316d44d1b817898ea215f1c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LF`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12396     4]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d297904181e449f9f266cf289f2aee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LC</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LF</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.999841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999839</td>\n",
       "      <td>0.999839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LI</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MO</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MT</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PC</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             acc                                 f1       \\\n",
       "                            mean  std       max       min      mean  std   \n",
       "appliance base                                                             \n",
       "LC        cv            1.000000  0.0  1.000000  1.000000  1.000000  0.0   \n",
       "          treino-teste  1.000000  NaN  1.000000  1.000000  1.000000  NaN   \n",
       "LF        cv            1.000000  0.0  1.000000  1.000000  1.000000  0.0   \n",
       "          treino-teste  0.999841  NaN  0.999841  0.999841  0.999841  NaN   \n",
       "LI        cv            1.000000  0.0  1.000000  1.000000  1.000000  0.0   \n",
       "          treino-teste  1.000000  NaN  1.000000  1.000000  1.000000  NaN   \n",
       "MO        cv            1.000000  0.0  1.000000  1.000000  1.000000  0.0   \n",
       "          treino-teste  1.000000  NaN  1.000000  1.000000  1.000000  NaN   \n",
       "MT        cv            1.000000  0.0  1.000000  1.000000  1.000000  0.0   \n",
       "          treino-teste  1.000000  NaN  1.000000  1.000000  1.000000  NaN   \n",
       "PC        cv            1.000000  0.0  1.000000  1.000000  1.000000  0.0   \n",
       "          treino-teste  1.000000  NaN  1.000000  1.000000  1.000000  NaN   \n",
       "\n",
       "                                                 auc                           \n",
       "                             max       min      mean  std       max       min  \n",
       "appliance base                                                                 \n",
       "LC        cv            1.000000  1.000000  1.000000  0.0  1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  1.000000  NaN  1.000000  1.000000  \n",
       "LF        cv            1.000000  1.000000  1.000000  0.0  1.000000  1.000000  \n",
       "          treino-teste  0.999841  0.999841  0.999839  NaN  0.999839  0.999839  \n",
       "LI        cv            1.000000  1.000000  1.000000  0.0  1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  1.000000  NaN  1.000000  1.000000  \n",
       "MO        cv            1.000000  1.000000  1.000000  0.0  1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  1.000000  NaN  1.000000  1.000000  \n",
       "MT        cv            1.000000  1.000000  1.000000  0.0  1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  1.000000  NaN  1.000000  1.000000  \n",
       "PC        cv            1.000000  1.000000  1.000000  0.0  1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  1.000000  NaN  1.000000  1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo = MLPClassifier(alpha=1e-3, hidden_layer_sizes=(10,), random_state=SEED)\n",
    "nome_modelo = \"mlp\"\n",
    "\n",
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \n",
    "    \"base\": []\n",
    "}\n",
    "\n",
    "for rotulo_aparelho in colunas_output:\n",
    "    \n",
    "    print(\"****************************************************************\\n\")\n",
    "    print(f\"* Aparelho `{rotulo_aparelho}`...\\n\")\n",
    "    \n",
    "    #######################################################################\n",
    "    #                AVALIACAO 1 - Base de treino/validacao               #\n",
    "    #######################################################################\n",
    "\n",
    "    # # Filtrando output/status por aparelho\n",
    "    y_treino_aparelho = y_treino[rotulo_aparelho]\n",
    "    y_validacao_aparelho = y_validacao[rotulo_aparelho]\n",
    "\n",
    "    print(f\"  - Avaliando modelo através da base treino/validacao...\")\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem (lote validacao):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_validacao_aparelho).items():\n",
    "        print(f\"       - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_validacao_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "\n",
    "    # Treinando modelo\n",
    "    print(f\"     -> Treinando modelo...\\n\")\n",
    "    clf = clone(modelo)\n",
    "        \n",
    "    clf.fit(X_treino, y_treino_aparelho)\n",
    "\n",
    "    # Prevendo conjunto de dados\n",
    "    y_hat = clf.predict(X_validacao)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "    resultados_modelo[\"fold\"].append(\"-\")\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_validacao_aparelho, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_validacao_aparelho, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_validacao_aparelho, y_hat) if np.unique(y_validacao_aparelho).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"treino-teste\")\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_validacao_aparelho, y_hat))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_validacao_aparelho, y_hat))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    #######################################################################\n",
    "    #                  AVALIACAO 2 - Validacao Cruzada                    #\n",
    "    #######################################################################\n",
    "    \n",
    "    y_true_cv, y_pred_cv  = [], []\n",
    "\n",
    "    print(f\"  - Avaliando através de validação cruzada ({skf.n_splits}-folds)...\")\n",
    "\n",
    "    # Filtrando output/status por aparelho\n",
    "    y_aparelho = y_cv[rotulo_aparelho]\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem:\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_aparelho).items():\n",
    "        print(f\"        - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "    \n",
    "\n",
    "    print(f\"     -> Avaliando modelo (CV - {skf.n_splits} folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in tqdm_notebook(enumerate(skf.split(X_cv, y_aparelho)), total=skf.n_splits):\n",
    "        \n",
    "        # Preparando lotes\n",
    "        X_treino_cv, X_teste_cv = X_cv.iloc[idx_treino], X_cv.iloc[idx_teste]\n",
    "        y_treino_cv, y_teste_cv = y_aparelho.iloc[idx_treino], y_aparelho.iloc[idx_teste]\n",
    "\n",
    "        # Treinando modelo\n",
    "        clf = clone(modelo)\n",
    "        \n",
    "        clf.fit(X_treino_cv, y_treino_cv)\n",
    "\n",
    "        # Prevendo conjunto de dados\n",
    "        y_hat = clf.predict(X_teste_cv)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste_cv, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste_cv, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste_cv, y_hat) if np.unique(y_teste_cv).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"cv\")\n",
    "\n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true_cv.extend(y_teste_cv)\n",
    "        y_pred_cv.extend(y_hat)\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true_cv, y_pred_cv))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true_cv, y_pred_cv))\n",
    "    print()\n",
    "    print(\"**********************************************\")\n",
    "    print()\n",
    "    \n",
    "# Consolidando DataFrame\n",
    "df_resultados = pd.DataFrame(resultados_modelo)\n",
    "\n",
    "arquivo_resultados = os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_resultados_{nome_modelo}.xlsx\")\n",
    "if os.path.isfile(arquivo_resultados): os.remove(arquivo_resultados)\n",
    "df_resultados.to_excel(arquivo_resultados, index=False)\n",
    "    \n",
    "print(\"############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\")\n",
    "display(df_resultados.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise dos Resultados (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:10:32.077065Z",
     "start_time": "2021-05-03T09:10:31.295643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Análise por modelo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>cv</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBOOST</th>\n",
       "      <td>cv</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBOOST</th>\n",
       "      <td>treino-teste</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>treino-teste</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>cv</td>\n",
       "      <td>0.942587</td>\n",
       "      <td>0.094760</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.741270</td>\n",
       "      <td>0.941168</td>\n",
       "      <td>0.097609</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.732748</td>\n",
       "      <td>0.942916</td>\n",
       "      <td>0.093782</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.744292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>treino-teste</td>\n",
       "      <td>0.933862</td>\n",
       "      <td>0.116390</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.933098</td>\n",
       "      <td>0.117816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.710714</td>\n",
       "      <td>0.933972</td>\n",
       "      <td>0.115759</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.716230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 base       acc                                 f1            \\\n",
       "                           mean       std  max       min      mean       std   \n",
       "model                                                                          \n",
       "MLP                cv  1.000000  0.000000  1.0  1.000000  1.000000  0.000000   \n",
       "XGBOOST            cv  1.000000  0.000000  1.0  1.000000  1.000000  0.000000   \n",
       "XGBOOST  treino-teste  1.000000  0.000000  1.0  1.000000  1.000000  0.000000   \n",
       "MLP      treino-teste  0.999974  0.000065  1.0  0.999841  0.999974  0.000065   \n",
       "SVM                cv  0.942587  0.094760  1.0  0.741270  0.941168  0.097609   \n",
       "SVM      treino-teste  0.933862  0.116390  1.0  0.714286  0.933098  0.117816   \n",
       "\n",
       "                             auc                           \n",
       "         max       min      mean       std  max       min  \n",
       "model                                                      \n",
       "MLP      1.0  1.000000  1.000000  0.000000  1.0  1.000000  \n",
       "XGBOOST  1.0  1.000000  1.000000  0.000000  1.0  1.000000  \n",
       "XGBOOST  1.0  1.000000  1.000000  0.000000  1.0  1.000000  \n",
       "MLP      1.0  0.999841  0.999973  0.000066  1.0  0.999839  \n",
       "SVM      1.0  0.732748  0.942916  0.093782  1.0  0.744292  \n",
       "SVM      1.0  0.710714  0.933972  0.115759  1.0  0.716230  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Análise por aparelho/modelo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>model</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">LC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.906762</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.904841</td>\n",
       "      <td>0.906200</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.908224</td>\n",
       "      <td>0.904230</td>\n",
       "      <td>0.905762</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.907780</td>\n",
       "      <td>0.903800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.887872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.887872</td>\n",
       "      <td>0.887872</td>\n",
       "      <td>0.887601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.887601</td>\n",
       "      <td>0.887601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">LF</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.999841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999839</td>\n",
       "      <td>0.999839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.748762</td>\n",
       "      <td>0.007253</td>\n",
       "      <td>0.758968</td>\n",
       "      <td>0.741270</td>\n",
       "      <td>0.740807</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.750905</td>\n",
       "      <td>0.732748</td>\n",
       "      <td>0.751731</td>\n",
       "      <td>0.007258</td>\n",
       "      <td>0.762016</td>\n",
       "      <td>0.744292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.710714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710714</td>\n",
       "      <td>0.710714</td>\n",
       "      <td>0.716230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.716230</td>\n",
       "      <td>0.716230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">LI</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MO</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MT</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">PC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     acc                                \\\n",
       "                                    mean       std       max       min   \n",
       "appliance model   base                                                   \n",
       "LC        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            0.906762  0.001764  0.908730  0.904841   \n",
       "                  treino-teste  0.888889       NaN  0.888889  0.888889   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "LF        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  0.999841       NaN  0.999841  0.999841   \n",
       "          SVM     cv            0.748762  0.007253  0.758968  0.741270   \n",
       "                  treino-teste  0.714286       NaN  0.714286  0.714286   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "LI        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "MO        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "MT        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "PC        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "\n",
       "                                      f1                                \\\n",
       "                                    mean       std       max       min   \n",
       "appliance model   base                                                   \n",
       "LC        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            0.906200  0.001793  0.908224  0.904230   \n",
       "                  treino-teste  0.887872       NaN  0.887872  0.887872   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "LF        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  0.999841       NaN  0.999841  0.999841   \n",
       "          SVM     cv            0.740807  0.007481  0.750905  0.732748   \n",
       "                  treino-teste  0.710714       NaN  0.710714  0.710714   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "LI        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "MO        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "MT        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "PC        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "\n",
       "                                     auc                                \n",
       "                                    mean       std       max       min  \n",
       "appliance model   base                                                  \n",
       "LC        MLP     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          SVM     cv            0.905762  0.001785  0.907780  0.903800  \n",
       "                  treino-teste  0.887601       NaN  0.887601  0.887601  \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "LF        MLP     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  0.999839       NaN  0.999839  0.999839  \n",
       "          SVM     cv            0.751731  0.007258  0.762016  0.744292  \n",
       "                  treino-teste  0.716230       NaN  0.716230  0.716230  \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "LI        MLP     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "MO        MLP     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "MT        MLP     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "PC        MLP     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_resultados_svm = pd.read_excel(os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_resultados_svm.xlsx\"), engine='openpyxl')\n",
    "df_resultados_svm[\"model\"] = \"SVM\"\n",
    "\n",
    "df_resultados_xgboost = pd.read_excel(os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_resultados_xgboost.xlsx\"), engine='openpyxl')\n",
    "df_resultados_xgboost[\"model\"] = \"XGBOOST\"\n",
    "\n",
    "df_resultados_mlp = pd.read_excel(os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_resultados_mlp.xlsx\"), engine='openpyxl')\n",
    "df_resultados_mlp[\"model\"] = \"MLP\"\n",
    "\n",
    "# df_resultados_elm = pd.read_excel(os.path.join(caminho_dados_notebook, \"df_resultados_elm.xlsx\"))\n",
    "# df_resultados_elm[\"model\"] = \"ELM\"\n",
    "\n",
    "df_analise = pd.concat([\n",
    "    df_resultados_svm,\n",
    "    df_resultados_xgboost,\n",
    "    df_resultados_mlp, \n",
    "#     df_resultados_elm,  \n",
    "])\n",
    "\n",
    "print(\"* Análise por modelo:\")\n",
    "df_analise_modelo = df_analise.groupby([\"model\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"f1\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"auc\": [\"mean\",\"std\",\"max\",\"min\"]\n",
    "}).reset_index().sort_values(('f1','mean'), ascending=False).set_index(\"model\")\n",
    "display(df_analise_modelo)\n",
    "df_analise_modelo.to_excel(os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_analise_modelos.xlsx\"))\n",
    "\n",
    "print()\n",
    "print(\"* Análise por aparelho/modelo:\")\n",
    "df_analise_aparelho = df_analise.groupby([\"appliance\",\"model\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"f1\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"auc\": [\"mean\",\"std\",\"max\",\"min\"]\n",
    "})#.reset_index().sort_values(('f1','mean'), ascending=False).set_index([\"aparelho\",\"metodologia\"])\n",
    "display(df_analise_aparelho)\n",
    "df_analise_aparelho.to_excel(os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_analise_aparelhos.xls\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:10:32.109285Z",
     "start_time": "2021-05-03T09:10:32.079991Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:10:32.155124Z",
     "start_time": "2021-05-03T09:10:32.113288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Diego Luiz Cavalca\n",
      "\n",
      "Last updated: Mon Jan 24 2022 08:52:41Hora oficial do Brasil\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.8\n",
      "IPython version      : 7.21.0\n",
      "\n",
      "Compiler    : MSC v.1928 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 158 Stepping 9, GenuineIntel\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 5e5bccaaf9e541e11be67706c7eb7d7b39a8be65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -a \"Diego Luiz Cavalca\" -u -n -t -z -v -m -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

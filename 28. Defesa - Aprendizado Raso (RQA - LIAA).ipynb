{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Defesa - Dataset LIAA - Aprendizado Raso em Atributos RQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estruturação de pipeline baseado em aprendizado raso utilizando atributos de alta frequência.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T17:00:00.198228Z",
     "start_time": "2021-05-02T16:59:56.833044Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "from pretty_confusion_matrix import *\n",
    "\n",
    "# TODO: implementar rotina na classe PyNILM.utils\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "def listar_variaveis_memoria(ambiente):\n",
    "    print(\"* Variáveis instanciadas em memória:\")\n",
    "    print(\"---\")\n",
    "    total = 0\n",
    "    for name, size in sorted(((name, sys.getsizeof(value)) for name, value in ambiente.items()),\n",
    "                             key= lambda x: -x[1])[:10]:\n",
    "        total += size\n",
    "        print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))\n",
    "    print(\"---\")\n",
    "    print(\"Total:\", sizeof_fmt(total))\n",
    "    \n",
    "# TODO: implementar na classe utils\n",
    "def highlight_col(x):\n",
    "    r = 'background-color: #D9D9D9'\n",
    "    df1 = pd.DataFrame('', index=x.index, columns=x.columns)\n",
    "    df1.iloc[:, -2] = r\n",
    "    return df1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T17:00:00.322361Z",
     "start_time": "2021-05-02T17:00:00.201233Z"
    }
   },
   "outputs": [],
   "source": [
    "# CONSTANTES FUNDAMENTAIS DE ORGANIZACAO DE PASTAS/ARQUIVOS\n",
    "RESIDENCIA = 3\n",
    "\n",
    "# Path do arquivo H5 (base REDD ja preparada p/ NILMTK) e outros insumos fundamentais\n",
    "caminho_dados = \"D:/Projetos/phd-thesis/datasets/\"\n",
    "\n",
    "# Definir diretorios onde iremos salvar os insumos gerados do notebook (dados, imagens, etc.)\n",
    "caminho_dados_notebook = os.path.join(caminho_dados, \"28\") # Num. notebook\n",
    "if not os.path.isdir(caminho_dados_notebook):\n",
    "    os.makedirs(caminho_dados_notebook)\n",
    "caminho_imagens_notebook = os.path.join(caminho_dados_notebook, \"imagens\") # Num. notebook\n",
    "if not os.path.isdir(caminho_imagens_notebook):\n",
    "    os.makedirs(caminho_imagens_notebook)\n",
    "\n",
    "# Path do arquivo H5 (base REDD ja preparada p/ NILMTK)\n",
    "caminho_redd = os.path.join(caminho_dados, \"REDD/low_freq\")\n",
    "\n",
    "# Path completo do arquivo REDD\n",
    "arquivo_dataset = os.path.join(caminho_redd, \"redd.h5\")\n",
    "\n",
    "# VARIAVEL AUXILIAR\n",
    "# Path dos arquivos relacionados as janelas\n",
    "caminho_janelas = os.path.join(caminho_redd, \"../../phd\")\n",
    "if not os.path.isdir(caminho_janelas):\n",
    "    os.makedirs(caminho_janelas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T17:00:01.903538Z",
     "start_time": "2021-05-02T17:00:00.325362Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from six import iteritems\n",
    "\n",
    "from nilmtk import DataSet, TimeFrame, MeterGroup, HDFDataStore\n",
    "from nilmtk.legacy.disaggregate import CombinatorialOptimisation, FHMM\n",
    "import nilmtk.utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando datasets\n",
    "df_treino = pd.read_csv(os.path.join(caminho_dados_notebook, 'training_windows.txt'))\n",
    "df_validacao = pd.read_csv(os.path.join(caminho_dados_notebook, 'validation_windows.txt'))\n",
    "\n",
    "# Selecionando feature dominio do tempo e frequencia / outputs (status dos aparelhos - dummy)\n",
    "colunas_janela = df_treino.columns[:512]\n",
    "\n",
    "colunas_output = ['LC', 'LI', 'MO', 'MT', 'PC', 'LF']\n",
    "\n",
    "# Preparando dados de treino e validacao\n",
    "X_treino = df_treino[colunas_janela]\n",
    "X_validacao = df_validacao[colunas_janela]\n",
    "\n",
    "y_treino = df_treino[colunas_output].replace(-1, 0)\n",
    "y_validacao = df_validacao[colunas_output].replace(-1, 0)\n",
    "\n",
    "del df_treino\n",
    "del df_validacao\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento e Avaliação dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T17:00:27.268721Z",
     "start_time": "2021-05-02T17:00:16.855220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "# from PyNILM.dados.janelas import Janelas\n",
    "from PyNILM.dados.janelas import Janelas\n",
    "from PyNILM.dados.utils import *\n",
    "\n",
    "from PyNILM.avaliacao.metricas import *\n",
    "from PyNILM.avaliacao.graficos import *\n",
    "from PyNILM.avaliacao.analises import *\n",
    "\n",
    "from PyNILM.modelos.utils import *\n",
    "from PyNILM.modelos.dlafe import DLAFE\n",
    "from PyNILM.modelos.rqa import RQA\n",
    "\n",
    "# Inicializar uso GPU\n",
    "start_tf_session(memory_limit=int(1024*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T17:00:27.377109Z",
     "start_time": "2021-05-02T17:00:27.271695Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atributos RQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrqa.time_series import TimeSeries\n",
    "from pyrqa.settings import Settings\n",
    "from pyrqa.analysis_type import Classic\n",
    "from pyrqa.neighbourhood import FixedRadius\n",
    "from pyrqa.metric import EuclideanMetric\n",
    "from pyrqa.computation import RQAComputation\n",
    "\n",
    "def converter_janelas_para_rqa(\n",
    "    X,\n",
    "    atributos_rqa_estudo=None,\n",
    "    arquivo_rqa=None):\n",
    "    atributos_rqa = [\n",
    "        \"Minimum diagonal line length (L_min)\",\n",
    "        \"Minimum vertical line length (V_min)\",\n",
    "        \"Minimum white vertical line length (W_min)\",\n",
    "        \"Recurrence rate (RR)\",\n",
    "        \"Determinism (DET)\",\n",
    "        \"Average diagonal line length (L)\",\n",
    "        \"Longest diagonal line length (L_max)\",\n",
    "        \"Divergence (DIV)\",\n",
    "        \"Entropy diagonal lines (L_entr)\",\n",
    "        \"Laminarity (LAM)\",\n",
    "        \"Trapping time (TT)\",\n",
    "        \"Longest vertical line length (V_max)\",\n",
    "        \"Entropy vertical lines (V_entr)\",\n",
    "        \"Average white vertical line length (W)\",\n",
    "        \"Longest white vertical line length (W_max)\",\n",
    "        \"Longest white vertical line length inverse (W_div)\",\n",
    "        \"Entropy white vertical lines (W_entr)\",\n",
    "        \"Ratio determinism / recurrence rate (DET/RR)\",\n",
    "        \"Ratio laminarity / determinism (LAM/DET)\"\n",
    "    ]\n",
    "\n",
    "    rqa_data = []\n",
    "    for x in tqdm(X, total=X.shape[0]) :\n",
    "\n",
    "        # Calculating RQA attributes\n",
    "        time_series = TimeSeries(x,\n",
    "                    embedding_dimension=PARAMETROS_RP[\"dimension\"],\n",
    "                    time_delay=PARAMETROS_RP[\"time_delay\"])\n",
    "        settings = Settings(time_series,\n",
    "                            analysis_type=Classic,\n",
    "                            neighbourhood=FixedRadius(PARAMETROS_RP[\"percentage\"]/100), \n",
    "                            # PS.: Utilizando percentage ao inves de threshold \n",
    "                            # devido a semanticas distintas entre libs (pyts e pyrqa)\n",
    "                            # bem como distincao entre RPs (cnn) e RQAs (supervisionado).\n",
    "                            similarity_measure=EuclideanMetric)\n",
    "        computation = RQAComputation.create(settings, verbose=False)\n",
    "        rqa_result = computation.run()\n",
    "\n",
    "        rqa_data.append( list(np.nan_to_num(rqa_result.to_array())) )\n",
    "\n",
    "    # Numpy to Pandas \n",
    "    df_rqa = pd.DataFrame(\n",
    "        data=rqa_data,\n",
    "        columns=atributos_rqa\n",
    "    )\n",
    "    if arquivo_rqa:\n",
    "        if os.path.isfile(arquivo_rqa): os.remove(arquivo_rqa)\n",
    "        df_rqa.to_excel(arquivo_rqa, index=False)\n",
    "\n",
    "    if not atributos_rqa_estudo:\n",
    "        return df_rqa\n",
    "    else:\n",
    "        return df_rqa[atributos_rqa_estudo]\n",
    "\n",
    "# Parametros execucao do experimento\n",
    "atributos = \"rqa\" \n",
    "\n",
    "atributos_rqa_estudo = [\n",
    "        \"Recurrence rate (RR)\",\n",
    "        \"Determinism (DET)\"\n",
    "    ]\n",
    "\n",
    "# Carregando dados RQA (treino)\n",
    "arquivo_rqa_treino = os.path.join(caminho_dados_notebook, f\"rqa_treino.xlsx\")\n",
    "if os.path.isfile(arquivo_rqa_treino):\n",
    "    X_treino = pd.read_excel(arquivo_rqa_treino,engine='openpyxl')[atributos_rqa_estudo]\n",
    "else:\n",
    "    X_treino = converter_janelas_para_rqa(\n",
    "        X_treino.values,\n",
    "        atributos_rqa_estudo=atributos_rqa_estudo,\n",
    "        arquivo_rqa=arquivo_rqa_treino)\n",
    "\n",
    "# Carregando dados RQA (validacao)\n",
    "arquivo_rqa_validacao = os.path.join(caminho_dados_notebook, f\"rqa_validacao.xlsx\")\n",
    "if os.path.isfile(arquivo_rqa_validacao):\n",
    "    X_validacao = pd.read_excel(arquivo_rqa_validacao,engine='openpyxl')[atributos_rqa_estudo]\n",
    "else:\n",
    "    X_validacao = converter_janelas_para_rqa(\n",
    "        X_validacao.values,\n",
    "        atributos_rqa_estudo=atributos_rqa_estudo,\n",
    "        arquivo_rqa=arquivo_rqa_validacao)\n",
    "\n",
    "\n",
    "# Dados agregados (validacao cruzada)\n",
    "X_cv = pd.concat([X_treino, X_validacao]).reset_index(drop=True) \n",
    "y_cv = pd.concat([y_treino, y_validacao]).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T22:18:59.268806Z",
     "start_time": "2021-05-02T17:03:12.352604Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "\n",
      "* Aparelho `LC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.36      0.43     12400\n",
      "           1       0.54      0.72      0.61     12800\n",
      "\n",
      "    accuracy                           0.54     25200\n",
      "   macro avg       0.54      0.54      0.52     25200\n",
      "weighted avg       0.54      0.54      0.52     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[4414 7986]\n",
      " [3600 9200]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c8f1cf25a249729b6217f2f6f4cfff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.32      0.40     31000\n",
      "           1       0.52      0.72      0.61     32000\n",
      "\n",
      "    accuracy                           0.52     63000\n",
      "   macro avg       0.52      0.52      0.50     63000\n",
      "weighted avg       0.52      0.52      0.50     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[10003 20997]\n",
      " [ 9000 23000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LI`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85     12400\n",
      "           1       0.87      0.84      0.86     12800\n",
      "\n",
      "    accuracy                           0.85     25200\n",
      "   macro avg       0.85      0.85      0.85     25200\n",
      "weighted avg       0.85      0.85      0.85     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[10720  1680]\n",
      " [ 1984 10816]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651bae8c15bc42eea85d41a0ce258867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86     31000\n",
      "           1       0.87      0.85      0.86     32000\n",
      "\n",
      "    accuracy                           0.86     63000\n",
      "   macro avg       0.86      0.86      0.86     63000\n",
      "weighted avg       0.86      0.86      0.86     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[26959  4041]\n",
      " [ 4771 27229]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MO`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61     12400\n",
      "           1       0.60      0.47      0.53     12800\n",
      "\n",
      "    accuracy                           0.57     25200\n",
      "   macro avg       0.58      0.57      0.57     25200\n",
      "weighted avg       0.58      0.57      0.57     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[8400 4000]\n",
      " [6800 6000]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4d40162e6749e1854f3e31c6db98d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.71      0.63     31000\n",
      "           1       0.62      0.47      0.54     32000\n",
      "\n",
      "    accuracy                           0.59     63000\n",
      "   macro avg       0.59      0.59      0.58     63000\n",
      "weighted avg       0.59      0.59      0.58     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[21977  9023]\n",
      " [17000 15000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MT`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83     12400\n",
      "           1       0.86      0.79      0.82     12800\n",
      "\n",
      "    accuracy                           0.83     25200\n",
      "   macro avg       0.83      0.83      0.83     25200\n",
      "weighted avg       0.83      0.83      0.83     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[10809  1591]\n",
      " [ 2738 10062]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550f391bcf2a4d82a560c5f1bd5f7047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85     31000\n",
      "           1       0.88      0.80      0.84     32000\n",
      "\n",
      "    accuracy                           0.84     63000\n",
      "   macro avg       0.85      0.84      0.84     63000\n",
      "weighted avg       0.85      0.84      0.84     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[27368  3632]\n",
      " [ 6248 25752]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `PC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.73     12400\n",
      "           1       0.74      0.73      0.74     12800\n",
      "\n",
      "    accuracy                           0.73     25200\n",
      "   macro avg       0.73      0.73      0.73     25200\n",
      "weighted avg       0.73      0.73      0.73     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[9200 3200]\n",
      " [3487 9313]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796e2156f548446ab3cf2b75f40b72e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74     31000\n",
      "           1       0.75      0.74      0.75     32000\n",
      "\n",
      "    accuracy                           0.74     63000\n",
      "   macro avg       0.74      0.74      0.74     63000\n",
      "weighted avg       0.74      0.74      0.74     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[22999  8001]\n",
      " [ 8207 23793]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LF`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.65      0.58     12400\n",
      "           1       0.56      0.43      0.49     12800\n",
      "\n",
      "    accuracy                           0.54     25200\n",
      "   macro avg       0.54      0.54      0.53     25200\n",
      "weighted avg       0.54      0.54      0.53     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[8002 4398]\n",
      " [7289 5511]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440c510c7c4246f2ab04c29e83a91edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.65      0.58     31000\n",
      "           1       0.56      0.43      0.49     32000\n",
      "\n",
      "    accuracy                           0.54     63000\n",
      "   macro avg       0.54      0.54      0.53     63000\n",
      "weighted avg       0.54      0.54      0.53     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[20033 10967]\n",
      " [18162 13838]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LC</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.523857</td>\n",
       "      <td>0.003016</td>\n",
       "      <td>0.526349</td>\n",
       "      <td>0.518968</td>\n",
       "      <td>0.502690</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.504807</td>\n",
       "      <td>0.498104</td>\n",
       "      <td>0.520714</td>\n",
       "      <td>0.002982</td>\n",
       "      <td>0.523170</td>\n",
       "      <td>0.515862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.540238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540238</td>\n",
       "      <td>0.540238</td>\n",
       "      <td>0.523034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523034</td>\n",
       "      <td>0.523034</td>\n",
       "      <td>0.537359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537359</td>\n",
       "      <td>0.537359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LF</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.537635</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.543175</td>\n",
       "      <td>0.529524</td>\n",
       "      <td>0.533119</td>\n",
       "      <td>0.005471</td>\n",
       "      <td>0.538765</td>\n",
       "      <td>0.525246</td>\n",
       "      <td>0.539332</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>0.544864</td>\n",
       "      <td>0.531164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.536230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.536230</td>\n",
       "      <td>0.536230</td>\n",
       "      <td>0.531654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.531654</td>\n",
       "      <td>0.531654</td>\n",
       "      <td>0.537935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537935</td>\n",
       "      <td>0.537935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LI</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.860127</td>\n",
       "      <td>0.003047</td>\n",
       "      <td>0.865238</td>\n",
       "      <td>0.857619</td>\n",
       "      <td>0.860123</td>\n",
       "      <td>0.003045</td>\n",
       "      <td>0.865232</td>\n",
       "      <td>0.857619</td>\n",
       "      <td>0.860276</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>0.865345</td>\n",
       "      <td>0.857848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.854603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.854603</td>\n",
       "      <td>0.854603</td>\n",
       "      <td>0.854601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.854601</td>\n",
       "      <td>0.854601</td>\n",
       "      <td>0.854758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.854758</td>\n",
       "      <td>0.854758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MO</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.586937</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.591190</td>\n",
       "      <td>0.582619</td>\n",
       "      <td>0.581805</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>0.586307</td>\n",
       "      <td>0.577364</td>\n",
       "      <td>0.588843</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>0.593065</td>\n",
       "      <td>0.584536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.567506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567506</td>\n",
       "      <td>0.567506</td>\n",
       "      <td>0.573085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.573085</td>\n",
       "      <td>0.573085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MT</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.843175</td>\n",
       "      <td>0.005706</td>\n",
       "      <td>0.849762</td>\n",
       "      <td>0.836190</td>\n",
       "      <td>0.843059</td>\n",
       "      <td>0.005770</td>\n",
       "      <td>0.849747</td>\n",
       "      <td>0.836001</td>\n",
       "      <td>0.843794</td>\n",
       "      <td>0.005576</td>\n",
       "      <td>0.850136</td>\n",
       "      <td>0.836941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.828214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.828214</td>\n",
       "      <td>0.828214</td>\n",
       "      <td>0.828063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.828063</td>\n",
       "      <td>0.828063</td>\n",
       "      <td>0.828894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.828894</td>\n",
       "      <td>0.828894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PC</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.742730</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.746111</td>\n",
       "      <td>0.736032</td>\n",
       "      <td>0.742689</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>0.746077</td>\n",
       "      <td>0.735973</td>\n",
       "      <td>0.742717</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.735980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.734643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734643</td>\n",
       "      <td>0.734643</td>\n",
       "      <td>0.734638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734638</td>\n",
       "      <td>0.734638</td>\n",
       "      <td>0.734757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734757</td>\n",
       "      <td>0.734757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             acc                                      f1  \\\n",
       "                            mean       std       max       min      mean   \n",
       "appliance base                                                             \n",
       "LC        cv            0.523857  0.003016  0.526349  0.518968  0.502690   \n",
       "          treino-teste  0.540238       NaN  0.540238  0.540238  0.523034   \n",
       "LF        cv            0.537635  0.005499  0.543175  0.529524  0.533119   \n",
       "          treino-teste  0.536230       NaN  0.536230  0.536230  0.531654   \n",
       "LI        cv            0.860127  0.003047  0.865238  0.857619  0.860123   \n",
       "          treino-teste  0.854603       NaN  0.854603  0.854603  0.854601   \n",
       "MO        cv            0.586937  0.003658  0.591190  0.582619  0.581805   \n",
       "          treino-teste  0.571429       NaN  0.571429  0.571429  0.567506   \n",
       "MT        cv            0.843175  0.005706  0.849762  0.836190  0.843059   \n",
       "          treino-teste  0.828214       NaN  0.828214  0.828214  0.828063   \n",
       "PC        cv            0.742730  0.003953  0.746111  0.736032  0.742689   \n",
       "          treino-teste  0.734643       NaN  0.734643  0.734643  0.734638   \n",
       "\n",
       "                                                           auc            \\\n",
       "                             std       max       min      mean       std   \n",
       "appliance base                                                             \n",
       "LC        cv            0.002701  0.504807  0.498104  0.520714  0.002982   \n",
       "          treino-teste       NaN  0.523034  0.523034  0.537359       NaN   \n",
       "LF        cv            0.005471  0.538765  0.525246  0.539332  0.005515   \n",
       "          treino-teste       NaN  0.531654  0.531654  0.537935       NaN   \n",
       "LI        cv            0.003045  0.865232  0.857619  0.860276  0.003005   \n",
       "          treino-teste       NaN  0.854601  0.854601  0.854758       NaN   \n",
       "MO        cv            0.003703  0.586307  0.577364  0.588843  0.003660   \n",
       "          treino-teste       NaN  0.567506  0.567506  0.573085       NaN   \n",
       "MT        cv            0.005770  0.849747  0.836001  0.843794  0.005576   \n",
       "          treino-teste       NaN  0.828063  0.828063  0.828894       NaN   \n",
       "PC        cv            0.003962  0.746077  0.735973  0.742717  0.003974   \n",
       "          treino-teste       NaN  0.734638  0.734638  0.734757       NaN   \n",
       "\n",
       "                                            \n",
       "                             max       min  \n",
       "appliance base                              \n",
       "LC        cv            0.523170  0.515862  \n",
       "          treino-teste  0.537359  0.537359  \n",
       "LF        cv            0.544864  0.531164  \n",
       "          treino-teste  0.537935  0.537935  \n",
       "LI        cv            0.865345  0.857848  \n",
       "          treino-teste  0.854758  0.854758  \n",
       "MO        cv            0.593065  0.584536  \n",
       "          treino-teste  0.573085  0.573085  \n",
       "MT        cv            0.850136  0.836941  \n",
       "          treino-teste  0.828894  0.828894  \n",
       "PC        cv            0.746114  0.735980  \n",
       "          treino-teste  0.734757  0.734757  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo = SVC(kernel='rbf', random_state=SEED)\n",
    "nome_modelo = \"svm\"\n",
    "\n",
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \n",
    "    \"base\": []\n",
    "}\n",
    "\n",
    "for rotulo_aparelho in colunas_output:\n",
    "    \n",
    "    print(\"****************************************************************\\n\")\n",
    "    print(f\"* Aparelho `{rotulo_aparelho}`...\\n\")\n",
    "    \n",
    "    #######################################################################\n",
    "    #                AVALIACAO 1 - Base de treino/validacao               #\n",
    "    #######################################################################\n",
    "\n",
    "    # # Filtrando output/status por aparelho\n",
    "    y_treino_aparelho = y_treino[rotulo_aparelho]\n",
    "    y_validacao_aparelho = y_validacao[rotulo_aparelho]\n",
    "\n",
    "    print(f\"  - Avaliando modelo através da base treino/validacao...\")\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem (lote validacao):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_validacao_aparelho).items():\n",
    "        print(f\"       - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_validacao_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "\n",
    "    # Treinando modelo\n",
    "    print(f\"     -> Treinando modelo...\\n\")\n",
    "    clf = clone(modelo)\n",
    "        \n",
    "    clf.fit(X_treino, y_treino_aparelho)\n",
    "\n",
    "    # Prevendo conjunto de dados\n",
    "    y_hat = clf.predict(X_validacao)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "    resultados_modelo[\"fold\"].append(\"-\")\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_validacao_aparelho, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_validacao_aparelho, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_validacao_aparelho, y_hat) if np.unique(y_validacao_aparelho).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"treino-teste\")\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_validacao_aparelho, y_hat))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_validacao_aparelho, y_hat))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    #######################################################################\n",
    "    #                  AVALIACAO 2 - Validacao Cruzada                    #\n",
    "    #######################################################################\n",
    "    \n",
    "    y_true_cv, y_pred_cv  = [], []\n",
    "\n",
    "    print(f\"  - Avaliando através de validação cruzada ({skf.n_splits}-folds)...\")\n",
    "\n",
    "    # Filtrando output/status por aparelho\n",
    "    y_aparelho = y_cv[rotulo_aparelho]\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem:\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_aparelho).items():\n",
    "        print(f\"        - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "    \n",
    "\n",
    "    print(f\"     -> Avaliando modelo (CV - {skf.n_splits} folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in tqdm_notebook(enumerate(skf.split(X_cv, y_aparelho)), total=skf.n_splits):\n",
    "        \n",
    "        # Preparando lotes\n",
    "        X_treino_cv, X_teste_cv = X_cv.iloc[idx_treino], X_cv.iloc[idx_teste]\n",
    "        y_treino_cv, y_teste_cv = y_aparelho.iloc[idx_treino], y_aparelho.iloc[idx_teste]\n",
    "\n",
    "        # Treinando modelo\n",
    "        clf = clone(modelo)\n",
    "        \n",
    "        clf.fit(X_treino_cv, y_treino_cv)\n",
    "\n",
    "        # Prevendo conjunto de dados\n",
    "        y_hat = clf.predict(X_teste_cv)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste_cv, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste_cv, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste_cv, y_hat) if np.unique(y_teste_cv).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"cv\")\n",
    "\n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true_cv.extend(y_teste_cv)\n",
    "        y_pred_cv.extend(y_hat)\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true_cv, y_pred_cv))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true_cv, y_pred_cv))\n",
    "    print()\n",
    "    print(\"**********************************************\")\n",
    "    print()\n",
    "    \n",
    "# Consolidando DataFrame\n",
    "df_resultados = pd.DataFrame(resultados_modelo)\n",
    "\n",
    "arquivo_resultados = os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_resultados_{nome_modelo}.xlsx\")\n",
    "if os.path.isfile(arquivo_resultados): os.remove(arquivo_resultados)\n",
    "df_resultados.to_excel(arquivo_resultados, index=False)\n",
    "    \n",
    "print(\"############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\")\n",
    "display(df_resultados.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T19:59:41.720698Z",
     "start_time": "2020-08-31T19:59:41.680673Z"
    }
   },
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T03:52:19.841404Z",
     "start_time": "2021-05-02T22:19:01.487888Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "\n",
      "* Aparelho `LC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96     12400\n",
      "           1       0.96      0.97      0.96     12800\n",
      "\n",
      "    accuracy                           0.96     25200\n",
      "   macro avg       0.96      0.96      0.96     25200\n",
      "weighted avg       0.96      0.96      0.96     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[11839   561]\n",
      " [  367 12433]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a76cc553754679a1b7054b2e616c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[30941    59]\n",
      " [   46 31954]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LI`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     12400\n",
      "           1       0.99      0.98      0.98     12800\n",
      "\n",
      "    accuracy                           0.98     25200\n",
      "   macro avg       0.98      0.98      0.98     25200\n",
      "weighted avg       0.98      0.98      0.98     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12269   131]\n",
      " [  287 12513]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859560e9cc42403abce9b9dcb91ce6b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[30992     8]\n",
      " [   14 31986]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MO`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     12400\n",
      "           1       0.99      0.98      0.99     12800\n",
      "\n",
      "    accuracy                           0.99     25200\n",
      "   macro avg       0.99      0.99      0.99     25200\n",
      "weighted avg       0.99      0.99      0.99     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12318    82]\n",
      " [  229 12571]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4805ee9517bd4a7ba05602e7c27647c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[30972    28]\n",
      " [   31 31969]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MT`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12347    53]\n",
      " [   33 12767]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5603710412b840c89d79dd0e34501d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    2 31998]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `PC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     12400\n",
      "           1       0.98      0.98      0.98     12800\n",
      "\n",
      "    accuracy                           0.98     25200\n",
      "   macro avg       0.98      0.98      0.98     25200\n",
      "weighted avg       0.98      0.98      0.98     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12153   247]\n",
      " [  223 12577]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31c43f8d6594d5eaa4eef1ad4413080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[30975    25]\n",
      " [   30 31970]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LF`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     12400\n",
      "           1       0.99      0.97      0.98     12800\n",
      "\n",
      "    accuracy                           0.98     25200\n",
      "   macro avg       0.98      0.98      0.98     25200\n",
      "weighted avg       0.98      0.98      0.98     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12321    79]\n",
      " [  366 12434]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363760608c7d4ed0abfb20cf296b5071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[30987    13]\n",
      " [    8 31992]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LC</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.998333</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.998413</td>\n",
       "      <td>0.998175</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.998412</td>\n",
       "      <td>0.998174</td>\n",
       "      <td>0.998330</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.998410</td>\n",
       "      <td>0.998170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.963175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.963175</td>\n",
       "      <td>0.963175</td>\n",
       "      <td>0.963154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.963154</td>\n",
       "      <td>0.963154</td>\n",
       "      <td>0.963043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.963043</td>\n",
       "      <td>0.963043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LF</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999667</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999365</td>\n",
       "      <td>0.999667</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999365</td>\n",
       "      <td>0.999665</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.999370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.982341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.982341</td>\n",
       "      <td>0.982341</td>\n",
       "      <td>0.982341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.982341</td>\n",
       "      <td>0.982341</td>\n",
       "      <td>0.982518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.982518</td>\n",
       "      <td>0.982518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LI</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999651</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999444</td>\n",
       "      <td>0.999651</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999444</td>\n",
       "      <td>0.999652</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.983413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.983413</td>\n",
       "      <td>0.983413</td>\n",
       "      <td>0.983411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.983411</td>\n",
       "      <td>0.983411</td>\n",
       "      <td>0.983507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.983507</td>\n",
       "      <td>0.983507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MO</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999063</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.999206</td>\n",
       "      <td>0.998730</td>\n",
       "      <td>0.999063</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.999206</td>\n",
       "      <td>0.998730</td>\n",
       "      <td>0.999064</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.999209</td>\n",
       "      <td>0.998730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.987659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987659</td>\n",
       "      <td>0.987659</td>\n",
       "      <td>0.987657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987657</td>\n",
       "      <td>0.987657</td>\n",
       "      <td>0.987748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987748</td>\n",
       "      <td>0.987748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MT</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.996587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996587</td>\n",
       "      <td>0.996587</td>\n",
       "      <td>0.996586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996586</td>\n",
       "      <td>0.996586</td>\n",
       "      <td>0.996574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996574</td>\n",
       "      <td>0.996574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PC</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999127</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.999524</td>\n",
       "      <td>0.998095</td>\n",
       "      <td>0.999127</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.999524</td>\n",
       "      <td>0.998095</td>\n",
       "      <td>0.999128</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.999526</td>\n",
       "      <td>0.998095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.981349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981349</td>\n",
       "      <td>0.981349</td>\n",
       "      <td>0.981344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981344</td>\n",
       "      <td>0.981344</td>\n",
       "      <td>0.981329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981329</td>\n",
       "      <td>0.981329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             acc                                      f1  \\\n",
       "                            mean       std       max       min      mean   \n",
       "appliance base                                                             \n",
       "LC        cv            0.998333  0.000112  0.998413  0.998175  0.998333   \n",
       "          treino-teste  0.963175       NaN  0.963175  0.963175  0.963154   \n",
       "LF        cv            0.999667  0.000220  0.999921  0.999365  0.999667   \n",
       "          treino-teste  0.982341       NaN  0.982341  0.982341  0.982341   \n",
       "LI        cv            0.999651  0.000191  0.999841  0.999444  0.999651   \n",
       "          treino-teste  0.983413       NaN  0.983413  0.983413  0.983411   \n",
       "MO        cv            0.999063  0.000198  0.999206  0.998730  0.999063   \n",
       "          treino-teste  0.987659       NaN  0.987659  0.987659  0.987657   \n",
       "MT        cv            0.999968  0.000043  1.000000  0.999921  0.999968   \n",
       "          treino-teste  0.996587       NaN  0.996587  0.996587  0.996586   \n",
       "PC        cv            0.999127  0.000589  0.999524  0.998095  0.999127   \n",
       "          treino-teste  0.981349       NaN  0.981349  0.981349  0.981344   \n",
       "\n",
       "                                                           auc            \\\n",
       "                             std       max       min      mean       std   \n",
       "appliance base                                                             \n",
       "LC        cv            0.000112  0.998412  0.998174  0.998330  0.000111   \n",
       "          treino-teste       NaN  0.963154  0.963154  0.963043       NaN   \n",
       "LF        cv            0.000220  0.999921  0.999365  0.999665  0.000219   \n",
       "          treino-teste       NaN  0.982341  0.982341  0.982518       NaN   \n",
       "LI        cv            0.000191  0.999841  0.999444  0.999652  0.000189   \n",
       "          treino-teste       NaN  0.983411  0.983411  0.983507       NaN   \n",
       "MO        cv            0.000198  0.999206  0.998730  0.999064  0.000198   \n",
       "          treino-teste       NaN  0.987657  0.987657  0.987748       NaN   \n",
       "MT        cv            0.000043  1.000000  0.999921  0.999969  0.000043   \n",
       "          treino-teste       NaN  0.996586  0.996586  0.996574       NaN   \n",
       "PC        cv            0.000589  0.999524  0.998095  0.999128  0.000589   \n",
       "          treino-teste       NaN  0.981344  0.981344  0.981329       NaN   \n",
       "\n",
       "                                            \n",
       "                             max       min  \n",
       "appliance base                              \n",
       "LC        cv            0.998410  0.998170  \n",
       "          treino-teste  0.963043  0.963043  \n",
       "LF        cv            0.999919  0.999370  \n",
       "          treino-teste  0.982518  0.982518  \n",
       "LI        cv            0.999841  0.999448  \n",
       "          treino-teste  0.983507  0.983507  \n",
       "MO        cv            0.999209  0.998730  \n",
       "          treino-teste  0.987748  0.987748  \n",
       "MT        cv            1.000000  0.999922  \n",
       "          treino-teste  0.996574  0.996574  \n",
       "PC        cv            0.999526  0.998095  \n",
       "          treino-teste  0.981329  0.981329  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo = XGBClassifier(eval_metric='error', random_state=SEED, n_jobs=4)\n",
    "nome_modelo = \"xgboost\"\n",
    "\n",
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \n",
    "    \"base\": []\n",
    "}\n",
    "\n",
    "for rotulo_aparelho in colunas_output:\n",
    "    \n",
    "    print(\"****************************************************************\\n\")\n",
    "    print(f\"* Aparelho `{rotulo_aparelho}`...\\n\")\n",
    "    \n",
    "    #######################################################################\n",
    "    #                AVALIACAO 1 - Base de treino/validacao               #\n",
    "    #######################################################################\n",
    "\n",
    "    # # Filtrando output/status por aparelho\n",
    "    y_treino_aparelho = y_treino[rotulo_aparelho]\n",
    "    y_validacao_aparelho = y_validacao[rotulo_aparelho]\n",
    "\n",
    "    print(f\"  - Avaliando modelo através da base treino/validacao...\")\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem (lote validacao):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_validacao_aparelho).items():\n",
    "        print(f\"       - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_validacao_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "\n",
    "    # Treinando modelo\n",
    "    print(f\"     -> Treinando modelo...\\n\")\n",
    "    clf = clone(modelo)\n",
    "        \n",
    "    clf.fit(X_treino, y_treino_aparelho)\n",
    "\n",
    "    # Prevendo conjunto de dados\n",
    "    y_hat = clf.predict(X_validacao)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "    resultados_modelo[\"fold\"].append(\"-\")\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_validacao_aparelho, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_validacao_aparelho, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_validacao_aparelho, y_hat) if np.unique(y_validacao_aparelho).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"treino-teste\")\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_validacao_aparelho, y_hat))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_validacao_aparelho, y_hat))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    #######################################################################\n",
    "    #                  AVALIACAO 2 - Validacao Cruzada                    #\n",
    "    #######################################################################\n",
    "    \n",
    "    y_true_cv, y_pred_cv  = [], []\n",
    "\n",
    "    print(f\"  - Avaliando através de validação cruzada ({skf.n_splits}-folds)...\")\n",
    "\n",
    "    # Filtrando output/status por aparelho\n",
    "    y_aparelho = y_cv[rotulo_aparelho]\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem:\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_aparelho).items():\n",
    "        print(f\"        - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "    \n",
    "\n",
    "    print(f\"     -> Avaliando modelo (CV - {skf.n_splits} folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in tqdm_notebook(enumerate(skf.split(X_cv, y_aparelho)), total=skf.n_splits):\n",
    "        \n",
    "        # Preparando lotes\n",
    "        X_treino_cv, X_teste_cv = X_cv.iloc[idx_treino], X_cv.iloc[idx_teste]\n",
    "        y_treino_cv, y_teste_cv = y_aparelho.iloc[idx_treino], y_aparelho.iloc[idx_teste]\n",
    "\n",
    "        # Treinando modelo\n",
    "        clf = clone(modelo)\n",
    "        \n",
    "        clf.fit(X_treino_cv, y_treino_cv)\n",
    "\n",
    "        # Prevendo conjunto de dados\n",
    "        y_hat = clf.predict(X_teste_cv)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste_cv, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste_cv, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste_cv, y_hat) if np.unique(y_teste_cv).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"cv\")\n",
    "\n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true_cv.extend(y_teste_cv)\n",
    "        y_pred_cv.extend(y_hat)\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true_cv, y_pred_cv))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true_cv, y_pred_cv))\n",
    "    print()\n",
    "    print(\"**********************************************\")\n",
    "    print()\n",
    "    \n",
    "# Consolidando DataFrame\n",
    "df_resultados = pd.DataFrame(resultados_modelo)\n",
    "\n",
    "arquivo_resultados = os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_resultados_{nome_modelo}.xlsx\")\n",
    "if os.path.isfile(arquivo_resultados): os.remove(arquivo_resultados)\n",
    "df_resultados.to_excel(arquivo_resultados, index=False)\n",
    "    \n",
    "print(\"############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\")\n",
    "display(df_resultados.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:10:29.051087Z",
     "start_time": "2021-05-03T03:52:22.146464Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "\n",
      "* Aparelho `LC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     12400\n",
      "           1       0.51      1.00      0.67     12800\n",
      "\n",
      "    accuracy                           0.51     25200\n",
      "   macro avg       0.25      0.50      0.34     25200\n",
      "weighted avg       0.26      0.51      0.34     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[    0 12400]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1006e6a3384fb69117e8585a36a8e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.02      0.03     31000\n",
      "           1       0.51      0.99      0.67     32000\n",
      "\n",
      "    accuracy                           0.51     63000\n",
      "   macro avg       0.53      0.50      0.35     63000\n",
      "weighted avg       0.53      0.51      0.36     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[  489 30511]\n",
      " [  393 31607]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LI`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86     12400\n",
      "           1       0.87      0.85      0.86     12800\n",
      "\n",
      "    accuracy                           0.86     25200\n",
      "   macro avg       0.86      0.86      0.86     25200\n",
      "weighted avg       0.86      0.86      0.86     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[10800  1600]\n",
      " [ 1939 10861]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4665a01e7b9a43d2bd766ca3e5bcbd47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86     31000\n",
      "           1       0.87      0.85      0.86     32000\n",
      "\n",
      "    accuracy                           0.86     63000\n",
      "   macro avg       0.86      0.86      0.86     63000\n",
      "weighted avg       0.86      0.86      0.86     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[27000  4000]\n",
      " [ 4842 27158]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MO`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70     12400\n",
      "           1       0.71      0.69      0.70     12800\n",
      "\n",
      "    accuracy                           0.70     25200\n",
      "   macro avg       0.70      0.70      0.70     25200\n",
      "weighted avg       0.70      0.70      0.70     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[8787 3613]\n",
      " [4005 8795]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4447ada9df2d469ea938fcdd241cd457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69     31000\n",
      "           1       0.70      0.71      0.71     32000\n",
      "\n",
      "    accuracy                           0.70     63000\n",
      "   macro avg       0.70      0.70      0.70     63000\n",
      "weighted avg       0.70      0.70      0.70     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[21230  9770]\n",
      " [ 9216 22784]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MT`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84     12400\n",
      "           1       0.89      0.77      0.83     12800\n",
      "\n",
      "    accuracy                           0.83     25200\n",
      "   macro avg       0.84      0.84      0.83     25200\n",
      "weighted avg       0.84      0.83      0.83     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[11200  1200]\n",
      " [ 2960  9840]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66da9717d67d4506a21cd3b39f4c6828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85     31000\n",
      "           1       0.89      0.79      0.84     32000\n",
      "\n",
      "    accuracy                           0.85     63000\n",
      "   macro avg       0.85      0.85      0.85     63000\n",
      "weighted avg       0.85      0.85      0.85     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[27920  3080]\n",
      " [ 6600 25400]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `PC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.72      0.68     12400\n",
      "           1       0.69      0.61      0.65     12800\n",
      "\n",
      "    accuracy                           0.66     25200\n",
      "   macro avg       0.67      0.66      0.66     25200\n",
      "weighted avg       0.67      0.66      0.66     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[8870 3530]\n",
      " [4948 7852]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b819819b374db09755232515342f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.74      0.67     31000\n",
      "           1       0.69      0.57      0.62     32000\n",
      "\n",
      "    accuracy                           0.65     63000\n",
      "   macro avg       0.66      0.65      0.65     63000\n",
      "weighted avg       0.66      0.65      0.65     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[22838  8162]\n",
      " [13882 18118]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LF`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.58      0.58     12400\n",
      "           1       0.60      0.60      0.60     12800\n",
      "\n",
      "    accuracy                           0.59     25200\n",
      "   macro avg       0.59      0.59      0.59     25200\n",
      "weighted avg       0.59      0.59      0.59     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[7217 5183]\n",
      " [5094 7706]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e192fcba592743528616137dfed70cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.60      0.59     31000\n",
      "           1       0.59      0.57      0.58     32000\n",
      "\n",
      "    accuracy                           0.58     63000\n",
      "   macro avg       0.58      0.58      0.58     63000\n",
      "weighted avg       0.58      0.58      0.58     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[18583 12417]\n",
      " [13807 18193]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LC</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.509460</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.515556</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.349593</td>\n",
       "      <td>0.028512</td>\n",
       "      <td>0.400597</td>\n",
       "      <td>0.336842</td>\n",
       "      <td>0.501746</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.508732</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.507937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.336842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.336842</td>\n",
       "      <td>0.336842</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LF</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.583746</td>\n",
       "      <td>0.020376</td>\n",
       "      <td>0.617698</td>\n",
       "      <td>0.566905</td>\n",
       "      <td>0.583477</td>\n",
       "      <td>0.020399</td>\n",
       "      <td>0.617471</td>\n",
       "      <td>0.566580</td>\n",
       "      <td>0.583991</td>\n",
       "      <td>0.020187</td>\n",
       "      <td>0.617467</td>\n",
       "      <td>0.567482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.592183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592183</td>\n",
       "      <td>0.592183</td>\n",
       "      <td>0.592029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592029</td>\n",
       "      <td>0.592029</td>\n",
       "      <td>0.592024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592024</td>\n",
       "      <td>0.592024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LI</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.859651</td>\n",
       "      <td>0.004081</td>\n",
       "      <td>0.864762</td>\n",
       "      <td>0.854444</td>\n",
       "      <td>0.859647</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>0.864758</td>\n",
       "      <td>0.854444</td>\n",
       "      <td>0.859828</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>0.864894</td>\n",
       "      <td>0.854682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.859563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.859563</td>\n",
       "      <td>0.859563</td>\n",
       "      <td>0.859563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.859563</td>\n",
       "      <td>0.859563</td>\n",
       "      <td>0.859742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.859742</td>\n",
       "      <td>0.859742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MO</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.698635</td>\n",
       "      <td>0.007372</td>\n",
       "      <td>0.706349</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.698399</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.705930</td>\n",
       "      <td>0.690464</td>\n",
       "      <td>0.698419</td>\n",
       "      <td>0.007164</td>\n",
       "      <td>0.705927</td>\n",
       "      <td>0.690549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.697698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.697698</td>\n",
       "      <td>0.697698</td>\n",
       "      <td>0.697698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.697698</td>\n",
       "      <td>0.697698</td>\n",
       "      <td>0.697869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.697869</td>\n",
       "      <td>0.697869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MT</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.846349</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>0.854524</td>\n",
       "      <td>0.842302</td>\n",
       "      <td>0.846091</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.841970</td>\n",
       "      <td>0.847198</td>\n",
       "      <td>0.004936</td>\n",
       "      <td>0.855144</td>\n",
       "      <td>0.843241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.834921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.834921</td>\n",
       "      <td>0.834921</td>\n",
       "      <td>0.834438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.834438</td>\n",
       "      <td>0.834438</td>\n",
       "      <td>0.835988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835988</td>\n",
       "      <td>0.835988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PC</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.650095</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.653810</td>\n",
       "      <td>0.644841</td>\n",
       "      <td>0.648113</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>0.651642</td>\n",
       "      <td>0.643282</td>\n",
       "      <td>0.651449</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>0.655227</td>\n",
       "      <td>0.646053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.663571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.663571</td>\n",
       "      <td>0.663571</td>\n",
       "      <td>0.663022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.663022</td>\n",
       "      <td>0.663022</td>\n",
       "      <td>0.664380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.664380</td>\n",
       "      <td>0.664380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             acc                                      f1  \\\n",
       "                            mean       std       max       min      mean   \n",
       "appliance base                                                             \n",
       "LC        cv            0.509460  0.003407  0.515556  0.507937  0.349593   \n",
       "          treino-teste  0.507937       NaN  0.507937  0.507937  0.336842   \n",
       "LF        cv            0.583746  0.020376  0.617698  0.566905  0.583477   \n",
       "          treino-teste  0.592183       NaN  0.592183  0.592183  0.592029   \n",
       "LI        cv            0.859651  0.004081  0.864762  0.854444  0.859647   \n",
       "          treino-teste  0.859563       NaN  0.859563  0.859563  0.859563   \n",
       "MO        cv            0.698635  0.007372  0.706349  0.690476  0.698399   \n",
       "          treino-teste  0.697698       NaN  0.697698  0.697698  0.697698   \n",
       "MT        cv            0.846349  0.005069  0.854524  0.842302  0.846091   \n",
       "          treino-teste  0.834921       NaN  0.834921  0.834921  0.834438   \n",
       "PC        cv            0.650095  0.003488  0.653810  0.644841  0.648113   \n",
       "          treino-teste  0.663571       NaN  0.663571  0.663571  0.663022   \n",
       "\n",
       "                                                           auc            \\\n",
       "                             std       max       min      mean       std   \n",
       "appliance base                                                             \n",
       "LC        cv            0.028512  0.400597  0.336842  0.501746  0.003905   \n",
       "          treino-teste       NaN  0.336842  0.336842  0.500000       NaN   \n",
       "LF        cv            0.020399  0.617471  0.566580  0.583991  0.020187   \n",
       "          treino-teste       NaN  0.592029  0.592029  0.592024       NaN   \n",
       "LI        cv            0.004078  0.864758  0.854444  0.859828  0.004021   \n",
       "          treino-teste       NaN  0.859563  0.859563  0.859742       NaN   \n",
       "MO        cv            0.007200  0.705930  0.690464  0.698419  0.007164   \n",
       "          treino-teste       NaN  0.697698  0.697698  0.697869       NaN   \n",
       "MT        cv            0.005168  0.854429  0.841970  0.847198  0.004936   \n",
       "          treino-teste       NaN  0.834438  0.834438  0.835988       NaN   \n",
       "PC        cv            0.003284  0.651642  0.643282  0.651449  0.003560   \n",
       "          treino-teste       NaN  0.663022  0.663022  0.664380       NaN   \n",
       "\n",
       "                                            \n",
       "                             max       min  \n",
       "appliance base                              \n",
       "LC        cv            0.508732  0.500000  \n",
       "          treino-teste  0.500000  0.500000  \n",
       "LF        cv            0.617467  0.567482  \n",
       "          treino-teste  0.592024  0.592024  \n",
       "LI        cv            0.864894  0.854682  \n",
       "          treino-teste  0.859742  0.859742  \n",
       "MO        cv            0.705927  0.690549  \n",
       "          treino-teste  0.697869  0.697869  \n",
       "MT        cv            0.855144  0.843241  \n",
       "          treino-teste  0.835988  0.835988  \n",
       "PC        cv            0.655227  0.646053  \n",
       "          treino-teste  0.664380  0.664380  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo = MLPClassifier(alpha=1e-3, hidden_layer_sizes=(10,), random_state=SEED)\n",
    "nome_modelo = \"mlp\"\n",
    "\n",
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \n",
    "    \"base\": []\n",
    "}\n",
    "\n",
    "for rotulo_aparelho in colunas_output:\n",
    "    \n",
    "    print(\"****************************************************************\\n\")\n",
    "    print(f\"* Aparelho `{rotulo_aparelho}`...\\n\")\n",
    "    \n",
    "    #######################################################################\n",
    "    #                AVALIACAO 1 - Base de treino/validacao               #\n",
    "    #######################################################################\n",
    "\n",
    "    # # Filtrando output/status por aparelho\n",
    "    y_treino_aparelho = y_treino[rotulo_aparelho]\n",
    "    y_validacao_aparelho = y_validacao[rotulo_aparelho]\n",
    "\n",
    "    print(f\"  - Avaliando modelo através da base treino/validacao...\")\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem (lote validacao):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_validacao_aparelho).items():\n",
    "        print(f\"       - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_validacao_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "\n",
    "    # Treinando modelo\n",
    "    print(f\"     -> Treinando modelo...\\n\")\n",
    "    clf = clone(modelo)\n",
    "        \n",
    "    clf.fit(X_treino, y_treino_aparelho)\n",
    "\n",
    "    # Prevendo conjunto de dados\n",
    "    y_hat = clf.predict(X_validacao)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "    resultados_modelo[\"fold\"].append(\"-\")\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_validacao_aparelho, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_validacao_aparelho, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_validacao_aparelho, y_hat) if np.unique(y_validacao_aparelho).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"treino-teste\")\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_validacao_aparelho, y_hat))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_validacao_aparelho, y_hat))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    #######################################################################\n",
    "    #                  AVALIACAO 2 - Validacao Cruzada                    #\n",
    "    #######################################################################\n",
    "    \n",
    "    y_true_cv, y_pred_cv  = [], []\n",
    "\n",
    "    print(f\"  - Avaliando através de validação cruzada ({skf.n_splits}-folds)...\")\n",
    "\n",
    "    # Filtrando output/status por aparelho\n",
    "    y_aparelho = y_cv[rotulo_aparelho]\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem:\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_aparelho).items():\n",
    "        print(f\"        - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "    \n",
    "\n",
    "    print(f\"     -> Avaliando modelo (CV - {skf.n_splits} folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in tqdm_notebook(enumerate(skf.split(X_cv, y_aparelho)), total=skf.n_splits):\n",
    "        \n",
    "        # Preparando lotes\n",
    "        X_treino_cv, X_teste_cv = X_cv.iloc[idx_treino], X_cv.iloc[idx_teste]\n",
    "        y_treino_cv, y_teste_cv = y_aparelho.iloc[idx_treino], y_aparelho.iloc[idx_teste]\n",
    "\n",
    "        # Treinando modelo\n",
    "        clf = clone(modelo)\n",
    "        \n",
    "        clf.fit(X_treino_cv, y_treino_cv)\n",
    "\n",
    "        # Prevendo conjunto de dados\n",
    "        y_hat = clf.predict(X_teste_cv)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste_cv, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste_cv, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste_cv, y_hat) if np.unique(y_teste_cv).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"cv\")\n",
    "\n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true_cv.extend(y_teste_cv)\n",
    "        y_pred_cv.extend(y_hat)\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true_cv, y_pred_cv))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true_cv, y_pred_cv))\n",
    "    print()\n",
    "    print(\"**********************************************\")\n",
    "    print()\n",
    "    \n",
    "# Consolidando DataFrame\n",
    "df_resultados = pd.DataFrame(resultados_modelo)\n",
    "\n",
    "arquivo_resultados = os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_resultados_{nome_modelo}.xlsx\")\n",
    "if os.path.isfile(arquivo_resultados): os.remove(arquivo_resultados)\n",
    "df_resultados.to_excel(arquivo_resultados, index=False)\n",
    "    \n",
    "print(\"############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\")\n",
    "display(df_resultados.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise dos Resultados (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:10:32.077065Z",
     "start_time": "2021-05-03T09:10:31.295643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Análise por modelo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBOOST</th>\n",
       "      <td>cv</td>\n",
       "      <td>0.999302</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998095</td>\n",
       "      <td>0.999301</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998095</td>\n",
       "      <td>0.999301</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBOOST</th>\n",
       "      <td>treino-teste</td>\n",
       "      <td>0.982421</td>\n",
       "      <td>0.010961</td>\n",
       "      <td>0.996587</td>\n",
       "      <td>0.963175</td>\n",
       "      <td>0.982416</td>\n",
       "      <td>0.010968</td>\n",
       "      <td>0.996586</td>\n",
       "      <td>0.963154</td>\n",
       "      <td>0.982453</td>\n",
       "      <td>0.011014</td>\n",
       "      <td>0.996574</td>\n",
       "      <td>0.963043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>cv</td>\n",
       "      <td>0.682410</td>\n",
       "      <td>0.141646</td>\n",
       "      <td>0.865238</td>\n",
       "      <td>0.518968</td>\n",
       "      <td>0.677247</td>\n",
       "      <td>0.147191</td>\n",
       "      <td>0.865232</td>\n",
       "      <td>0.498104</td>\n",
       "      <td>0.682613</td>\n",
       "      <td>0.141894</td>\n",
       "      <td>0.865345</td>\n",
       "      <td>0.515862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>treino-teste</td>\n",
       "      <td>0.677560</td>\n",
       "      <td>0.146557</td>\n",
       "      <td>0.854603</td>\n",
       "      <td>0.536230</td>\n",
       "      <td>0.673249</td>\n",
       "      <td>0.151275</td>\n",
       "      <td>0.854601</td>\n",
       "      <td>0.523034</td>\n",
       "      <td>0.677798</td>\n",
       "      <td>0.146723</td>\n",
       "      <td>0.854758</td>\n",
       "      <td>0.537359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>cv</td>\n",
       "      <td>0.691323</td>\n",
       "      <td>0.130777</td>\n",
       "      <td>0.864762</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.664220</td>\n",
       "      <td>0.175810</td>\n",
       "      <td>0.864758</td>\n",
       "      <td>0.336842</td>\n",
       "      <td>0.690439</td>\n",
       "      <td>0.132748</td>\n",
       "      <td>0.864894</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>treino-teste</td>\n",
       "      <td>0.692646</td>\n",
       "      <td>0.136517</td>\n",
       "      <td>0.859563</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.663932</td>\n",
       "      <td>0.190075</td>\n",
       "      <td>0.859563</td>\n",
       "      <td>0.336842</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.138943</td>\n",
       "      <td>0.859742</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 base       acc                                      f1  \\\n",
       "                           mean       std       max       min      mean   \n",
       "model                                                                     \n",
       "XGBOOST            cv  0.999302  0.000603  1.000000  0.998095  0.999301   \n",
       "XGBOOST  treino-teste  0.982421  0.010961  0.996587  0.963175  0.982416   \n",
       "SVM                cv  0.682410  0.141646  0.865238  0.518968  0.677247   \n",
       "SVM      treino-teste  0.677560  0.146557  0.854603  0.536230  0.673249   \n",
       "MLP                cv  0.691323  0.130777  0.864762  0.507937  0.664220   \n",
       "MLP      treino-teste  0.692646  0.136517  0.859563  0.507937  0.663932   \n",
       "\n",
       "                                            auc                                \n",
       "              std       max       min      mean       std       max       min  \n",
       "model                                                                          \n",
       "XGBOOST  0.000604  1.000000  0.998095  0.999301  0.000604  1.000000  0.998095  \n",
       "XGBOOST  0.010968  0.996586  0.963154  0.982453  0.011014  0.996574  0.963043  \n",
       "SVM      0.147191  0.865232  0.498104  0.682613  0.141894  0.865345  0.515862  \n",
       "SVM      0.151275  0.854601  0.523034  0.677798  0.146723  0.854758  0.537359  \n",
       "MLP      0.175810  0.864758  0.336842  0.690439  0.132748  0.864894  0.500000  \n",
       "MLP      0.190075  0.859563  0.336842  0.691667  0.138943  0.859742  0.500000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Análise por aparelho/modelo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>model</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">LC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.509460</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.515556</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.349593</td>\n",
       "      <td>0.028512</td>\n",
       "      <td>0.400597</td>\n",
       "      <td>0.336842</td>\n",
       "      <td>0.501746</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.508732</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.507937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.336842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.336842</td>\n",
       "      <td>0.336842</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.523857</td>\n",
       "      <td>0.003016</td>\n",
       "      <td>0.526349</td>\n",
       "      <td>0.518968</td>\n",
       "      <td>0.502690</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.504807</td>\n",
       "      <td>0.498104</td>\n",
       "      <td>0.520714</td>\n",
       "      <td>0.002982</td>\n",
       "      <td>0.523170</td>\n",
       "      <td>0.515862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.540238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540238</td>\n",
       "      <td>0.540238</td>\n",
       "      <td>0.523034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523034</td>\n",
       "      <td>0.523034</td>\n",
       "      <td>0.537359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537359</td>\n",
       "      <td>0.537359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.998333</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.998413</td>\n",
       "      <td>0.998175</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.998412</td>\n",
       "      <td>0.998174</td>\n",
       "      <td>0.998330</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.998410</td>\n",
       "      <td>0.998170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.963175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.963175</td>\n",
       "      <td>0.963175</td>\n",
       "      <td>0.963154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.963154</td>\n",
       "      <td>0.963154</td>\n",
       "      <td>0.963043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.963043</td>\n",
       "      <td>0.963043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">LF</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.583746</td>\n",
       "      <td>0.020376</td>\n",
       "      <td>0.617698</td>\n",
       "      <td>0.566905</td>\n",
       "      <td>0.583477</td>\n",
       "      <td>0.020399</td>\n",
       "      <td>0.617471</td>\n",
       "      <td>0.566580</td>\n",
       "      <td>0.583991</td>\n",
       "      <td>0.020187</td>\n",
       "      <td>0.617467</td>\n",
       "      <td>0.567482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.592183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592183</td>\n",
       "      <td>0.592183</td>\n",
       "      <td>0.592029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592029</td>\n",
       "      <td>0.592029</td>\n",
       "      <td>0.592024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592024</td>\n",
       "      <td>0.592024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.537635</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.543175</td>\n",
       "      <td>0.529524</td>\n",
       "      <td>0.533119</td>\n",
       "      <td>0.005471</td>\n",
       "      <td>0.538765</td>\n",
       "      <td>0.525246</td>\n",
       "      <td>0.539332</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>0.544864</td>\n",
       "      <td>0.531164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.536230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.536230</td>\n",
       "      <td>0.536230</td>\n",
       "      <td>0.531654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.531654</td>\n",
       "      <td>0.531654</td>\n",
       "      <td>0.537935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537935</td>\n",
       "      <td>0.537935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999667</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999365</td>\n",
       "      <td>0.999667</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999365</td>\n",
       "      <td>0.999665</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.999370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.982341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.982341</td>\n",
       "      <td>0.982341</td>\n",
       "      <td>0.982341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.982341</td>\n",
       "      <td>0.982341</td>\n",
       "      <td>0.982518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.982518</td>\n",
       "      <td>0.982518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">LI</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.859651</td>\n",
       "      <td>0.004081</td>\n",
       "      <td>0.864762</td>\n",
       "      <td>0.854444</td>\n",
       "      <td>0.859647</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>0.864758</td>\n",
       "      <td>0.854444</td>\n",
       "      <td>0.859828</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>0.864894</td>\n",
       "      <td>0.854682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.859563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.859563</td>\n",
       "      <td>0.859563</td>\n",
       "      <td>0.859563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.859563</td>\n",
       "      <td>0.859563</td>\n",
       "      <td>0.859742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.859742</td>\n",
       "      <td>0.859742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.860127</td>\n",
       "      <td>0.003047</td>\n",
       "      <td>0.865238</td>\n",
       "      <td>0.857619</td>\n",
       "      <td>0.860123</td>\n",
       "      <td>0.003045</td>\n",
       "      <td>0.865232</td>\n",
       "      <td>0.857619</td>\n",
       "      <td>0.860276</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>0.865345</td>\n",
       "      <td>0.857848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.854603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.854603</td>\n",
       "      <td>0.854603</td>\n",
       "      <td>0.854601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.854601</td>\n",
       "      <td>0.854601</td>\n",
       "      <td>0.854758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.854758</td>\n",
       "      <td>0.854758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999651</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999444</td>\n",
       "      <td>0.999651</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999444</td>\n",
       "      <td>0.999652</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.983413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.983413</td>\n",
       "      <td>0.983413</td>\n",
       "      <td>0.983411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.983411</td>\n",
       "      <td>0.983411</td>\n",
       "      <td>0.983507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.983507</td>\n",
       "      <td>0.983507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MO</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.698635</td>\n",
       "      <td>0.007372</td>\n",
       "      <td>0.706349</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.698399</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.705930</td>\n",
       "      <td>0.690464</td>\n",
       "      <td>0.698419</td>\n",
       "      <td>0.007164</td>\n",
       "      <td>0.705927</td>\n",
       "      <td>0.690549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.697698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.697698</td>\n",
       "      <td>0.697698</td>\n",
       "      <td>0.697698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.697698</td>\n",
       "      <td>0.697698</td>\n",
       "      <td>0.697869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.697869</td>\n",
       "      <td>0.697869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.586937</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.591190</td>\n",
       "      <td>0.582619</td>\n",
       "      <td>0.581805</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>0.586307</td>\n",
       "      <td>0.577364</td>\n",
       "      <td>0.588843</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>0.593065</td>\n",
       "      <td>0.584536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.567506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567506</td>\n",
       "      <td>0.567506</td>\n",
       "      <td>0.573085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.573085</td>\n",
       "      <td>0.573085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999063</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.999206</td>\n",
       "      <td>0.998730</td>\n",
       "      <td>0.999063</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.999206</td>\n",
       "      <td>0.998730</td>\n",
       "      <td>0.999064</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.999209</td>\n",
       "      <td>0.998730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.987659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987659</td>\n",
       "      <td>0.987659</td>\n",
       "      <td>0.987657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987657</td>\n",
       "      <td>0.987657</td>\n",
       "      <td>0.987748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987748</td>\n",
       "      <td>0.987748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MT</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.846349</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>0.854524</td>\n",
       "      <td>0.842302</td>\n",
       "      <td>0.846091</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.841970</td>\n",
       "      <td>0.847198</td>\n",
       "      <td>0.004936</td>\n",
       "      <td>0.855144</td>\n",
       "      <td>0.843241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.834921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.834921</td>\n",
       "      <td>0.834921</td>\n",
       "      <td>0.834438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.834438</td>\n",
       "      <td>0.834438</td>\n",
       "      <td>0.835988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835988</td>\n",
       "      <td>0.835988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.843175</td>\n",
       "      <td>0.005706</td>\n",
       "      <td>0.849762</td>\n",
       "      <td>0.836190</td>\n",
       "      <td>0.843059</td>\n",
       "      <td>0.005770</td>\n",
       "      <td>0.849747</td>\n",
       "      <td>0.836001</td>\n",
       "      <td>0.843794</td>\n",
       "      <td>0.005576</td>\n",
       "      <td>0.850136</td>\n",
       "      <td>0.836941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.828214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.828214</td>\n",
       "      <td>0.828214</td>\n",
       "      <td>0.828063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.828063</td>\n",
       "      <td>0.828063</td>\n",
       "      <td>0.828894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.828894</td>\n",
       "      <td>0.828894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.996587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996587</td>\n",
       "      <td>0.996587</td>\n",
       "      <td>0.996586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996586</td>\n",
       "      <td>0.996586</td>\n",
       "      <td>0.996574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996574</td>\n",
       "      <td>0.996574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">PC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.650095</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.653810</td>\n",
       "      <td>0.644841</td>\n",
       "      <td>0.648113</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>0.651642</td>\n",
       "      <td>0.643282</td>\n",
       "      <td>0.651449</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>0.655227</td>\n",
       "      <td>0.646053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.663571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.663571</td>\n",
       "      <td>0.663571</td>\n",
       "      <td>0.663022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.663022</td>\n",
       "      <td>0.663022</td>\n",
       "      <td>0.664380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.664380</td>\n",
       "      <td>0.664380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.742730</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.746111</td>\n",
       "      <td>0.736032</td>\n",
       "      <td>0.742689</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>0.746077</td>\n",
       "      <td>0.735973</td>\n",
       "      <td>0.742717</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.735980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.734643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734643</td>\n",
       "      <td>0.734643</td>\n",
       "      <td>0.734638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734638</td>\n",
       "      <td>0.734638</td>\n",
       "      <td>0.734757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734757</td>\n",
       "      <td>0.734757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999127</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.999524</td>\n",
       "      <td>0.998095</td>\n",
       "      <td>0.999127</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.999524</td>\n",
       "      <td>0.998095</td>\n",
       "      <td>0.999128</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.999526</td>\n",
       "      <td>0.998095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.981349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981349</td>\n",
       "      <td>0.981349</td>\n",
       "      <td>0.981344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981344</td>\n",
       "      <td>0.981344</td>\n",
       "      <td>0.981329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981329</td>\n",
       "      <td>0.981329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     acc                                \\\n",
       "                                    mean       std       max       min   \n",
       "appliance model   base                                                   \n",
       "LC        MLP     cv            0.509460  0.003407  0.515556  0.507937   \n",
       "                  treino-teste  0.507937       NaN  0.507937  0.507937   \n",
       "          SVM     cv            0.523857  0.003016  0.526349  0.518968   \n",
       "                  treino-teste  0.540238       NaN  0.540238  0.540238   \n",
       "          XGBOOST cv            0.998333  0.000112  0.998413  0.998175   \n",
       "                  treino-teste  0.963175       NaN  0.963175  0.963175   \n",
       "LF        MLP     cv            0.583746  0.020376  0.617698  0.566905   \n",
       "                  treino-teste  0.592183       NaN  0.592183  0.592183   \n",
       "          SVM     cv            0.537635  0.005499  0.543175  0.529524   \n",
       "                  treino-teste  0.536230       NaN  0.536230  0.536230   \n",
       "          XGBOOST cv            0.999667  0.000220  0.999921  0.999365   \n",
       "                  treino-teste  0.982341       NaN  0.982341  0.982341   \n",
       "LI        MLP     cv            0.859651  0.004081  0.864762  0.854444   \n",
       "                  treino-teste  0.859563       NaN  0.859563  0.859563   \n",
       "          SVM     cv            0.860127  0.003047  0.865238  0.857619   \n",
       "                  treino-teste  0.854603       NaN  0.854603  0.854603   \n",
       "          XGBOOST cv            0.999651  0.000191  0.999841  0.999444   \n",
       "                  treino-teste  0.983413       NaN  0.983413  0.983413   \n",
       "MO        MLP     cv            0.698635  0.007372  0.706349  0.690476   \n",
       "                  treino-teste  0.697698       NaN  0.697698  0.697698   \n",
       "          SVM     cv            0.586937  0.003658  0.591190  0.582619   \n",
       "                  treino-teste  0.571429       NaN  0.571429  0.571429   \n",
       "          XGBOOST cv            0.999063  0.000198  0.999206  0.998730   \n",
       "                  treino-teste  0.987659       NaN  0.987659  0.987659   \n",
       "MT        MLP     cv            0.846349  0.005069  0.854524  0.842302   \n",
       "                  treino-teste  0.834921       NaN  0.834921  0.834921   \n",
       "          SVM     cv            0.843175  0.005706  0.849762  0.836190   \n",
       "                  treino-teste  0.828214       NaN  0.828214  0.828214   \n",
       "          XGBOOST cv            0.999968  0.000043  1.000000  0.999921   \n",
       "                  treino-teste  0.996587       NaN  0.996587  0.996587   \n",
       "PC        MLP     cv            0.650095  0.003488  0.653810  0.644841   \n",
       "                  treino-teste  0.663571       NaN  0.663571  0.663571   \n",
       "          SVM     cv            0.742730  0.003953  0.746111  0.736032   \n",
       "                  treino-teste  0.734643       NaN  0.734643  0.734643   \n",
       "          XGBOOST cv            0.999127  0.000589  0.999524  0.998095   \n",
       "                  treino-teste  0.981349       NaN  0.981349  0.981349   \n",
       "\n",
       "                                      f1                                \\\n",
       "                                    mean       std       max       min   \n",
       "appliance model   base                                                   \n",
       "LC        MLP     cv            0.349593  0.028512  0.400597  0.336842   \n",
       "                  treino-teste  0.336842       NaN  0.336842  0.336842   \n",
       "          SVM     cv            0.502690  0.002701  0.504807  0.498104   \n",
       "                  treino-teste  0.523034       NaN  0.523034  0.523034   \n",
       "          XGBOOST cv            0.998333  0.000112  0.998412  0.998174   \n",
       "                  treino-teste  0.963154       NaN  0.963154  0.963154   \n",
       "LF        MLP     cv            0.583477  0.020399  0.617471  0.566580   \n",
       "                  treino-teste  0.592029       NaN  0.592029  0.592029   \n",
       "          SVM     cv            0.533119  0.005471  0.538765  0.525246   \n",
       "                  treino-teste  0.531654       NaN  0.531654  0.531654   \n",
       "          XGBOOST cv            0.999667  0.000220  0.999921  0.999365   \n",
       "                  treino-teste  0.982341       NaN  0.982341  0.982341   \n",
       "LI        MLP     cv            0.859647  0.004078  0.864758  0.854444   \n",
       "                  treino-teste  0.859563       NaN  0.859563  0.859563   \n",
       "          SVM     cv            0.860123  0.003045  0.865232  0.857619   \n",
       "                  treino-teste  0.854601       NaN  0.854601  0.854601   \n",
       "          XGBOOST cv            0.999651  0.000191  0.999841  0.999444   \n",
       "                  treino-teste  0.983411       NaN  0.983411  0.983411   \n",
       "MO        MLP     cv            0.698399  0.007200  0.705930  0.690464   \n",
       "                  treino-teste  0.697698       NaN  0.697698  0.697698   \n",
       "          SVM     cv            0.581805  0.003703  0.586307  0.577364   \n",
       "                  treino-teste  0.567506       NaN  0.567506  0.567506   \n",
       "          XGBOOST cv            0.999063  0.000198  0.999206  0.998730   \n",
       "                  treino-teste  0.987657       NaN  0.987657  0.987657   \n",
       "MT        MLP     cv            0.846091  0.005168  0.854429  0.841970   \n",
       "                  treino-teste  0.834438       NaN  0.834438  0.834438   \n",
       "          SVM     cv            0.843059  0.005770  0.849747  0.836001   \n",
       "                  treino-teste  0.828063       NaN  0.828063  0.828063   \n",
       "          XGBOOST cv            0.999968  0.000043  1.000000  0.999921   \n",
       "                  treino-teste  0.996586       NaN  0.996586  0.996586   \n",
       "PC        MLP     cv            0.648113  0.003284  0.651642  0.643282   \n",
       "                  treino-teste  0.663022       NaN  0.663022  0.663022   \n",
       "          SVM     cv            0.742689  0.003962  0.746077  0.735973   \n",
       "                  treino-teste  0.734638       NaN  0.734638  0.734638   \n",
       "          XGBOOST cv            0.999127  0.000589  0.999524  0.998095   \n",
       "                  treino-teste  0.981344       NaN  0.981344  0.981344   \n",
       "\n",
       "                                     auc                                \n",
       "                                    mean       std       max       min  \n",
       "appliance model   base                                                  \n",
       "LC        MLP     cv            0.501746  0.003905  0.508732  0.500000  \n",
       "                  treino-teste  0.500000       NaN  0.500000  0.500000  \n",
       "          SVM     cv            0.520714  0.002982  0.523170  0.515862  \n",
       "                  treino-teste  0.537359       NaN  0.537359  0.537359  \n",
       "          XGBOOST cv            0.998330  0.000111  0.998410  0.998170  \n",
       "                  treino-teste  0.963043       NaN  0.963043  0.963043  \n",
       "LF        MLP     cv            0.583991  0.020187  0.617467  0.567482  \n",
       "                  treino-teste  0.592024       NaN  0.592024  0.592024  \n",
       "          SVM     cv            0.539332  0.005515  0.544864  0.531164  \n",
       "                  treino-teste  0.537935       NaN  0.537935  0.537935  \n",
       "          XGBOOST cv            0.999665  0.000219  0.999919  0.999370  \n",
       "                  treino-teste  0.982518       NaN  0.982518  0.982518  \n",
       "LI        MLP     cv            0.859828  0.004021  0.864894  0.854682  \n",
       "                  treino-teste  0.859742       NaN  0.859742  0.859742  \n",
       "          SVM     cv            0.860276  0.003005  0.865345  0.857848  \n",
       "                  treino-teste  0.854758       NaN  0.854758  0.854758  \n",
       "          XGBOOST cv            0.999652  0.000189  0.999841  0.999448  \n",
       "                  treino-teste  0.983507       NaN  0.983507  0.983507  \n",
       "MO        MLP     cv            0.698419  0.007164  0.705927  0.690549  \n",
       "                  treino-teste  0.697869       NaN  0.697869  0.697869  \n",
       "          SVM     cv            0.588843  0.003660  0.593065  0.584536  \n",
       "                  treino-teste  0.573085       NaN  0.573085  0.573085  \n",
       "          XGBOOST cv            0.999064  0.000198  0.999209  0.998730  \n",
       "                  treino-teste  0.987748       NaN  0.987748  0.987748  \n",
       "MT        MLP     cv            0.847198  0.004936  0.855144  0.843241  \n",
       "                  treino-teste  0.835988       NaN  0.835988  0.835988  \n",
       "          SVM     cv            0.843794  0.005576  0.850136  0.836941  \n",
       "                  treino-teste  0.828894       NaN  0.828894  0.828894  \n",
       "          XGBOOST cv            0.999969  0.000043  1.000000  0.999922  \n",
       "                  treino-teste  0.996574       NaN  0.996574  0.996574  \n",
       "PC        MLP     cv            0.651449  0.003560  0.655227  0.646053  \n",
       "                  treino-teste  0.664380       NaN  0.664380  0.664380  \n",
       "          SVM     cv            0.742717  0.003974  0.746114  0.735980  \n",
       "                  treino-teste  0.734757       NaN  0.734757  0.734757  \n",
       "          XGBOOST cv            0.999128  0.000589  0.999526  0.998095  \n",
       "                  treino-teste  0.981329       NaN  0.981329  0.981329  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_resultados_svm = pd.read_excel(os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_resultados_svm.xlsx\"), engine='openpyxl')\n",
    "df_resultados_svm[\"model\"] = \"SVM\"\n",
    "\n",
    "df_resultados_xgboost = pd.read_excel(os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_resultados_xgboost.xlsx\"), engine='openpyxl')\n",
    "df_resultados_xgboost[\"model\"] = \"XGBOOST\"\n",
    "\n",
    "df_resultados_mlp = pd.read_excel(os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_resultados_mlp.xlsx\"), engine='openpyxl')\n",
    "df_resultados_mlp[\"model\"] = \"MLP\"\n",
    "\n",
    "# df_resultados_elm = pd.read_excel(os.path.join(caminho_dados_notebook, \"df_resultados_elm.xlsx\"))\n",
    "# df_resultados_elm[\"model\"] = \"ELM\"\n",
    "\n",
    "df_analise = pd.concat([\n",
    "    df_resultados_svm,\n",
    "    df_resultados_xgboost,\n",
    "    df_resultados_mlp, \n",
    "#     df_resultados_elm,  \n",
    "])\n",
    "\n",
    "print(\"* Análise por modelo:\")\n",
    "df_analise_modelo = df_analise.groupby([\"model\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"f1\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"auc\": [\"mean\",\"std\",\"max\",\"min\"]\n",
    "}).reset_index().sort_values(('f1','mean'), ascending=False).set_index(\"model\")\n",
    "display(df_analise_modelo)\n",
    "df_analise_modelo.to_excel(os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_analise_modelos.xlsx\"))\n",
    "\n",
    "print()\n",
    "print(\"* Análise por aparelho/modelo:\")\n",
    "df_analise_aparelho = df_analise.groupby([\"appliance\",\"model\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"f1\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"auc\": [\"mean\",\"std\",\"max\",\"min\"]\n",
    "})#.reset_index().sort_values(('f1','mean'), ascending=False).set_index([\"aparelho\",\"metodologia\"])\n",
    "display(df_analise_aparelho)\n",
    "df_analise_aparelho.to_excel(os.path.join(caminho_dados_notebook, \"resultados\", f\"{atributos}_analise_aparelhos.xls\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atributos Domínio da Frequência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dominio = 'frequencia'\n",
    "\n",
    "X_treino = X_treino_frequencia\n",
    "X_validacao = X_validacao_frequencia\n",
    "\n",
    "# Dados agregados (validacao cruzada)\n",
    "X_cv = pd.concat([X_treino, X_validacao]).reset_index(drop=True) \n",
    "y_cv = pd.concat([y_treino, y_validacao]).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T22:18:59.268806Z",
     "start_time": "2021-05-02T17:03:12.352604Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "\n",
      "* Aparelho `LC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78881c740431403a94ce9455dffa9f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LI`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd7e025520f4575b5ec278e31cbbc42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MO`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3741d08a1b146e0b35325b14618e81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MT`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381a4b7aca7c4844ac18173fe29dd6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `PC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88     12400\n",
      "           1       0.93      0.81      0.86     12800\n",
      "\n",
      "    accuracy                           0.87     25200\n",
      "   macro avg       0.88      0.87      0.87     25200\n",
      "weighted avg       0.88      0.87      0.87     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[11600   800]\n",
      " [ 2443 10357]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543a9688087d4a97ba9980a5b3a5ebde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93     31000\n",
      "           1       0.98      0.88      0.93     32000\n",
      "\n",
      "    accuracy                           0.93     63000\n",
      "   macro avg       0.93      0.93      0.93     63000\n",
      "weighted avg       0.93      0.93      0.93     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[30291   709]\n",
      " [ 3786 28214]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LF`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74     12400\n",
      "           1       0.75      0.75      0.75     12800\n",
      "\n",
      "    accuracy                           0.75     25200\n",
      "   macro avg       0.75      0.75      0.75     25200\n",
      "weighted avg       0.75      0.75      0.75     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[9200 3200]\n",
      " [3200 9600]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7735b7c77ca84330af72fe90ceae9ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73     31000\n",
      "           1       0.74      0.76      0.75     32000\n",
      "\n",
      "    accuracy                           0.74     63000\n",
      "   macro avg       0.74      0.74      0.74     63000\n",
      "weighted avg       0.74      0.74      0.74     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[22299  8701]\n",
      " [ 7634 24366]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LC</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LF</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.740714</td>\n",
       "      <td>0.00331</td>\n",
       "      <td>0.744127</td>\n",
       "      <td>0.736190</td>\n",
       "      <td>0.740423</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>0.743966</td>\n",
       "      <td>0.735730</td>\n",
       "      <td>0.740380</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.743916</td>\n",
       "      <td>0.735713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.746032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>0.745968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LI</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MO</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MT</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PC</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.928651</td>\n",
       "      <td>0.00595</td>\n",
       "      <td>0.935397</td>\n",
       "      <td>0.923413</td>\n",
       "      <td>0.928570</td>\n",
       "      <td>0.005976</td>\n",
       "      <td>0.935340</td>\n",
       "      <td>0.923316</td>\n",
       "      <td>0.929408</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.936104</td>\n",
       "      <td>0.924209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.871310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.871310</td>\n",
       "      <td>0.871310</td>\n",
       "      <td>0.870996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.870996</td>\n",
       "      <td>0.870996</td>\n",
       "      <td>0.872312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.872312</td>\n",
       "      <td>0.872312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             acc                                     f1  \\\n",
       "                            mean      std       max       min      mean   \n",
       "appliance base                                                            \n",
       "LC        cv            1.000000  0.00000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000      NaN  1.000000  1.000000  1.000000   \n",
       "LF        cv            0.740714  0.00331  0.744127  0.736190  0.740423   \n",
       "          treino-teste  0.746032      NaN  0.746032  0.746032  0.745968   \n",
       "LI        cv            1.000000  0.00000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000      NaN  1.000000  1.000000  1.000000   \n",
       "MO        cv            1.000000  0.00000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000      NaN  1.000000  1.000000  1.000000   \n",
       "MT        cv            1.000000  0.00000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000      NaN  1.000000  1.000000  1.000000   \n",
       "PC        cv            0.928651  0.00595  0.935397  0.923413  0.928570   \n",
       "          treino-teste  0.871310      NaN  0.871310  0.871310  0.870996   \n",
       "\n",
       "                                                           auc            \\\n",
       "                             std       max       min      mean       std   \n",
       "appliance base                                                             \n",
       "LC        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "LF        cv            0.003435  0.743966  0.735730  0.740380  0.003423   \n",
       "          treino-teste       NaN  0.745968  0.745968  0.745968       NaN   \n",
       "LI        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "MO        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "MT        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "PC        cv            0.005976  0.935340  0.923316  0.929408  0.005882   \n",
       "          treino-teste       NaN  0.870996  0.870996  0.872312       NaN   \n",
       "\n",
       "                                            \n",
       "                             max       min  \n",
       "appliance base                              \n",
       "LC        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "LF        cv            0.743916  0.735713  \n",
       "          treino-teste  0.745968  0.745968  \n",
       "LI        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "MO        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "MT        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "PC        cv            0.936104  0.924209  \n",
       "          treino-teste  0.872312  0.872312  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo = SVC(kernel='rbf', random_state=SEED)\n",
    "\n",
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \n",
    "    \"base\": []\n",
    "}\n",
    "\n",
    "for rotulo_aparelho in colunas_output:\n",
    "    \n",
    "    print(\"****************************************************************\\n\")\n",
    "    print(f\"* Aparelho `{rotulo_aparelho}`...\\n\")\n",
    "    \n",
    "    #######################################################################\n",
    "    #                AVALIACAO 1 - Base de treino/validacao               #\n",
    "    #######################################################################\n",
    "\n",
    "    # # Filtrando output/status por aparelho\n",
    "    y_treino_aparelho = y_treino[rotulo_aparelho]\n",
    "    y_validacao_aparelho = y_validacao[rotulo_aparelho]\n",
    "\n",
    "    print(f\"  - Avaliando modelo através da base treino/validacao...\")\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem (lote validacao):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_validacao_aparelho).items():\n",
    "        print(f\"       - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_validacao_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "\n",
    "    # Treinando modelo\n",
    "    print(f\"     -> Treinando modelo...\\n\")\n",
    "    clf = clone(modelo)\n",
    "    \n",
    "    clf.fit(X_treino, y_treino_aparelho)\n",
    "\n",
    "    # Prevendo conjunto de dados\n",
    "    y_hat = clf.predict(X_validacao)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "    resultados_modelo[\"fold\"].append(\"-\")\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_validacao_aparelho, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_validacao_aparelho, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_validacao_aparelho, y_hat) if np.unique(y_validacao_aparelho).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"treino-teste\")\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_validacao_aparelho, y_hat))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_validacao_aparelho, y_hat))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    #######################################################################\n",
    "    #                  AVALIACAO 2 - Validacao Cruzada                    #\n",
    "    #######################################################################\n",
    "    \n",
    "    y_true_cv, y_pred_cv  = [], []\n",
    "\n",
    "    print(f\"  - Avaliando através de validação cruzada ({skf.n_splits}-folds)...\")\n",
    "\n",
    "    # Filtrando output/status por aparelho\n",
    "    y_aparelho = y_cv[rotulo_aparelho]\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem:\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_aparelho).items():\n",
    "        print(f\"        - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "    \n",
    "\n",
    "    print(f\"     -> Avaliando modelo (CV - {skf.n_splits} folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in tqdm_notebook(enumerate(skf.split(X_cv, y_aparelho)), total=skf.n_splits):\n",
    "        \n",
    "        # Preparando lotes\n",
    "        X_treino_cv, X_teste_cv = X_cv.iloc[idx_treino], X_cv.iloc[idx_teste]\n",
    "        y_treino_cv, y_teste_cv = y_aparelho.iloc[idx_treino], y_aparelho.iloc[idx_teste]\n",
    "\n",
    "        # Treinando modelo\n",
    "        clf = clone(modelo)\n",
    "        \n",
    "        clf.fit(X_treino_cv, y_treino_cv)\n",
    "\n",
    "        # Prevendo conjunto de dados\n",
    "        y_hat = clf.predict(X_teste_cv)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste_cv, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste_cv, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste_cv, y_hat) if np.unique(y_teste_cv).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"cv\")\n",
    "\n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true_cv.extend(y_teste_cv)\n",
    "        y_pred_cv.extend(y_hat)\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true_cv, y_pred_cv))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true_cv, y_pred_cv))\n",
    "    print()\n",
    "    print(\"**********************************************\")\n",
    "    print()\n",
    "    \n",
    "# Consolidando DataFrame\n",
    "df_resultados = pd.DataFrame(resultados_modelo)\n",
    "\n",
    "arquivo_resultados = os.path.join(caminho_dados_notebook, f\"resultados_{dominio}_svm.xlsx\")\n",
    "if os.path.isfile(arquivo_resultados): os.remove(arquivo_resultados)\n",
    "df_resultados.to_excel(arquivo_resultados, index=False)\n",
    "    \n",
    "print(\"############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\")\n",
    "display(df_resultados.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T19:59:41.720698Z",
     "start_time": "2020-08-31T19:59:41.680673Z"
    }
   },
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T03:52:19.841404Z",
     "start_time": "2021-05-02T22:19:01.487888Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "\n",
      "* Aparelho `LC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     12400\n",
      "           1       1.00      0.98      0.99     12800\n",
      "\n",
      "    accuracy                           0.99     25200\n",
      "   macro avg       0.99      0.99      0.99     25200\n",
      "weighted avg       0.99      0.99      0.99     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12381    19]\n",
      " [  239 12561]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128ff98e2a6a42bc89dad40c6d82c409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[30999     1]\n",
      " [    1 31999]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LI`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f632a7818b4a609f61a526e69d82d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MO`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     12400\n",
      "           1       0.98      1.00      0.99     12800\n",
      "\n",
      "    accuracy                           0.99     25200\n",
      "   macro avg       0.99      0.99      0.99     25200\n",
      "weighted avg       0.99      0.99      0.99     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12093   307]\n",
      " [   13 12787]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4155d5e44c54af99dfec7f7e3e4f09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MT`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb0ab14d2fb460eb1e1e2d9e407f182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `PC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33d6fa2c86c430b80ea83d942536a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LF`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     12400\n",
      "           1       0.97      0.95      0.96     12800\n",
      "\n",
      "    accuracy                           0.96     25200\n",
      "   macro avg       0.96      0.96      0.96     25200\n",
      "weighted avg       0.96      0.96      0.96     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[11980   420]\n",
      " [  582 12218]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d82905ba1cb9408cbc98383b6b705851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    2 31998]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LC</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.989762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989762</td>\n",
       "      <td>0.989762</td>\n",
       "      <td>0.989761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989761</td>\n",
       "      <td>0.989761</td>\n",
       "      <td>0.989898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989898</td>\n",
       "      <td>0.989898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LF</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.960238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.960238</td>\n",
       "      <td>0.960238</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.960330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.960330</td>\n",
       "      <td>0.960330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LI</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MO</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.987302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987302</td>\n",
       "      <td>0.987302</td>\n",
       "      <td>0.987292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987292</td>\n",
       "      <td>0.987292</td>\n",
       "      <td>0.987113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987113</td>\n",
       "      <td>0.987113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MT</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PC</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             acc                                      f1  \\\n",
       "                            mean       std       max       min      mean   \n",
       "appliance base                                                             \n",
       "LC        cv            0.999968  0.000043  1.000000  0.999921  0.999968   \n",
       "          treino-teste  0.989762       NaN  0.989762  0.989762  0.989761   \n",
       "LF        cv            0.999968  0.000071  1.000000  0.999841  0.999968   \n",
       "          treino-teste  0.960238       NaN  0.960238  0.960238  0.960235   \n",
       "LI        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "MO        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  0.987302       NaN  0.987302  0.987302  0.987292   \n",
       "MT        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "PC        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "\n",
       "                                                           auc            \\\n",
       "                             std       max       min      mean       std   \n",
       "appliance base                                                             \n",
       "LC        cv            0.000043  1.000000  0.999921  0.999968  0.000043   \n",
       "          treino-teste       NaN  0.989761  0.989761  0.989898       NaN   \n",
       "LF        cv            0.000071  1.000000  0.999841  0.999969  0.000070   \n",
       "          treino-teste       NaN  0.960235  0.960235  0.960330       NaN   \n",
       "LI        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "MO        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  0.987292  0.987292  0.987113       NaN   \n",
       "MT        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "PC        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "\n",
       "                                            \n",
       "                             max       min  \n",
       "appliance base                              \n",
       "LC        cv            1.000000  0.999919  \n",
       "          treino-teste  0.989898  0.989898  \n",
       "LF        cv            1.000000  0.999844  \n",
       "          treino-teste  0.960330  0.960330  \n",
       "LI        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "MO        cv            1.000000  1.000000  \n",
       "          treino-teste  0.987113  0.987113  \n",
       "MT        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "PC        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo = XGBClassifier(eval_metric='error', random_state=SEED, n_jobs=4)\n",
    "\n",
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \n",
    "    \"base\": []\n",
    "}\n",
    "\n",
    "for rotulo_aparelho in colunas_output:\n",
    "    \n",
    "    print(\"****************************************************************\\n\")\n",
    "    print(f\"* Aparelho `{rotulo_aparelho}`...\\n\")\n",
    "    \n",
    "    #######################################################################\n",
    "    #                AVALIACAO 1 - Base de treino/validacao               #\n",
    "    #######################################################################\n",
    "\n",
    "    # # Filtrando output/status por aparelho\n",
    "    y_treino_aparelho = y_treino[rotulo_aparelho]\n",
    "    y_validacao_aparelho = y_validacao[rotulo_aparelho]\n",
    "\n",
    "    print(f\"  - Avaliando modelo através da base treino/validacao...\")\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem (lote validacao):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_validacao_aparelho).items():\n",
    "        print(f\"       - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_validacao_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "\n",
    "    # Treinando modelo\n",
    "    print(f\"     -> Treinando modelo...\\n\")\n",
    "    clf = clone(modelo)\n",
    "    \n",
    "    clf.fit(X_treino, y_treino_aparelho)\n",
    "\n",
    "    # Prevendo conjunto de dados\n",
    "    y_hat = clf.predict(X_validacao)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "    resultados_modelo[\"fold\"].append(\"-\")\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_validacao_aparelho, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_validacao_aparelho, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_validacao_aparelho, y_hat) if np.unique(y_validacao_aparelho).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"treino-teste\")\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_validacao_aparelho, y_hat))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_validacao_aparelho, y_hat))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    #######################################################################\n",
    "    #                  AVALIACAO 2 - Validacao Cruzada                    #\n",
    "    #######################################################################\n",
    "    \n",
    "    y_true_cv, y_pred_cv  = [], []\n",
    "\n",
    "    print(f\"  - Avaliando através de validação cruzada ({skf.n_splits}-folds)...\")\n",
    "\n",
    "    # Filtrando output/status por aparelho\n",
    "    y_aparelho = y_cv[rotulo_aparelho]\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem:\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_aparelho).items():\n",
    "        print(f\"        - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "    \n",
    "\n",
    "    print(f\"     -> Avaliando modelo (CV - {skf.n_splits} folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in tqdm_notebook(enumerate(skf.split(X_cv, y_aparelho)), total=skf.n_splits):\n",
    "        \n",
    "        # Preparando lotes\n",
    "        X_treino_cv, X_teste_cv = X_cv.iloc[idx_treino], X_cv.iloc[idx_teste]\n",
    "        y_treino_cv, y_teste_cv = y_aparelho.iloc[idx_treino], y_aparelho.iloc[idx_teste]\n",
    "\n",
    "        # Treinando modelo\n",
    "        clf = clone(modelo)\n",
    "        \n",
    "        clf.fit(X_treino_cv, y_treino_cv)\n",
    "\n",
    "        # Prevendo conjunto de dados\n",
    "        y_hat = clf.predict(X_teste_cv)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste_cv, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste_cv, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste_cv, y_hat) if np.unique(y_teste_cv).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"cv\")\n",
    "\n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true_cv.extend(y_teste_cv)\n",
    "        y_pred_cv.extend(y_hat)\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true_cv, y_pred_cv))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true_cv, y_pred_cv))\n",
    "    print()\n",
    "    print(\"**********************************************\")\n",
    "    print()\n",
    "\n",
    "# Consolidando DataFrame\n",
    "df_resultados = pd.DataFrame(resultados_modelo)\n",
    "\n",
    "arquivo_resultados = os.path.join(caminho_dados_notebook, f\"resultados_{dominio}_xgboost.xlsx\")\n",
    "if os.path.isfile(arquivo_resultados): os.remove(arquivo_resultados)\n",
    "df_resultados.to_excel(arquivo_resultados, index=False)\n",
    "    \n",
    "print(\"############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\")\n",
    "display(df_resultados.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:10:29.051087Z",
     "start_time": "2021-05-03T03:52:22.146464Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "\n",
      "* Aparelho `LC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df619ccbbef346449319f2a4f651ecba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LI`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bcd9832e1e44a4084ca199f966cec87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MO`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864ada0fda3043beaad5513c8a366eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.48      0.65     31000\n",
      "           1       0.67      1.00      0.80     32000\n",
      "\n",
      "    accuracy                           0.75     63000\n",
      "   macro avg       0.83      0.74      0.73     63000\n",
      "weighted avg       0.83      0.75      0.73     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[15000 16000]\n",
      " [   45 31955]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MT`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e191ac5d89b54584a89e9c2b5c4715ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `PC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84     12400\n",
      "           1       0.83      0.90      0.86     12800\n",
      "\n",
      "    accuracy                           0.85     25200\n",
      "   macro avg       0.86      0.85      0.85     25200\n",
      "weighted avg       0.86      0.85      0.85     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[10009  2391]\n",
      " [ 1308 11492]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9977f5963a24a0695f9a3106a21bf2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.87     31000\n",
      "           1       0.84      0.94      0.89     32000\n",
      "\n",
      "    accuracy                           0.88     63000\n",
      "   macro avg       0.88      0.88      0.88     63000\n",
      "weighted avg       0.88      0.88      0.88     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[25109  5891]\n",
      " [ 1845 30155]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LF`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87     12400\n",
      "           1       0.87      0.87      0.87     12800\n",
      "\n",
      "    accuracy                           0.87     25200\n",
      "   macro avg       0.87      0.87      0.87     25200\n",
      "weighted avg       0.87      0.87      0.87     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[10784  1616]\n",
      " [ 1609 11191]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a41eae27d574bac9104b1bf849d84a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90     31000\n",
      "           1       0.91      0.90      0.90     32000\n",
      "\n",
      "    accuracy                           0.90     63000\n",
      "   macro avg       0.90      0.90      0.90     63000\n",
      "weighted avg       0.90      0.90      0.90     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[27998  3002]\n",
      " [ 3266 28734]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LC</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LF</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.900508</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.896032</td>\n",
       "      <td>0.900493</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>0.904188</td>\n",
       "      <td>0.896004</td>\n",
       "      <td>0.900549</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.904214</td>\n",
       "      <td>0.895998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.872024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.872024</td>\n",
       "      <td>0.872024</td>\n",
       "      <td>0.871990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.871990</td>\n",
       "      <td>0.871990</td>\n",
       "      <td>0.871987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.871987</td>\n",
       "      <td>0.871987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LI</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MO</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.745317</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.748254</td>\n",
       "      <td>0.743492</td>\n",
       "      <td>0.725425</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.729423</td>\n",
       "      <td>0.723475</td>\n",
       "      <td>0.741232</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.744254</td>\n",
       "      <td>0.739408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MT</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PC</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.877206</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.878730</td>\n",
       "      <td>0.875714</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.877882</td>\n",
       "      <td>0.874976</td>\n",
       "      <td>0.876156</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.877629</td>\n",
       "      <td>0.874793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.853214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.853214</td>\n",
       "      <td>0.853214</td>\n",
       "      <td>0.852704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.852704</td>\n",
       "      <td>0.852704</td>\n",
       "      <td>0.852495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.852495</td>\n",
       "      <td>0.852495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             acc                                      f1  \\\n",
       "                            mean       std       max       min      mean   \n",
       "appliance base                                                             \n",
       "LC        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "LF        cv            0.900508  0.003033  0.904206  0.896032  0.900493   \n",
       "          treino-teste  0.872024       NaN  0.872024  0.872024  0.871990   \n",
       "LI        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "MO        cv            0.745317  0.001864  0.748254  0.743492  0.725425   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "MT        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "PC        cv            0.877206  0.001313  0.878730  0.875714  0.876404   \n",
       "          treino-teste  0.853214       NaN  0.853214  0.853214  0.852704   \n",
       "\n",
       "                                                           auc            \\\n",
       "                             std       max       min      mean       std   \n",
       "appliance base                                                             \n",
       "LC        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "LF        cv            0.003038  0.904188  0.896004  0.900549  0.003056   \n",
       "          treino-teste       NaN  0.871990  0.871990  0.871987       NaN   \n",
       "LI        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "MO        cv            0.002426  0.729423  0.723475  0.741232  0.001905   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "MT        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "PC        cv            0.001292  0.877882  0.874976  0.876156  0.001278   \n",
       "          treino-teste       NaN  0.852704  0.852704  0.852495       NaN   \n",
       "\n",
       "                                            \n",
       "                             max       min  \n",
       "appliance base                              \n",
       "LC        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "LF        cv            0.904214  0.895998  \n",
       "          treino-teste  0.871987  0.871987  \n",
       "LI        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "MO        cv            0.744254  0.739408  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "MT        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "PC        cv            0.877629  0.874793  \n",
       "          treino-teste  0.852495  0.852495  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo = MLPClassifier(alpha=1e-3, hidden_layer_sizes=(10,), random_state=SEED)\n",
    "\n",
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \n",
    "    \"base\": []\n",
    "}\n",
    "\n",
    "for rotulo_aparelho in colunas_output:\n",
    "    \n",
    "    print(\"****************************************************************\\n\")\n",
    "    print(f\"* Aparelho `{rotulo_aparelho}`...\\n\")\n",
    "    \n",
    "    #######################################################################\n",
    "    #                AVALIACAO 1 - Base de treino/validacao               #\n",
    "    #######################################################################\n",
    "\n",
    "    # # Filtrando output/status por aparelho\n",
    "    y_treino_aparelho = y_treino[rotulo_aparelho]\n",
    "    y_validacao_aparelho = y_validacao[rotulo_aparelho]\n",
    "\n",
    "    print(f\"  - Avaliando modelo através da base treino/validacao...\")\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem (lote validacao):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_validacao_aparelho).items():\n",
    "        print(f\"       - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_validacao_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "\n",
    "    # Treinando modelo\n",
    "    print(f\"     -> Treinando modelo...\\n\")\n",
    "    clf = clone(modelo)\n",
    "    \n",
    "    clf.fit(X_treino, y_treino_aparelho)\n",
    "\n",
    "    # Prevendo conjunto de dados\n",
    "    y_hat = clf.predict(X_validacao)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "    resultados_modelo[\"fold\"].append(\"-\")\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_validacao_aparelho, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_validacao_aparelho, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_validacao_aparelho, y_hat) if np.unique(y_validacao_aparelho).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"treino-teste\")\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_validacao_aparelho, y_hat))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_validacao_aparelho, y_hat))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    #######################################################################\n",
    "    #                  AVALIACAO 2 - Validacao Cruzada                    #\n",
    "    #######################################################################\n",
    "    \n",
    "    y_true_cv, y_pred_cv  = [], []\n",
    "\n",
    "    print(f\"  - Avaliando através de validação cruzada ({skf.n_splits}-folds)...\")\n",
    "\n",
    "    # Filtrando output/status por aparelho\n",
    "    y_aparelho = y_cv[rotulo_aparelho]\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem:\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_aparelho).items():\n",
    "        print(f\"        - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "    \n",
    "\n",
    "    print(f\"     -> Avaliando modelo (CV - {skf.n_splits} folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in tqdm_notebook(enumerate(skf.split(X_cv, y_aparelho)), total=skf.n_splits):\n",
    "        \n",
    "        # Preparando lotes\n",
    "        X_treino_cv, X_teste_cv = X_cv.iloc[idx_treino], X_cv.iloc[idx_teste]\n",
    "        y_treino_cv, y_teste_cv = y_aparelho.iloc[idx_treino], y_aparelho.iloc[idx_teste]\n",
    "\n",
    "        # Treinando modelo\n",
    "        clf = clone(modelo)\n",
    "        \n",
    "        clf.fit(X_treino_cv, y_treino_cv)\n",
    "\n",
    "        # Prevendo conjunto de dados\n",
    "        y_hat = clf.predict(X_teste_cv)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste_cv, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste_cv, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste_cv, y_hat) if np.unique(y_teste_cv).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"cv\")\n",
    "\n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true_cv.extend(y_teste_cv)\n",
    "        y_pred_cv.extend(y_hat)\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true_cv, y_pred_cv))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true_cv, y_pred_cv))\n",
    "    print()\n",
    "    print(\"**********************************************\")\n",
    "    print()\n",
    "\n",
    "# Consolidando DataFrame\n",
    "df_resultados = pd.DataFrame(resultados_modelo)\n",
    "\n",
    "arquivo_resultados = os.path.join(caminho_dados_notebook, f\"resultados_{dominio}_mlp.xlsx\")\n",
    "if os.path.isfile(arquivo_resultados): os.remove(arquivo_resultados)\n",
    "df_resultados.to_excel(arquivo_resultados, index=False)\n",
    "    \n",
    "print(\"############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\")\n",
    "display(df_resultados.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise dos Resultados (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:10:32.077065Z",
     "start_time": "2021-05-03T09:10:31.295643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Análise por modelo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBOOST</th>\n",
       "      <td>cv</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBOOST</th>\n",
       "      <td>treino-teste</td>\n",
       "      <td>0.989550</td>\n",
       "      <td>0.015440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960238</td>\n",
       "      <td>0.989548</td>\n",
       "      <td>0.015441</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.989557</td>\n",
       "      <td>0.015411</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>treino-teste</td>\n",
       "      <td>0.954206</td>\n",
       "      <td>0.071192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.853214</td>\n",
       "      <td>0.954116</td>\n",
       "      <td>0.071345</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852704</td>\n",
       "      <td>0.954080</td>\n",
       "      <td>0.071405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>cv</td>\n",
       "      <td>0.944894</td>\n",
       "      <td>0.096612</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.736190</td>\n",
       "      <td>0.944832</td>\n",
       "      <td>0.096722</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.735730</td>\n",
       "      <td>0.944965</td>\n",
       "      <td>0.096713</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.735713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>treino-teste</td>\n",
       "      <td>0.936224</td>\n",
       "      <td>0.106449</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.936161</td>\n",
       "      <td>0.106510</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>0.936380</td>\n",
       "      <td>0.106350</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>cv</td>\n",
       "      <td>0.920505</td>\n",
       "      <td>0.094627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.743492</td>\n",
       "      <td>0.917054</td>\n",
       "      <td>0.101116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.723475</td>\n",
       "      <td>0.919656</td>\n",
       "      <td>0.096015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.739408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 base       acc                                 f1            \\\n",
       "                           mean       std  max       min      mean       std   \n",
       "model                                                                          \n",
       "XGBOOST            cv  0.999989  0.000034  1.0  0.999841  0.999989  0.000034   \n",
       "XGBOOST  treino-teste  0.989550  0.015440  1.0  0.960238  0.989548  0.015441   \n",
       "MLP      treino-teste  0.954206  0.071192  1.0  0.853214  0.954116  0.071345   \n",
       "SVM                cv  0.944894  0.096612  1.0  0.736190  0.944832  0.096722   \n",
       "SVM      treino-teste  0.936224  0.106449  1.0  0.746032  0.936161  0.106510   \n",
       "MLP                cv  0.920505  0.094627  1.0  0.743492  0.917054  0.101116   \n",
       "\n",
       "                             auc                           \n",
       "         max       min      mean       std  max       min  \n",
       "model                                                      \n",
       "XGBOOST  1.0  0.999841  0.999989  0.000034  1.0  0.999844  \n",
       "XGBOOST  1.0  0.960235  0.989557  0.015411  1.0  0.960330  \n",
       "MLP      1.0  0.852704  0.954080  0.071405  1.0  0.852495  \n",
       "SVM      1.0  0.735730  0.944965  0.096713  1.0  0.735713  \n",
       "SVM      1.0  0.745968  0.936380  0.106350  1.0  0.745968  \n",
       "MLP      1.0  0.723475  0.919656  0.096015  1.0  0.739408  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Análise por aparelho/modelo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>model</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">LC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.989762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989762</td>\n",
       "      <td>0.989762</td>\n",
       "      <td>0.989761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989761</td>\n",
       "      <td>0.989761</td>\n",
       "      <td>0.989898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989898</td>\n",
       "      <td>0.989898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">LF</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.900508</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.896032</td>\n",
       "      <td>0.900493</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>0.904188</td>\n",
       "      <td>0.896004</td>\n",
       "      <td>0.900549</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.904214</td>\n",
       "      <td>0.895998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.872024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.872024</td>\n",
       "      <td>0.872024</td>\n",
       "      <td>0.871990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.871990</td>\n",
       "      <td>0.871990</td>\n",
       "      <td>0.871987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.871987</td>\n",
       "      <td>0.871987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.740714</td>\n",
       "      <td>0.003310</td>\n",
       "      <td>0.744127</td>\n",
       "      <td>0.736190</td>\n",
       "      <td>0.740423</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>0.743966</td>\n",
       "      <td>0.735730</td>\n",
       "      <td>0.740380</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.743916</td>\n",
       "      <td>0.735713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.746032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>0.745968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.960238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.960238</td>\n",
       "      <td>0.960238</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.960330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.960330</td>\n",
       "      <td>0.960330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">LI</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MO</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.745317</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.748254</td>\n",
       "      <td>0.743492</td>\n",
       "      <td>0.725425</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.729423</td>\n",
       "      <td>0.723475</td>\n",
       "      <td>0.741232</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.744254</td>\n",
       "      <td>0.739408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.987302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987302</td>\n",
       "      <td>0.987302</td>\n",
       "      <td>0.987292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987292</td>\n",
       "      <td>0.987292</td>\n",
       "      <td>0.987113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987113</td>\n",
       "      <td>0.987113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MT</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">PC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.877206</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.878730</td>\n",
       "      <td>0.875714</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.877882</td>\n",
       "      <td>0.874976</td>\n",
       "      <td>0.876156</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.877629</td>\n",
       "      <td>0.874793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.853214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.853214</td>\n",
       "      <td>0.853214</td>\n",
       "      <td>0.852704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.852704</td>\n",
       "      <td>0.852704</td>\n",
       "      <td>0.852495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.852495</td>\n",
       "      <td>0.852495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.928651</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.935397</td>\n",
       "      <td>0.923413</td>\n",
       "      <td>0.928570</td>\n",
       "      <td>0.005976</td>\n",
       "      <td>0.935340</td>\n",
       "      <td>0.923316</td>\n",
       "      <td>0.929408</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.936104</td>\n",
       "      <td>0.924209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.871310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.871310</td>\n",
       "      <td>0.871310</td>\n",
       "      <td>0.870996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.870996</td>\n",
       "      <td>0.870996</td>\n",
       "      <td>0.872312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.872312</td>\n",
       "      <td>0.872312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     acc                                \\\n",
       "                                    mean       std       max       min   \n",
       "appliance model   base                                                   \n",
       "LC        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            0.999968  0.000043  1.000000  0.999921   \n",
       "                  treino-teste  0.989762       NaN  0.989762  0.989762   \n",
       "LF        MLP     cv            0.900508  0.003033  0.904206  0.896032   \n",
       "                  treino-teste  0.872024       NaN  0.872024  0.872024   \n",
       "          SVM     cv            0.740714  0.003310  0.744127  0.736190   \n",
       "                  treino-teste  0.746032       NaN  0.746032  0.746032   \n",
       "          XGBOOST cv            0.999968  0.000071  1.000000  0.999841   \n",
       "                  treino-teste  0.960238       NaN  0.960238  0.960238   \n",
       "LI        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "MO        MLP     cv            0.745317  0.001864  0.748254  0.743492   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  0.987302       NaN  0.987302  0.987302   \n",
       "MT        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "PC        MLP     cv            0.877206  0.001313  0.878730  0.875714   \n",
       "                  treino-teste  0.853214       NaN  0.853214  0.853214   \n",
       "          SVM     cv            0.928651  0.005950  0.935397  0.923413   \n",
       "                  treino-teste  0.871310       NaN  0.871310  0.871310   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "\n",
       "                                      f1                                \\\n",
       "                                    mean       std       max       min   \n",
       "appliance model   base                                                   \n",
       "LC        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            0.999968  0.000043  1.000000  0.999921   \n",
       "                  treino-teste  0.989761       NaN  0.989761  0.989761   \n",
       "LF        MLP     cv            0.900493  0.003038  0.904188  0.896004   \n",
       "                  treino-teste  0.871990       NaN  0.871990  0.871990   \n",
       "          SVM     cv            0.740423  0.003435  0.743966  0.735730   \n",
       "                  treino-teste  0.745968       NaN  0.745968  0.745968   \n",
       "          XGBOOST cv            0.999968  0.000071  1.000000  0.999841   \n",
       "                  treino-teste  0.960235       NaN  0.960235  0.960235   \n",
       "LI        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "MO        MLP     cv            0.725425  0.002426  0.729423  0.723475   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  0.987292       NaN  0.987292  0.987292   \n",
       "MT        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "PC        MLP     cv            0.876404  0.001292  0.877882  0.874976   \n",
       "                  treino-teste  0.852704       NaN  0.852704  0.852704   \n",
       "          SVM     cv            0.928570  0.005976  0.935340  0.923316   \n",
       "                  treino-teste  0.870996       NaN  0.870996  0.870996   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "\n",
       "                                     auc                                \n",
       "                                    mean       std       max       min  \n",
       "appliance model   base                                                  \n",
       "LC        MLP     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          XGBOOST cv            0.999968  0.000043  1.000000  0.999919  \n",
       "                  treino-teste  0.989898       NaN  0.989898  0.989898  \n",
       "LF        MLP     cv            0.900549  0.003056  0.904214  0.895998  \n",
       "                  treino-teste  0.871987       NaN  0.871987  0.871987  \n",
       "          SVM     cv            0.740380  0.003423  0.743916  0.735713  \n",
       "                  treino-teste  0.745968       NaN  0.745968  0.745968  \n",
       "          XGBOOST cv            0.999969  0.000070  1.000000  0.999844  \n",
       "                  treino-teste  0.960330       NaN  0.960330  0.960330  \n",
       "LI        MLP     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "MO        MLP     cv            0.741232  0.001905  0.744254  0.739408  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  0.987113       NaN  0.987113  0.987113  \n",
       "MT        MLP     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "PC        MLP     cv            0.876156  0.001278  0.877629  0.874793  \n",
       "                  treino-teste  0.852495       NaN  0.852495  0.852495  \n",
       "          SVM     cv            0.929408  0.005882  0.936104  0.924209  \n",
       "                  treino-teste  0.872312       NaN  0.872312  0.872312  \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_resultados_svm = pd.read_excel(os.path.join(caminho_dados_notebook, f\"resultados_{dominio}_svm.xlsx\"), engine='openpyxl')\n",
    "df_resultados_svm[\"model\"] = \"SVM\"\n",
    "\n",
    "df_resultados_xgboost = pd.read_excel(os.path.join(caminho_dados_notebook, f\"resultados_{dominio}_xgboost.xlsx\"), engine='openpyxl')\n",
    "df_resultados_xgboost[\"model\"] = \"XGBOOST\"\n",
    "\n",
    "df_resultados_mlp = pd.read_excel(os.path.join(caminho_dados_notebook, f\"resultados_{dominio}_mlp.xlsx\"), engine='openpyxl')\n",
    "df_resultados_mlp[\"model\"] = \"MLP\"\n",
    "\n",
    "# df_resultados_elm = pd.read_excel(os.path.join(caminho_dados_notebook, \"df_resultados_elm.xlsx\"))\n",
    "# df_resultados_elm[\"model\"] = \"ELM\"\n",
    "\n",
    "df_analise = pd.concat([\n",
    "    df_resultados_svm,\n",
    "    df_resultados_xgboost,\n",
    "    df_resultados_mlp, \n",
    "#     df_resultados_elm,  \n",
    "])\n",
    "\n",
    "print(\"* Análise por modelo:\")\n",
    "df_analise_modelo = df_analise.groupby([\"model\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"f1\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"auc\": [\"mean\",\"std\",\"max\",\"min\"]\n",
    "}).reset_index().sort_values(('f1','mean'), ascending=False).set_index(\"model\")\n",
    "display(df_analise_modelo)\n",
    "df_analise_modelo.to_excel(os.path.join(caminho_dados_notebook, f\"analise_{dominio}_modelos.xlsx\"))\n",
    "\n",
    "print()\n",
    "print(\"* Análise por aparelho/modelo:\")\n",
    "df_analise_aparelho = df_analise.groupby([\"appliance\",\"model\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"f1\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"auc\": [\"mean\",\"std\",\"max\",\"min\"]\n",
    "})#.reset_index().sort_values(('f1','mean'), ascending=False).set_index([\"aparelho\",\"metodologia\"])\n",
    "display(df_analise_aparelho)\n",
    "df_analise_aparelho.to_excel(os.path.join(caminho_dados_notebook, f\"analise_{dominio}_aparelhos.xls\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:10:32.109285Z",
     "start_time": "2021-05-03T09:10:32.079991Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:10:32.155124Z",
     "start_time": "2021-05-03T09:10:32.113288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Diego Luiz Cavalca\n",
      "\n",
      "Last updated: Mon Jan 24 2022 08:52:41Hora oficial do Brasil\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.8\n",
      "IPython version      : 7.21.0\n",
      "\n",
      "Compiler    : MSC v.1928 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 158 Stepping 9, GenuineIntel\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 5e5bccaaf9e541e11be67706c7eb7d7b39a8be65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -a \"Diego Luiz Cavalca\" -u -n -t -z -v -m -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

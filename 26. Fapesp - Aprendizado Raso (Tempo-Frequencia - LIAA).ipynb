{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Defesa - Dataset LIAA - Aprendizado Raso em Atributos no domínio do Tempo/Frequência"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estruturação de pipeline baseado em aprendizado raso utilizando atributos de alta frequência.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T17:00:00.198228Z",
     "start_time": "2021-05-02T16:59:56.833044Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "from pretty_confusion_matrix import *\n",
    "\n",
    "# TODO: implementar rotina na classe PyNILM.utils\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "def listar_variaveis_memoria(ambiente):\n",
    "    print(\"* Variáveis instanciadas em memória:\")\n",
    "    print(\"---\")\n",
    "    total = 0\n",
    "    for name, size in sorted(((name, sys.getsizeof(value)) for name, value in ambiente.items()),\n",
    "                             key= lambda x: -x[1])[:10]:\n",
    "        total += size\n",
    "        print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))\n",
    "    print(\"---\")\n",
    "    print(\"Total:\", sizeof_fmt(total))\n",
    "    \n",
    "# TODO: implementar na classe utils\n",
    "def highlight_col(x):\n",
    "    r = 'background-color: #D9D9D9'\n",
    "    df1 = pd.DataFrame('', index=x.index, columns=x.columns)\n",
    "    df1.iloc[:, -2] = r\n",
    "    return df1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T17:00:00.322361Z",
     "start_time": "2021-05-02T17:00:00.201233Z"
    }
   },
   "outputs": [],
   "source": [
    "# CONSTANTES FUNDAMENTAIS DE ORGANIZACAO DE PASTAS/ARQUIVOS\n",
    "RESIDENCIA = 3\n",
    "\n",
    "# Path do arquivo H5 (base REDD ja preparada p/ NILMTK) e outros insumos fundamentais\n",
    "caminho_dados = \"D:/Projetos/phd-thesis/datasets/\"\n",
    "\n",
    "# Definir diretorios onde iremos salvar os insumos gerados do notebook (dados, imagens, etc.)\n",
    "caminho_dados_notebook = os.path.join(caminho_dados, \"26\") # Num. notebook\n",
    "if not os.path.isdir(caminho_dados_notebook):\n",
    "    os.makedirs(caminho_dados_notebook)\n",
    "caminho_imagens_notebook = os.path.join(caminho_dados_notebook, \"imagens\") # Num. notebook\n",
    "if not os.path.isdir(caminho_imagens_notebook):\n",
    "    os.makedirs(caminho_imagens_notebook)\n",
    "\n",
    "# Path do arquivo H5 (base REDD ja preparada p/ NILMTK)\n",
    "caminho_redd = os.path.join(caminho_dados, \"REDD/low_freq\")\n",
    "\n",
    "# Path completo do arquivo REDD\n",
    "arquivo_dataset = os.path.join(caminho_redd, \"redd.h5\")\n",
    "\n",
    "# VARIAVEL AUXILIAR\n",
    "# Path dos arquivos relacionados as janelas\n",
    "caminho_janelas = os.path.join(caminho_redd, \"../../phd\")\n",
    "if not os.path.isdir(caminho_janelas):\n",
    "    os.makedirs(caminho_janelas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T17:00:01.903538Z",
     "start_time": "2021-05-02T17:00:00.325362Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from six import iteritems\n",
    "\n",
    "from nilmtk import DataSet, TimeFrame, MeterGroup, HDFDataStore\n",
    "from nilmtk.legacy.disaggregate import CombinatorialOptimisation, FHMM\n",
    "import nilmtk.utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando datasets\n",
    "df_treino = pd.read_csv(os.path.join(caminho_dados_notebook, '512_UmCiclo_Treinamento.csv'))\n",
    "df_validacao = pd.read_csv(os.path.join(caminho_dados_notebook, '512_UmCiclo_Validacao.csv'))\n",
    "\n",
    "# Selecionando feature dominio do tempo e frequencia / outputs (status dos aparelhos - dummy)\n",
    "colunas_tempo = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10']\n",
    "colunas_frequencia = ['Fund', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th', '10th',\n",
    "       '11th', '12th', '13th', '14th', '15th']\n",
    "\n",
    "colunas_output = ['LC', 'LI', 'MO', 'MT', 'PC', 'LF']\n",
    "\n",
    "# Preparando dados de treino e validacao por dominio\n",
    "X_treino_tempo = df_treino[colunas_tempo]\n",
    "X_validacao_tempo = df_validacao[colunas_tempo]\n",
    "\n",
    "X_treino_frequencia = df_treino[colunas_frequencia]\n",
    "X_validacao_frequencia = df_validacao[colunas_frequencia]\n",
    "\n",
    "y_treino = df_treino[colunas_output].replace(-1, 0)\n",
    "y_validacao = df_validacao[colunas_output].replace(-1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento e Avaliação dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T17:00:27.268721Z",
     "start_time": "2021-05-02T17:00:16.855220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "# from PyNILM.dados.janelas import Janelas\n",
    "from PyNILM.dados.janelas import Janelas\n",
    "from PyNILM.dados.utils import *\n",
    "\n",
    "from PyNILM.avaliacao.metricas import *\n",
    "from PyNILM.avaliacao.graficos import *\n",
    "from PyNILM.avaliacao.analises import *\n",
    "\n",
    "from PyNILM.modelos.utils import *\n",
    "from PyNILM.modelos.dlafe import DLAFE\n",
    "from PyNILM.modelos.rqa import RQA\n",
    "\n",
    "# Inicializar uso GPU\n",
    "start_tf_session(memory_limit=int(1024*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T17:00:27.377109Z",
     "start_time": "2021-05-02T17:00:27.271695Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atributos Domínio do Tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dominio = 'tempo'\n",
    "\n",
    "X_treino = X_treino_tempo\n",
    "X_validacao = X_validacao_tempo\n",
    "\n",
    "# Dados agregados (validacao cruzada)\n",
    "X_cv = pd.concat([X_treino, X_validacao]).reset_index(drop=True) \n",
    "y_cv = pd.concat([y_treino, y_validacao]).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T22:18:59.268806Z",
     "start_time": "2021-05-02T17:03:12.352604Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "\n",
      "* Aparelho `LC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.65      0.60     12400\n",
      "           1       0.60      0.53      0.56     12800\n",
      "\n",
      "    accuracy                           0.58     25200\n",
      "   macro avg       0.59      0.59      0.58     25200\n",
      "weighted avg       0.59      0.58      0.58     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[8000 4400]\n",
      " [6061 6739]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2e6edc020140f2b4f4a4394c2c9523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.65      0.61     31000\n",
      "           1       0.61      0.53      0.57     32000\n",
      "\n",
      "    accuracy                           0.59     63000\n",
      "   macro avg       0.59      0.59      0.59     63000\n",
      "weighted avg       0.59      0.59      0.59     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[20018 10982]\n",
      " [14996 17004]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LI`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.93     12400\n",
      "           1       0.91      0.95      0.93     12800\n",
      "\n",
      "    accuracy                           0.93     25200\n",
      "   macro avg       0.93      0.93      0.93     25200\n",
      "weighted avg       0.93      0.93      0.93     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[11200  1200]\n",
      " [  583 12217]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f1c40d744b4cdf818a32fd843de90c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93     31000\n",
      "           1       0.91      0.97      0.94     32000\n",
      "\n",
      "    accuracy                           0.94     63000\n",
      "   macro avg       0.94      0.94      0.94     63000\n",
      "weighted avg       0.94      0.94      0.94     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[27997  3003]\n",
      " [ 1000 31000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MO`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.61      0.71     12400\n",
      "           1       0.70      0.88      0.78     12800\n",
      "\n",
      "    accuracy                           0.75     25200\n",
      "   macro avg       0.77      0.75      0.74     25200\n",
      "weighted avg       0.77      0.75      0.74     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[ 7600  4800]\n",
      " [ 1505 11295]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59cce1425a554f1fb1fa026035ae4a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.61      0.73     31000\n",
      "           1       0.71      0.93      0.81     32000\n",
      "\n",
      "    accuracy                           0.77     63000\n",
      "   macro avg       0.80      0.77      0.77     63000\n",
      "weighted avg       0.80      0.77      0.77     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[18997 12003]\n",
      " [ 2214 29786]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MT`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89     12400\n",
      "           1       0.88      0.91      0.90     12800\n",
      "\n",
      "    accuracy                           0.89     25200\n",
      "   macro avg       0.89      0.89      0.89     25200\n",
      "weighted avg       0.89      0.89      0.89     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[10801  1599]\n",
      " [ 1089 11711]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7187eb34cc40d3bef64def2945bfeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89     31000\n",
      "           1       0.90      0.89      0.90     32000\n",
      "\n",
      "    accuracy                           0.90     63000\n",
      "   macro avg       0.90      0.90      0.90     63000\n",
      "weighted avg       0.90      0.90      0.90     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[27849  3151]\n",
      " [ 3389 28611]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `PC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.87      0.74     12400\n",
      "           1       0.81      0.52      0.63     12800\n",
      "\n",
      "    accuracy                           0.69     25200\n",
      "   macro avg       0.72      0.69      0.68     25200\n",
      "weighted avg       0.72      0.69      0.68     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[10813  1587]\n",
      " [ 6185  6615]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cffb550ca2c546df95383c44d5a4f047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.91      0.75     31000\n",
      "           1       0.85      0.51      0.64     32000\n",
      "\n",
      "    accuracy                           0.70     63000\n",
      "   macro avg       0.75      0.71      0.69     63000\n",
      "weighted avg       0.75      0.70      0.69     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[28161  2839]\n",
      " [15789 16211]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LF`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.37      0.50     12400\n",
      "           1       0.59      0.89      0.71     12800\n",
      "\n",
      "    accuracy                           0.63     25200\n",
      "   macro avg       0.68      0.63      0.60     25200\n",
      "weighted avg       0.67      0.63      0.61     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[ 4597  7803]\n",
      " [ 1464 11336]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1d976a79d84530a21f404ff02213b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.36      0.48     31000\n",
      "           1       0.58      0.87      0.70     32000\n",
      "\n",
      "    accuracy                           0.62     63000\n",
      "   macro avg       0.66      0.62      0.59     63000\n",
      "weighted avg       0.66      0.62      0.59     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[11211 19789]\n",
      " [ 4159 27841]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LC</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.587651</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>0.591032</td>\n",
       "      <td>0.578810</td>\n",
       "      <td>0.586566</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.590842</td>\n",
       "      <td>0.577654</td>\n",
       "      <td>0.588558</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>0.591588</td>\n",
       "      <td>0.579786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.584881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.584881</td>\n",
       "      <td>0.584881</td>\n",
       "      <td>0.583839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583839</td>\n",
       "      <td>0.583839</td>\n",
       "      <td>0.585823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585823</td>\n",
       "      <td>0.585823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LF</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.619873</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>0.635952</td>\n",
       "      <td>0.612619</td>\n",
       "      <td>0.591407</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0.605570</td>\n",
       "      <td>0.584772</td>\n",
       "      <td>0.615838</td>\n",
       "      <td>0.009428</td>\n",
       "      <td>0.631706</td>\n",
       "      <td>0.608662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.632262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632262</td>\n",
       "      <td>0.632262</td>\n",
       "      <td>0.603938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603938</td>\n",
       "      <td>0.603938</td>\n",
       "      <td>0.628175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628175</td>\n",
       "      <td>0.628175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LI</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.936460</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.938968</td>\n",
       "      <td>0.933413</td>\n",
       "      <td>0.936315</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.938846</td>\n",
       "      <td>0.933253</td>\n",
       "      <td>0.935940</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.938495</td>\n",
       "      <td>0.932870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.929246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.929246</td>\n",
       "      <td>0.929246</td>\n",
       "      <td>0.929131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.929131</td>\n",
       "      <td>0.929131</td>\n",
       "      <td>0.928839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.928839</td>\n",
       "      <td>0.928839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MO</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.774333</td>\n",
       "      <td>0.011955</td>\n",
       "      <td>0.789206</td>\n",
       "      <td>0.761508</td>\n",
       "      <td>0.767521</td>\n",
       "      <td>0.011214</td>\n",
       "      <td>0.781202</td>\n",
       "      <td>0.755426</td>\n",
       "      <td>0.771809</td>\n",
       "      <td>0.011745</td>\n",
       "      <td>0.786368</td>\n",
       "      <td>0.759196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.749802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.749802</td>\n",
       "      <td>0.749802</td>\n",
       "      <td>0.744304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.744304</td>\n",
       "      <td>0.744304</td>\n",
       "      <td>0.747663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.747663</td>\n",
       "      <td>0.747663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MT</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.896190</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.902063</td>\n",
       "      <td>0.890794</td>\n",
       "      <td>0.896163</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.902057</td>\n",
       "      <td>0.890793</td>\n",
       "      <td>0.896224</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>0.902165</td>\n",
       "      <td>0.891053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.893333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.893194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.893194</td>\n",
       "      <td>0.893194</td>\n",
       "      <td>0.892985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.892985</td>\n",
       "      <td>0.892985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PC</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.704317</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>0.715714</td>\n",
       "      <td>0.686349</td>\n",
       "      <td>0.693284</td>\n",
       "      <td>0.010469</td>\n",
       "      <td>0.704844</td>\n",
       "      <td>0.676431</td>\n",
       "      <td>0.707507</td>\n",
       "      <td>0.011110</td>\n",
       "      <td>0.718942</td>\n",
       "      <td>0.689302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.691587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.691587</td>\n",
       "      <td>0.691587</td>\n",
       "      <td>0.682784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682784</td>\n",
       "      <td>0.682784</td>\n",
       "      <td>0.694407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.694407</td>\n",
       "      <td>0.694407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             acc                                      f1  \\\n",
       "                            mean       std       max       min      mean   \n",
       "appliance base                                                             \n",
       "LC        cv            0.587651  0.005133  0.591032  0.578810  0.586566   \n",
       "          treino-teste  0.584881       NaN  0.584881  0.584881  0.583839   \n",
       "LF        cv            0.619873  0.009559  0.635952  0.612619  0.591407   \n",
       "          treino-teste  0.632262       NaN  0.632262  0.632262  0.603938   \n",
       "LI        cv            0.936460  0.002049  0.938968  0.933413  0.936315   \n",
       "          treino-teste  0.929246       NaN  0.929246  0.929246  0.929131   \n",
       "MO        cv            0.774333  0.011955  0.789206  0.761508  0.767521   \n",
       "          treino-teste  0.749802       NaN  0.749802  0.749802  0.744304   \n",
       "MT        cv            0.896190  0.004926  0.902063  0.890794  0.896163   \n",
       "          treino-teste  0.893333       NaN  0.893333  0.893333  0.893194   \n",
       "PC        cv            0.704317  0.010984  0.715714  0.686349  0.693284   \n",
       "          treino-teste  0.691587       NaN  0.691587  0.691587  0.682784   \n",
       "\n",
       "                                                           auc            \\\n",
       "                             std       max       min      mean       std   \n",
       "appliance base                                                             \n",
       "LC        cv            0.005277  0.590842  0.577654  0.588558  0.005083   \n",
       "          treino-teste       NaN  0.583839  0.583839  0.585823       NaN   \n",
       "LF        cv            0.008368  0.605570  0.584772  0.615838  0.009428   \n",
       "          treino-teste       NaN  0.603938  0.603938  0.628175       NaN   \n",
       "LI        cv            0.002063  0.938846  0.933253  0.935940  0.002073   \n",
       "          treino-teste       NaN  0.929131  0.929131  0.928839       NaN   \n",
       "MO        cv            0.011214  0.781202  0.755426  0.771809  0.011745   \n",
       "          treino-teste       NaN  0.744304  0.744304  0.747663       NaN   \n",
       "MT        cv            0.004940  0.902057  0.890793  0.896224  0.004938   \n",
       "          treino-teste       NaN  0.893194  0.893194  0.892985       NaN   \n",
       "PC        cv            0.010469  0.704844  0.676431  0.707507  0.011110   \n",
       "          treino-teste       NaN  0.682784  0.682784  0.694407       NaN   \n",
       "\n",
       "                                            \n",
       "                             max       min  \n",
       "appliance base                              \n",
       "LC        cv            0.591588  0.579786  \n",
       "          treino-teste  0.585823  0.585823  \n",
       "LF        cv            0.631706  0.608662  \n",
       "          treino-teste  0.628175  0.628175  \n",
       "LI        cv            0.938495  0.932870  \n",
       "          treino-teste  0.928839  0.928839  \n",
       "MO        cv            0.786368  0.759196  \n",
       "          treino-teste  0.747663  0.747663  \n",
       "MT        cv            0.902165  0.891053  \n",
       "          treino-teste  0.892985  0.892985  \n",
       "PC        cv            0.718942  0.689302  \n",
       "          treino-teste  0.694407  0.694407  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo = SVC(kernel='rbf', random_state=SEED)\n",
    "\n",
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \n",
    "    \"base\": []\n",
    "}\n",
    "\n",
    "for rotulo_aparelho in colunas_output:\n",
    "    \n",
    "    print(\"****************************************************************\\n\")\n",
    "    print(f\"* Aparelho `{rotulo_aparelho}`...\\n\")\n",
    "    \n",
    "    #######################################################################\n",
    "    #                AVALIACAO 1 - Base de treino/validacao               #\n",
    "    #######################################################################\n",
    "\n",
    "    # # Filtrando output/status por aparelho\n",
    "    y_treino_aparelho = y_treino[rotulo_aparelho]\n",
    "    y_validacao_aparelho = y_validacao[rotulo_aparelho]\n",
    "\n",
    "    print(f\"  - Avaliando modelo através da base treino/validacao...\")\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem (lote validacao):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_validacao_aparelho).items():\n",
    "        print(f\"       - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_validacao_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "\n",
    "    # Treinando modelo\n",
    "    print(f\"     -> Treinando modelo...\\n\")\n",
    "    clf = clone(modelo)\n",
    "    \n",
    "    clf.fit(X_treino, y_treino_aparelho)\n",
    "\n",
    "    # Prevendo conjunto de dados\n",
    "    y_hat = clf.predict(X_validacao)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "    resultados_modelo[\"fold\"].append(\"-\")\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_validacao_aparelho, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_validacao_aparelho, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_validacao_aparelho, y_hat) if np.unique(y_validacao_aparelho).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"treino-teste\")\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_validacao_aparelho, y_hat))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_validacao_aparelho, y_hat))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    #######################################################################\n",
    "    #                  AVALIACAO 2 - Validacao Cruzada                    #\n",
    "    #######################################################################\n",
    "    \n",
    "    y_true_cv, y_pred_cv  = [], []\n",
    "\n",
    "    print(f\"  - Avaliando através de validação cruzada ({skf.n_splits}-folds)...\")\n",
    "\n",
    "    # Filtrando output/status por aparelho\n",
    "    y_aparelho = y_cv[rotulo_aparelho]\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem:\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_aparelho).items():\n",
    "        print(f\"        - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "    \n",
    "\n",
    "    print(f\"     -> Avaliando modelo (CV - {skf.n_splits} folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in tqdm_notebook(enumerate(skf.split(X_cv, y_aparelho)), total=skf.n_splits):\n",
    "        \n",
    "        # Preparando lotes\n",
    "        X_treino_cv, X_teste_cv = X_cv.iloc[idx_treino], X_cv.iloc[idx_teste]\n",
    "        y_treino_cv, y_teste_cv = y_aparelho.iloc[idx_treino], y_aparelho.iloc[idx_teste]\n",
    "\n",
    "        # Treinando modelo\n",
    "        clf = clone(modelo)\n",
    "        \n",
    "        clf.fit(X_treino_cv, y_treino_cv)\n",
    "\n",
    "        # Prevendo conjunto de dados\n",
    "        y_hat = clf.predict(X_teste_cv)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste_cv, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste_cv, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste_cv, y_hat) if np.unique(y_teste_cv).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"cv\")\n",
    "\n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true_cv.extend(y_teste_cv)\n",
    "        y_pred_cv.extend(y_hat)\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true_cv, y_pred_cv))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true_cv, y_pred_cv))\n",
    "    print()\n",
    "    print(\"**********************************************\")\n",
    "    print()\n",
    "    \n",
    "# Consolidando DataFrame\n",
    "df_resultados = pd.DataFrame(resultados_modelo)\n",
    "\n",
    "arquivo_resultados = os.path.join(caminho_dados_notebook, f\"resultados_{dominio}_svm.xlsx\")\n",
    "if os.path.isfile(arquivo_resultados): os.remove(arquivo_resultados)\n",
    "df_resultados.to_excel(arquivo_resultados, index=False)\n",
    "    \n",
    "print(\"############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\")\n",
    "display(df_resultados.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T19:59:41.720698Z",
     "start_time": "2020-08-31T19:59:41.680673Z"
    }
   },
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T03:52:19.841404Z",
     "start_time": "2021-05-02T22:19:01.487888Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "\n",
      "* Aparelho `LC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92     12400\n",
      "           1       0.91      0.95      0.93     12800\n",
      "\n",
      "    accuracy                           0.93     25200\n",
      "   macro avg       0.93      0.93      0.93     25200\n",
      "weighted avg       0.93      0.93      0.93     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[11172  1228]\n",
      " [  624 12176]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28981664573e46e8977041296138975d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    1 31999]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LI`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68af4020edf34cc3b13cabc95d108821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MO`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79ffc028e7b4fbfabc9702b6bf1ea6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MT`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7e03018c0d438cbe8b4f722b12e67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `PC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a733f3b2a3364e6b82d19d329a97a6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LF`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc7098c4adf4a4898049ae09d9ad1b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    3 31997]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LC</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.926508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.926508</td>\n",
       "      <td>0.926508</td>\n",
       "      <td>0.926391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.926391</td>\n",
       "      <td>0.926391</td>\n",
       "      <td>0.926109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.926109</td>\n",
       "      <td>0.926109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LF</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LI</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MO</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MT</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PC</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             acc                                      f1  \\\n",
       "                            mean       std       max       min      mean   \n",
       "appliance base                                                             \n",
       "LC        cv            0.999984  0.000035  1.000000  0.999921  0.999984   \n",
       "          treino-teste  0.926508       NaN  0.926508  0.926508  0.926391   \n",
       "LF        cv            0.999952  0.000071  1.000000  0.999841  0.999952   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "LI        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "MO        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "MT        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "PC        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "\n",
       "                                                           auc            \\\n",
       "                             std       max       min      mean       std   \n",
       "appliance base                                                             \n",
       "LC        cv            0.000036  1.000000  0.999921  0.999984  0.000035   \n",
       "          treino-teste       NaN  0.926391  0.926391  0.926109       NaN   \n",
       "LF        cv            0.000071  1.000000  0.999841  0.999953  0.000070   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "LI        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "MO        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "MT        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "PC        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "\n",
       "                                            \n",
       "                             max       min  \n",
       "appliance base                              \n",
       "LC        cv            1.000000  0.999922  \n",
       "          treino-teste  0.926109  0.926109  \n",
       "LF        cv            1.000000  0.999844  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "LI        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "MO        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "MT        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "PC        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo = XGBClassifier(eval_metric='error', random_state=SEED, n_jobs=4)\n",
    "\n",
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \n",
    "    \"base\": []\n",
    "}\n",
    "\n",
    "for rotulo_aparelho in colunas_output:\n",
    "    \n",
    "    print(\"****************************************************************\\n\")\n",
    "    print(f\"* Aparelho `{rotulo_aparelho}`...\\n\")\n",
    "    \n",
    "    #######################################################################\n",
    "    #                AVALIACAO 1 - Base de treino/validacao               #\n",
    "    #######################################################################\n",
    "\n",
    "    # # Filtrando output/status por aparelho\n",
    "    y_treino_aparelho = y_treino[rotulo_aparelho]\n",
    "    y_validacao_aparelho = y_validacao[rotulo_aparelho]\n",
    "\n",
    "    print(f\"  - Avaliando modelo através da base treino/validacao...\")\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem (lote validacao):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_validacao_aparelho).items():\n",
    "        print(f\"       - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_validacao_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "\n",
    "    # Treinando modelo\n",
    "    print(f\"     -> Treinando modelo...\\n\")\n",
    "    clf = clone(modelo)\n",
    "    \n",
    "    clf.fit(X_treino, y_treino_aparelho)\n",
    "\n",
    "    # Prevendo conjunto de dados\n",
    "    y_hat = clf.predict(X_validacao)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "    resultados_modelo[\"fold\"].append(\"-\")\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_validacao_aparelho, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_validacao_aparelho, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_validacao_aparelho, y_hat) if np.unique(y_validacao_aparelho).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"treino-teste\")\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_validacao_aparelho, y_hat))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_validacao_aparelho, y_hat))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    #######################################################################\n",
    "    #                  AVALIACAO 2 - Validacao Cruzada                    #\n",
    "    #######################################################################\n",
    "    \n",
    "    y_true_cv, y_pred_cv  = [], []\n",
    "\n",
    "    print(f\"  - Avaliando através de validação cruzada ({skf.n_splits}-folds)...\")\n",
    "\n",
    "    # Filtrando output/status por aparelho\n",
    "    y_aparelho = y_cv[rotulo_aparelho]\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem:\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_aparelho).items():\n",
    "        print(f\"        - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "    \n",
    "\n",
    "    print(f\"     -> Avaliando modelo (CV - {skf.n_splits} folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in tqdm_notebook(enumerate(skf.split(X_cv, y_aparelho)), total=skf.n_splits):\n",
    "        \n",
    "        # Preparando lotes\n",
    "        X_treino_cv, X_teste_cv = X_cv.iloc[idx_treino], X_cv.iloc[idx_teste]\n",
    "        y_treino_cv, y_teste_cv = y_aparelho.iloc[idx_treino], y_aparelho.iloc[idx_teste]\n",
    "\n",
    "        # Treinando modelo\n",
    "        clf = clone(modelo)\n",
    "        \n",
    "        clf.fit(X_treino_cv, y_treino_cv)\n",
    "\n",
    "        # Prevendo conjunto de dados\n",
    "        y_hat = clf.predict(X_teste_cv)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste_cv, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste_cv, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste_cv, y_hat) if np.unique(y_teste_cv).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"cv\")\n",
    "\n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true_cv.extend(y_teste_cv)\n",
    "        y_pred_cv.extend(y_hat)\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true_cv, y_pred_cv))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true_cv, y_pred_cv))\n",
    "    print()\n",
    "    print(\"**********************************************\")\n",
    "    print()\n",
    "\n",
    "# Consolidando DataFrame\n",
    "df_resultados = pd.DataFrame(resultados_modelo)\n",
    "\n",
    "arquivo_resultados = os.path.join(caminho_dados_notebook, f\"resultados_{dominio}_xgboost.xlsx\")\n",
    "if os.path.isfile(arquivo_resultados): os.remove(arquivo_resultados)\n",
    "df_resultados.to_excel(arquivo_resultados, index=False)\n",
    "    \n",
    "print(\"############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\")\n",
    "display(df_resultados.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:10:29.051087Z",
     "start_time": "2021-05-03T03:52:22.146464Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "\n",
      "* Aparelho `LC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.29      0.41     12400\n",
      "           1       0.56      0.87      0.68     12800\n",
      "\n",
      "    accuracy                           0.58     25200\n",
      "   macro avg       0.62      0.58      0.54     25200\n",
      "weighted avg       0.62      0.58      0.55     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[ 3595  8805]\n",
      " [ 1686 11114]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9d5581d93447cab547cd871ff203f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.39      0.47     31000\n",
      "           1       0.55      0.72      0.63     32000\n",
      "\n",
      "    accuracy                           0.56     63000\n",
      "   macro avg       0.57      0.56      0.55     63000\n",
      "weighted avg       0.57      0.56      0.55     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12201 18799]\n",
      " [ 8870 23130]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LI`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     12400\n",
      "           1       1.00      0.98      0.99     12800\n",
      "\n",
      "    accuracy                           0.99     25200\n",
      "   macro avg       0.99      0.99      0.99     25200\n",
      "weighted avg       0.99      0.99      0.99     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [  209 12591]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed7450b215f4d20b06cd3c0029475ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     31000\n",
      "           1       0.99      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[30756   244]\n",
      " [   24 31976]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MO`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.73      0.78     12400\n",
      "           1       0.77      0.85      0.81     12800\n",
      "\n",
      "    accuracy                           0.79     25200\n",
      "   macro avg       0.80      0.79      0.79     25200\n",
      "weighted avg       0.80      0.79      0.79     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[ 9052  3348]\n",
      " [ 1859 10941]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da473b2fdbcb4ba9a71683855164c358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85     31000\n",
      "           1       0.87      0.84      0.85     32000\n",
      "\n",
      "    accuracy                           0.85     63000\n",
      "   macro avg       0.85      0.85      0.85     63000\n",
      "weighted avg       0.85      0.85      0.85     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[26835  4165]\n",
      " [ 5059 26941]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MT`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     12400\n",
      "           1       0.98      1.00      0.99     12800\n",
      "\n",
      "    accuracy                           0.99     25200\n",
      "   macro avg       0.99      0.99      0.99     25200\n",
      "weighted avg       0.99      0.99      0.99     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12153   247]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76d8384ab6241fa8e30e5807281c24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     31000\n",
      "           1       0.93      0.92      0.93     32000\n",
      "\n",
      "    accuracy                           0.92     63000\n",
      "   macro avg       0.92      0.92      0.92     63000\n",
      "weighted avg       0.92      0.92      0.92     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[28940  2060]\n",
      " [ 2691 29309]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `PC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.60      0.59     12400\n",
      "           1       0.60      0.58      0.59     12800\n",
      "\n",
      "    accuracy                           0.59     25200\n",
      "   macro avg       0.59      0.59      0.59     25200\n",
      "weighted avg       0.59      0.59      0.59     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[7484 4916]\n",
      " [5346 7454]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51246435bbef43a782620fe3f0c6a61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.73      0.69     31000\n",
      "           1       0.70      0.63      0.66     32000\n",
      "\n",
      "    accuracy                           0.68     63000\n",
      "   macro avg       0.68      0.68      0.68     63000\n",
      "weighted avg       0.68      0.68      0.68     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[22520  8480]\n",
      " [11876 20124]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LF`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.34      0.48     12400\n",
      "           1       0.59      0.90      0.71     12800\n",
      "\n",
      "    accuracy                           0.63     25200\n",
      "   macro avg       0.68      0.62      0.59     25200\n",
      "weighted avg       0.68      0.63      0.60     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[ 4261  8139]\n",
      " [ 1224 11576]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1d1fd7eead4639b30a531d13431010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.76      0.64     31000\n",
      "           1       0.63      0.40      0.49     32000\n",
      "\n",
      "    accuracy                           0.58     63000\n",
      "   macro avg       0.59      0.58      0.57     63000\n",
      "weighted avg       0.59      0.58      0.56     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[23488  7512]\n",
      " [19108 12892]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LC</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.560810</td>\n",
       "      <td>0.033714</td>\n",
       "      <td>0.598095</td>\n",
       "      <td>0.523968</td>\n",
       "      <td>0.510568</td>\n",
       "      <td>0.070343</td>\n",
       "      <td>0.577894</td>\n",
       "      <td>0.404872</td>\n",
       "      <td>0.558197</td>\n",
       "      <td>0.032549</td>\n",
       "      <td>0.593639</td>\n",
       "      <td>0.520696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.583690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583690</td>\n",
       "      <td>0.583690</td>\n",
       "      <td>0.543006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.543006</td>\n",
       "      <td>0.543006</td>\n",
       "      <td>0.579100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.579100</td>\n",
       "      <td>0.579100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LF</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.577460</td>\n",
       "      <td>0.044927</td>\n",
       "      <td>0.627063</td>\n",
       "      <td>0.522937</td>\n",
       "      <td>0.546938</td>\n",
       "      <td>0.069653</td>\n",
       "      <td>0.620484</td>\n",
       "      <td>0.456666</td>\n",
       "      <td>0.580276</td>\n",
       "      <td>0.042847</td>\n",
       "      <td>0.629312</td>\n",
       "      <td>0.526709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.628452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628452</td>\n",
       "      <td>0.628452</td>\n",
       "      <td>0.594265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594265</td>\n",
       "      <td>0.594265</td>\n",
       "      <td>0.624002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.624002</td>\n",
       "      <td>0.624002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LI</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.995746</td>\n",
       "      <td>0.009159</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979365</td>\n",
       "      <td>0.995741</td>\n",
       "      <td>0.009170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979342</td>\n",
       "      <td>0.995690</td>\n",
       "      <td>0.009288</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.991706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991706</td>\n",
       "      <td>0.991706</td>\n",
       "      <td>0.991706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991706</td>\n",
       "      <td>0.991706</td>\n",
       "      <td>0.991836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991836</td>\n",
       "      <td>0.991836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MO</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.853587</td>\n",
       "      <td>0.149201</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.677460</td>\n",
       "      <td>0.850070</td>\n",
       "      <td>0.153898</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.663345</td>\n",
       "      <td>0.853776</td>\n",
       "      <td>0.148457</td>\n",
       "      <td>0.999839</td>\n",
       "      <td>0.680882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.793373</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.793373</td>\n",
       "      <td>0.793373</td>\n",
       "      <td>0.792205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.792205</td>\n",
       "      <td>0.792205</td>\n",
       "      <td>0.792383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.792383</td>\n",
       "      <td>0.792383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MT</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.924587</td>\n",
       "      <td>0.025218</td>\n",
       "      <td>0.940952</td>\n",
       "      <td>0.880873</td>\n",
       "      <td>0.924357</td>\n",
       "      <td>0.025505</td>\n",
       "      <td>0.940884</td>\n",
       "      <td>0.880152</td>\n",
       "      <td>0.924727</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>0.940650</td>\n",
       "      <td>0.879864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.990198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990198</td>\n",
       "      <td>0.990198</td>\n",
       "      <td>0.990192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990192</td>\n",
       "      <td>0.990192</td>\n",
       "      <td>0.990040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990040</td>\n",
       "      <td>0.990040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PC</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.676889</td>\n",
       "      <td>0.061685</td>\n",
       "      <td>0.750952</td>\n",
       "      <td>0.594921</td>\n",
       "      <td>0.671754</td>\n",
       "      <td>0.058942</td>\n",
       "      <td>0.747684</td>\n",
       "      <td>0.594903</td>\n",
       "      <td>0.677663</td>\n",
       "      <td>0.061987</td>\n",
       "      <td>0.749335</td>\n",
       "      <td>0.594965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.592778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592778</td>\n",
       "      <td>0.592778</td>\n",
       "      <td>0.592777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592777</td>\n",
       "      <td>0.592777</td>\n",
       "      <td>0.592946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592946</td>\n",
       "      <td>0.592946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             acc                                      f1  \\\n",
       "                            mean       std       max       min      mean   \n",
       "appliance base                                                             \n",
       "LC        cv            0.560810  0.033714  0.598095  0.523968  0.510568   \n",
       "          treino-teste  0.583690       NaN  0.583690  0.583690  0.543006   \n",
       "LF        cv            0.577460  0.044927  0.627063  0.522937  0.546938   \n",
       "          treino-teste  0.628452       NaN  0.628452  0.628452  0.594265   \n",
       "LI        cv            0.995746  0.009159  1.000000  0.979365  0.995741   \n",
       "          treino-teste  0.991706       NaN  0.991706  0.991706  0.991706   \n",
       "MO        cv            0.853587  0.149201  0.999841  0.677460  0.850070   \n",
       "          treino-teste  0.793373       NaN  0.793373  0.793373  0.792205   \n",
       "MT        cv            0.924587  0.025218  0.940952  0.880873  0.924357   \n",
       "          treino-teste  0.990198       NaN  0.990198  0.990198  0.990192   \n",
       "PC        cv            0.676889  0.061685  0.750952  0.594921  0.671754   \n",
       "          treino-teste  0.592778       NaN  0.592778  0.592778  0.592777   \n",
       "\n",
       "                                                           auc            \\\n",
       "                             std       max       min      mean       std   \n",
       "appliance base                                                             \n",
       "LC        cv            0.070343  0.577894  0.404872  0.558197  0.032549   \n",
       "          treino-teste       NaN  0.543006  0.543006  0.579100       NaN   \n",
       "LF        cv            0.069653  0.620484  0.456666  0.580276  0.042847   \n",
       "          treino-teste       NaN  0.594265  0.594265  0.624002       NaN   \n",
       "LI        cv            0.009170  1.000000  0.979342  0.995690  0.009288   \n",
       "          treino-teste       NaN  0.991706  0.991706  0.991836       NaN   \n",
       "MO        cv            0.153898  0.999841  0.663345  0.853776  0.148457   \n",
       "          treino-teste       NaN  0.792205  0.792205  0.792383       NaN   \n",
       "MT        cv            0.025505  0.940884  0.880152  0.924727  0.025732   \n",
       "          treino-teste       NaN  0.990192  0.990192  0.990040       NaN   \n",
       "PC        cv            0.058942  0.747684  0.594903  0.677663  0.061987   \n",
       "          treino-teste       NaN  0.592777  0.592777  0.592946       NaN   \n",
       "\n",
       "                                            \n",
       "                             max       min  \n",
       "appliance base                              \n",
       "LC        cv            0.593639  0.520696  \n",
       "          treino-teste  0.579100  0.579100  \n",
       "LF        cv            0.629312  0.526709  \n",
       "          treino-teste  0.624002  0.624002  \n",
       "LI        cv            1.000000  0.979078  \n",
       "          treino-teste  0.991836  0.991836  \n",
       "MO        cv            0.999839  0.680882  \n",
       "          treino-teste  0.792383  0.792383  \n",
       "MT        cv            0.940650  0.879864  \n",
       "          treino-teste  0.990040  0.990040  \n",
       "PC        cv            0.749335  0.594965  \n",
       "          treino-teste  0.592946  0.592946  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo = MLPClassifier(alpha=1e-3, hidden_layer_sizes=(10,), random_state=SEED)\n",
    "\n",
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \n",
    "    \"base\": []\n",
    "}\n",
    "\n",
    "for rotulo_aparelho in colunas_output:\n",
    "    \n",
    "    print(\"****************************************************************\\n\")\n",
    "    print(f\"* Aparelho `{rotulo_aparelho}`...\\n\")\n",
    "    \n",
    "    #######################################################################\n",
    "    #                AVALIACAO 1 - Base de treino/validacao               #\n",
    "    #######################################################################\n",
    "\n",
    "    # # Filtrando output/status por aparelho\n",
    "    y_treino_aparelho = y_treino[rotulo_aparelho]\n",
    "    y_validacao_aparelho = y_validacao[rotulo_aparelho]\n",
    "\n",
    "    print(f\"  - Avaliando modelo através da base treino/validacao...\")\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem (lote validacao):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_validacao_aparelho).items():\n",
    "        print(f\"       - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_validacao_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "\n",
    "    # Treinando modelo\n",
    "    print(f\"     -> Treinando modelo...\\n\")\n",
    "    clf = clone(modelo)\n",
    "    \n",
    "    clf.fit(X_treino, y_treino_aparelho)\n",
    "\n",
    "    # Prevendo conjunto de dados\n",
    "    y_hat = clf.predict(X_validacao)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "    resultados_modelo[\"fold\"].append(\"-\")\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_validacao_aparelho, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_validacao_aparelho, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_validacao_aparelho, y_hat) if np.unique(y_validacao_aparelho).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"treino-teste\")\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_validacao_aparelho, y_hat))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_validacao_aparelho, y_hat))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    #######################################################################\n",
    "    #                  AVALIACAO 2 - Validacao Cruzada                    #\n",
    "    #######################################################################\n",
    "    \n",
    "    y_true_cv, y_pred_cv  = [], []\n",
    "\n",
    "    print(f\"  - Avaliando através de validação cruzada ({skf.n_splits}-folds)...\")\n",
    "\n",
    "    # Filtrando output/status por aparelho\n",
    "    y_aparelho = y_cv[rotulo_aparelho]\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem:\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_aparelho).items():\n",
    "        print(f\"        - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "    \n",
    "\n",
    "    print(f\"     -> Avaliando modelo (CV - {skf.n_splits} folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in tqdm_notebook(enumerate(skf.split(X_cv, y_aparelho)), total=skf.n_splits):\n",
    "        \n",
    "        # Preparando lotes\n",
    "        X_treino_cv, X_teste_cv = X_cv.iloc[idx_treino], X_cv.iloc[idx_teste]\n",
    "        y_treino_cv, y_teste_cv = y_aparelho.iloc[idx_treino], y_aparelho.iloc[idx_teste]\n",
    "\n",
    "        # Treinando modelo\n",
    "        clf = clone(modelo)\n",
    "        \n",
    "        clf.fit(X_treino_cv, y_treino_cv)\n",
    "\n",
    "        # Prevendo conjunto de dados\n",
    "        y_hat = clf.predict(X_teste_cv)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste_cv, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste_cv, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste_cv, y_hat) if np.unique(y_teste_cv).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"cv\")\n",
    "\n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true_cv.extend(y_teste_cv)\n",
    "        y_pred_cv.extend(y_hat)\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true_cv, y_pred_cv))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true_cv, y_pred_cv))\n",
    "    print()\n",
    "    print(\"**********************************************\")\n",
    "    print()\n",
    "\n",
    "# Consolidando DataFrame\n",
    "df_resultados = pd.DataFrame(resultados_modelo)\n",
    "\n",
    "arquivo_resultados = os.path.join(caminho_dados_notebook, f\"resultados_{dominio}_mlp.xlsx\")\n",
    "if os.path.isfile(arquivo_resultados): os.remove(arquivo_resultados)\n",
    "df_resultados.to_excel(arquivo_resultados, index=False)\n",
    "    \n",
    "print(\"############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\")\n",
    "display(df_resultados.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise dos Resultados (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:10:32.077065Z",
     "start_time": "2021-05-03T09:10:31.295643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Análise por modelo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBOOST</th>\n",
       "      <td>cv</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBOOST</th>\n",
       "      <td>treino-teste</td>\n",
       "      <td>0.987751</td>\n",
       "      <td>0.030003</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926508</td>\n",
       "      <td>0.987732</td>\n",
       "      <td>0.030051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926391</td>\n",
       "      <td>0.987685</td>\n",
       "      <td>0.030166</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>treino-teste</td>\n",
       "      <td>0.763366</td>\n",
       "      <td>0.191874</td>\n",
       "      <td>0.991706</td>\n",
       "      <td>0.583690</td>\n",
       "      <td>0.750692</td>\n",
       "      <td>0.204798</td>\n",
       "      <td>0.991706</td>\n",
       "      <td>0.543006</td>\n",
       "      <td>0.761718</td>\n",
       "      <td>0.193300</td>\n",
       "      <td>0.991836</td>\n",
       "      <td>0.579100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>cv</td>\n",
       "      <td>0.764847</td>\n",
       "      <td>0.183426</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.522937</td>\n",
       "      <td>0.749905</td>\n",
       "      <td>0.201564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.404872</td>\n",
       "      <td>0.765055</td>\n",
       "      <td>0.183242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.520696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>cv</td>\n",
       "      <td>0.753138</td>\n",
       "      <td>0.132858</td>\n",
       "      <td>0.938968</td>\n",
       "      <td>0.578810</td>\n",
       "      <td>0.745209</td>\n",
       "      <td>0.138723</td>\n",
       "      <td>0.938846</td>\n",
       "      <td>0.577654</td>\n",
       "      <td>0.752646</td>\n",
       "      <td>0.132990</td>\n",
       "      <td>0.938495</td>\n",
       "      <td>0.579786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>treino-teste</td>\n",
       "      <td>0.746852</td>\n",
       "      <td>0.139394</td>\n",
       "      <td>0.929246</td>\n",
       "      <td>0.584881</td>\n",
       "      <td>0.739532</td>\n",
       "      <td>0.145209</td>\n",
       "      <td>0.929131</td>\n",
       "      <td>0.583839</td>\n",
       "      <td>0.746315</td>\n",
       "      <td>0.139455</td>\n",
       "      <td>0.928839</td>\n",
       "      <td>0.585823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 base       acc                                      f1  \\\n",
       "                           mean       std       max       min      mean   \n",
       "model                                                                     \n",
       "XGBOOST            cv  0.999989  0.000034  1.000000  0.999841  0.999989   \n",
       "XGBOOST  treino-teste  0.987751  0.030003  1.000000  0.926508  0.987732   \n",
       "MLP      treino-teste  0.763366  0.191874  0.991706  0.583690  0.750692   \n",
       "MLP                cv  0.764847  0.183426  1.000000  0.522937  0.749905   \n",
       "SVM                cv  0.753138  0.132858  0.938968  0.578810  0.745209   \n",
       "SVM      treino-teste  0.746852  0.139394  0.929246  0.584881  0.739532   \n",
       "\n",
       "                                            auc                                \n",
       "              std       max       min      mean       std       max       min  \n",
       "model                                                                          \n",
       "XGBOOST  0.000034  1.000000  0.999841  0.999990  0.000034  1.000000  0.999844  \n",
       "XGBOOST  0.030051  1.000000  0.926391  0.987685  0.030166  1.000000  0.926109  \n",
       "MLP      0.204798  0.991706  0.543006  0.761718  0.193300  0.991836  0.579100  \n",
       "MLP      0.201564  1.000000  0.404872  0.765055  0.183242  1.000000  0.520696  \n",
       "SVM      0.138723  0.938846  0.577654  0.752646  0.132990  0.938495  0.579786  \n",
       "SVM      0.145209  0.929131  0.583839  0.746315  0.139455  0.928839  0.585823  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Análise por aparelho/modelo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>model</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">LC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.560810</td>\n",
       "      <td>0.033714</td>\n",
       "      <td>0.598095</td>\n",
       "      <td>0.523968</td>\n",
       "      <td>0.510568</td>\n",
       "      <td>0.070343</td>\n",
       "      <td>0.577894</td>\n",
       "      <td>0.404872</td>\n",
       "      <td>0.558197</td>\n",
       "      <td>0.032549</td>\n",
       "      <td>0.593639</td>\n",
       "      <td>0.520696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.583690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583690</td>\n",
       "      <td>0.583690</td>\n",
       "      <td>0.543006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.543006</td>\n",
       "      <td>0.543006</td>\n",
       "      <td>0.579100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.579100</td>\n",
       "      <td>0.579100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.587651</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>0.591032</td>\n",
       "      <td>0.578810</td>\n",
       "      <td>0.586566</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.590842</td>\n",
       "      <td>0.577654</td>\n",
       "      <td>0.588558</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>0.591588</td>\n",
       "      <td>0.579786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.584881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.584881</td>\n",
       "      <td>0.584881</td>\n",
       "      <td>0.583839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583839</td>\n",
       "      <td>0.583839</td>\n",
       "      <td>0.585823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585823</td>\n",
       "      <td>0.585823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.926508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.926508</td>\n",
       "      <td>0.926508</td>\n",
       "      <td>0.926391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.926391</td>\n",
       "      <td>0.926391</td>\n",
       "      <td>0.926109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.926109</td>\n",
       "      <td>0.926109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">LF</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.577460</td>\n",
       "      <td>0.044927</td>\n",
       "      <td>0.627063</td>\n",
       "      <td>0.522937</td>\n",
       "      <td>0.546938</td>\n",
       "      <td>0.069653</td>\n",
       "      <td>0.620484</td>\n",
       "      <td>0.456666</td>\n",
       "      <td>0.580276</td>\n",
       "      <td>0.042847</td>\n",
       "      <td>0.629312</td>\n",
       "      <td>0.526709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.628452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628452</td>\n",
       "      <td>0.628452</td>\n",
       "      <td>0.594265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594265</td>\n",
       "      <td>0.594265</td>\n",
       "      <td>0.624002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.624002</td>\n",
       "      <td>0.624002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.619873</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>0.635952</td>\n",
       "      <td>0.612619</td>\n",
       "      <td>0.591407</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0.605570</td>\n",
       "      <td>0.584772</td>\n",
       "      <td>0.615838</td>\n",
       "      <td>0.009428</td>\n",
       "      <td>0.631706</td>\n",
       "      <td>0.608662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.632262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632262</td>\n",
       "      <td>0.632262</td>\n",
       "      <td>0.603938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.603938</td>\n",
       "      <td>0.603938</td>\n",
       "      <td>0.628175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628175</td>\n",
       "      <td>0.628175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">LI</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.995746</td>\n",
       "      <td>0.009159</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979365</td>\n",
       "      <td>0.995741</td>\n",
       "      <td>0.009170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979342</td>\n",
       "      <td>0.995690</td>\n",
       "      <td>0.009288</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.991706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991706</td>\n",
       "      <td>0.991706</td>\n",
       "      <td>0.991706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991706</td>\n",
       "      <td>0.991706</td>\n",
       "      <td>0.991836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991836</td>\n",
       "      <td>0.991836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.936460</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.938968</td>\n",
       "      <td>0.933413</td>\n",
       "      <td>0.936315</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.938846</td>\n",
       "      <td>0.933253</td>\n",
       "      <td>0.935940</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.938495</td>\n",
       "      <td>0.932870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.929246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.929246</td>\n",
       "      <td>0.929246</td>\n",
       "      <td>0.929131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.929131</td>\n",
       "      <td>0.929131</td>\n",
       "      <td>0.928839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.928839</td>\n",
       "      <td>0.928839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MO</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.853587</td>\n",
       "      <td>0.149201</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.677460</td>\n",
       "      <td>0.850070</td>\n",
       "      <td>0.153898</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.663345</td>\n",
       "      <td>0.853776</td>\n",
       "      <td>0.148457</td>\n",
       "      <td>0.999839</td>\n",
       "      <td>0.680882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.793373</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.793373</td>\n",
       "      <td>0.793373</td>\n",
       "      <td>0.792205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.792205</td>\n",
       "      <td>0.792205</td>\n",
       "      <td>0.792383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.792383</td>\n",
       "      <td>0.792383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.774333</td>\n",
       "      <td>0.011955</td>\n",
       "      <td>0.789206</td>\n",
       "      <td>0.761508</td>\n",
       "      <td>0.767521</td>\n",
       "      <td>0.011214</td>\n",
       "      <td>0.781202</td>\n",
       "      <td>0.755426</td>\n",
       "      <td>0.771809</td>\n",
       "      <td>0.011745</td>\n",
       "      <td>0.786368</td>\n",
       "      <td>0.759196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.749802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.749802</td>\n",
       "      <td>0.749802</td>\n",
       "      <td>0.744304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.744304</td>\n",
       "      <td>0.744304</td>\n",
       "      <td>0.747663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.747663</td>\n",
       "      <td>0.747663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MT</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.924587</td>\n",
       "      <td>0.025218</td>\n",
       "      <td>0.940952</td>\n",
       "      <td>0.880873</td>\n",
       "      <td>0.924357</td>\n",
       "      <td>0.025505</td>\n",
       "      <td>0.940884</td>\n",
       "      <td>0.880152</td>\n",
       "      <td>0.924727</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>0.940650</td>\n",
       "      <td>0.879864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.990198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990198</td>\n",
       "      <td>0.990198</td>\n",
       "      <td>0.990192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990192</td>\n",
       "      <td>0.990192</td>\n",
       "      <td>0.990040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990040</td>\n",
       "      <td>0.990040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.896190</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.902063</td>\n",
       "      <td>0.890794</td>\n",
       "      <td>0.896163</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.902057</td>\n",
       "      <td>0.890793</td>\n",
       "      <td>0.896224</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>0.902165</td>\n",
       "      <td>0.891053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.893333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.893194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.893194</td>\n",
       "      <td>0.893194</td>\n",
       "      <td>0.892985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.892985</td>\n",
       "      <td>0.892985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">PC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.676889</td>\n",
       "      <td>0.061685</td>\n",
       "      <td>0.750952</td>\n",
       "      <td>0.594921</td>\n",
       "      <td>0.671754</td>\n",
       "      <td>0.058942</td>\n",
       "      <td>0.747684</td>\n",
       "      <td>0.594903</td>\n",
       "      <td>0.677663</td>\n",
       "      <td>0.061987</td>\n",
       "      <td>0.749335</td>\n",
       "      <td>0.594965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.592778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592778</td>\n",
       "      <td>0.592778</td>\n",
       "      <td>0.592777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592777</td>\n",
       "      <td>0.592777</td>\n",
       "      <td>0.592946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592946</td>\n",
       "      <td>0.592946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.704317</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>0.715714</td>\n",
       "      <td>0.686349</td>\n",
       "      <td>0.693284</td>\n",
       "      <td>0.010469</td>\n",
       "      <td>0.704844</td>\n",
       "      <td>0.676431</td>\n",
       "      <td>0.707507</td>\n",
       "      <td>0.011110</td>\n",
       "      <td>0.718942</td>\n",
       "      <td>0.689302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.691587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.691587</td>\n",
       "      <td>0.691587</td>\n",
       "      <td>0.682784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.682784</td>\n",
       "      <td>0.682784</td>\n",
       "      <td>0.694407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.694407</td>\n",
       "      <td>0.694407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     acc                                \\\n",
       "                                    mean       std       max       min   \n",
       "appliance model   base                                                   \n",
       "LC        MLP     cv            0.560810  0.033714  0.598095  0.523968   \n",
       "                  treino-teste  0.583690       NaN  0.583690  0.583690   \n",
       "          SVM     cv            0.587651  0.005133  0.591032  0.578810   \n",
       "                  treino-teste  0.584881       NaN  0.584881  0.584881   \n",
       "          XGBOOST cv            0.999984  0.000035  1.000000  0.999921   \n",
       "                  treino-teste  0.926508       NaN  0.926508  0.926508   \n",
       "LF        MLP     cv            0.577460  0.044927  0.627063  0.522937   \n",
       "                  treino-teste  0.628452       NaN  0.628452  0.628452   \n",
       "          SVM     cv            0.619873  0.009559  0.635952  0.612619   \n",
       "                  treino-teste  0.632262       NaN  0.632262  0.632262   \n",
       "          XGBOOST cv            0.999952  0.000071  1.000000  0.999841   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "LI        MLP     cv            0.995746  0.009159  1.000000  0.979365   \n",
       "                  treino-teste  0.991706       NaN  0.991706  0.991706   \n",
       "          SVM     cv            0.936460  0.002049  0.938968  0.933413   \n",
       "                  treino-teste  0.929246       NaN  0.929246  0.929246   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "MO        MLP     cv            0.853587  0.149201  0.999841  0.677460   \n",
       "                  treino-teste  0.793373       NaN  0.793373  0.793373   \n",
       "          SVM     cv            0.774333  0.011955  0.789206  0.761508   \n",
       "                  treino-teste  0.749802       NaN  0.749802  0.749802   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "MT        MLP     cv            0.924587  0.025218  0.940952  0.880873   \n",
       "                  treino-teste  0.990198       NaN  0.990198  0.990198   \n",
       "          SVM     cv            0.896190  0.004926  0.902063  0.890794   \n",
       "                  treino-teste  0.893333       NaN  0.893333  0.893333   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "PC        MLP     cv            0.676889  0.061685  0.750952  0.594921   \n",
       "                  treino-teste  0.592778       NaN  0.592778  0.592778   \n",
       "          SVM     cv            0.704317  0.010984  0.715714  0.686349   \n",
       "                  treino-teste  0.691587       NaN  0.691587  0.691587   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "\n",
       "                                      f1                                \\\n",
       "                                    mean       std       max       min   \n",
       "appliance model   base                                                   \n",
       "LC        MLP     cv            0.510568  0.070343  0.577894  0.404872   \n",
       "                  treino-teste  0.543006       NaN  0.543006  0.543006   \n",
       "          SVM     cv            0.586566  0.005277  0.590842  0.577654   \n",
       "                  treino-teste  0.583839       NaN  0.583839  0.583839   \n",
       "          XGBOOST cv            0.999984  0.000036  1.000000  0.999921   \n",
       "                  treino-teste  0.926391       NaN  0.926391  0.926391   \n",
       "LF        MLP     cv            0.546938  0.069653  0.620484  0.456666   \n",
       "                  treino-teste  0.594265       NaN  0.594265  0.594265   \n",
       "          SVM     cv            0.591407  0.008368  0.605570  0.584772   \n",
       "                  treino-teste  0.603938       NaN  0.603938  0.603938   \n",
       "          XGBOOST cv            0.999952  0.000071  1.000000  0.999841   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "LI        MLP     cv            0.995741  0.009170  1.000000  0.979342   \n",
       "                  treino-teste  0.991706       NaN  0.991706  0.991706   \n",
       "          SVM     cv            0.936315  0.002063  0.938846  0.933253   \n",
       "                  treino-teste  0.929131       NaN  0.929131  0.929131   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "MO        MLP     cv            0.850070  0.153898  0.999841  0.663345   \n",
       "                  treino-teste  0.792205       NaN  0.792205  0.792205   \n",
       "          SVM     cv            0.767521  0.011214  0.781202  0.755426   \n",
       "                  treino-teste  0.744304       NaN  0.744304  0.744304   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "MT        MLP     cv            0.924357  0.025505  0.940884  0.880152   \n",
       "                  treino-teste  0.990192       NaN  0.990192  0.990192   \n",
       "          SVM     cv            0.896163  0.004940  0.902057  0.890793   \n",
       "                  treino-teste  0.893194       NaN  0.893194  0.893194   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "PC        MLP     cv            0.671754  0.058942  0.747684  0.594903   \n",
       "                  treino-teste  0.592777       NaN  0.592777  0.592777   \n",
       "          SVM     cv            0.693284  0.010469  0.704844  0.676431   \n",
       "                  treino-teste  0.682784       NaN  0.682784  0.682784   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "\n",
       "                                     auc                                \n",
       "                                    mean       std       max       min  \n",
       "appliance model   base                                                  \n",
       "LC        MLP     cv            0.558197  0.032549  0.593639  0.520696  \n",
       "                  treino-teste  0.579100       NaN  0.579100  0.579100  \n",
       "          SVM     cv            0.588558  0.005083  0.591588  0.579786  \n",
       "                  treino-teste  0.585823       NaN  0.585823  0.585823  \n",
       "          XGBOOST cv            0.999984  0.000035  1.000000  0.999922  \n",
       "                  treino-teste  0.926109       NaN  0.926109  0.926109  \n",
       "LF        MLP     cv            0.580276  0.042847  0.629312  0.526709  \n",
       "                  treino-teste  0.624002       NaN  0.624002  0.624002  \n",
       "          SVM     cv            0.615838  0.009428  0.631706  0.608662  \n",
       "                  treino-teste  0.628175       NaN  0.628175  0.628175  \n",
       "          XGBOOST cv            0.999953  0.000070  1.000000  0.999844  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "LI        MLP     cv            0.995690  0.009288  1.000000  0.979078  \n",
       "                  treino-teste  0.991836       NaN  0.991836  0.991836  \n",
       "          SVM     cv            0.935940  0.002073  0.938495  0.932870  \n",
       "                  treino-teste  0.928839       NaN  0.928839  0.928839  \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "MO        MLP     cv            0.853776  0.148457  0.999839  0.680882  \n",
       "                  treino-teste  0.792383       NaN  0.792383  0.792383  \n",
       "          SVM     cv            0.771809  0.011745  0.786368  0.759196  \n",
       "                  treino-teste  0.747663       NaN  0.747663  0.747663  \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "MT        MLP     cv            0.924727  0.025732  0.940650  0.879864  \n",
       "                  treino-teste  0.990040       NaN  0.990040  0.990040  \n",
       "          SVM     cv            0.896224  0.004938  0.902165  0.891053  \n",
       "                  treino-teste  0.892985       NaN  0.892985  0.892985  \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "PC        MLP     cv            0.677663  0.061987  0.749335  0.594965  \n",
       "                  treino-teste  0.592946       NaN  0.592946  0.592946  \n",
       "          SVM     cv            0.707507  0.011110  0.718942  0.689302  \n",
       "                  treino-teste  0.694407       NaN  0.694407  0.694407  \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_resultados_svm = pd.read_excel(os.path.join(caminho_dados_notebook, f\"resultados_{dominio}_svm.xlsx\"), engine='openpyxl')\n",
    "df_resultados_svm[\"model\"] = \"SVM\"\n",
    "\n",
    "df_resultados_xgboost = pd.read_excel(os.path.join(caminho_dados_notebook, f\"resultados_{dominio}_xgboost.xlsx\"), engine='openpyxl')\n",
    "df_resultados_xgboost[\"model\"] = \"XGBOOST\"\n",
    "\n",
    "df_resultados_mlp = pd.read_excel(os.path.join(caminho_dados_notebook, f\"resultados_{dominio}_mlp.xlsx\"), engine='openpyxl')\n",
    "df_resultados_mlp[\"model\"] = \"MLP\"\n",
    "\n",
    "# df_resultados_elm = pd.read_excel(os.path.join(caminho_dados_notebook, \"df_resultados_elm.xlsx\"))\n",
    "# df_resultados_elm[\"model\"] = \"ELM\"\n",
    "\n",
    "df_analise = pd.concat([\n",
    "    df_resultados_svm,\n",
    "    df_resultados_xgboost,\n",
    "    df_resultados_mlp, \n",
    "#     df_resultados_elm,  \n",
    "])\n",
    "\n",
    "print(\"* Análise por modelo:\")\n",
    "df_analise_modelo = df_analise.groupby([\"model\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"f1\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"auc\": [\"mean\",\"std\",\"max\",\"min\"]\n",
    "}).reset_index().sort_values(('f1','mean'), ascending=False).set_index(\"model\")\n",
    "display(df_analise_modelo)\n",
    "df_analise_modelo.to_excel(os.path.join(caminho_dados_notebook, f\"analise_{dominio}_modelos.xlsx\"))\n",
    "\n",
    "print()\n",
    "print(\"* Análise por aparelho/modelo:\")\n",
    "df_analise_aparelho = df_analise.groupby([\"appliance\",\"model\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"f1\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"auc\": [\"mean\",\"std\",\"max\",\"min\"]\n",
    "})#.reset_index().sort_values(('f1','mean'), ascending=False).set_index([\"aparelho\",\"metodologia\"])\n",
    "display(df_analise_aparelho)\n",
    "df_analise_aparelho.to_excel(os.path.join(caminho_dados_notebook, f\"analise_{dominio}_aparelhos.xls\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atributos Domínio da Frequência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dominio = 'frequencia'\n",
    "\n",
    "X_treino = X_treino_frequencia\n",
    "X_validacao = X_validacao_frequencia\n",
    "\n",
    "# Dados agregados (validacao cruzada)\n",
    "X_cv = pd.concat([X_treino, X_validacao]).reset_index(drop=True) \n",
    "y_cv = pd.concat([y_treino, y_validacao]).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-02T22:18:59.268806Z",
     "start_time": "2021-05-02T17:03:12.352604Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "\n",
      "* Aparelho `LC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78881c740431403a94ce9455dffa9f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LI`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd7e025520f4575b5ec278e31cbbc42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MO`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3741d08a1b146e0b35325b14618e81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MT`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381a4b7aca7c4844ac18173fe29dd6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `PC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88     12400\n",
      "           1       0.93      0.81      0.86     12800\n",
      "\n",
      "    accuracy                           0.87     25200\n",
      "   macro avg       0.88      0.87      0.87     25200\n",
      "weighted avg       0.88      0.87      0.87     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[11600   800]\n",
      " [ 2443 10357]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543a9688087d4a97ba9980a5b3a5ebde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93     31000\n",
      "           1       0.98      0.88      0.93     32000\n",
      "\n",
      "    accuracy                           0.93     63000\n",
      "   macro avg       0.93      0.93      0.93     63000\n",
      "weighted avg       0.93      0.93      0.93     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[30291   709]\n",
      " [ 3786 28214]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LF`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74     12400\n",
      "           1       0.75      0.75      0.75     12800\n",
      "\n",
      "    accuracy                           0.75     25200\n",
      "   macro avg       0.75      0.75      0.75     25200\n",
      "weighted avg       0.75      0.75      0.75     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[9200 3200]\n",
      " [3200 9600]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7735b7c77ca84330af72fe90ceae9ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73     31000\n",
      "           1       0.74      0.76      0.75     32000\n",
      "\n",
      "    accuracy                           0.74     63000\n",
      "   macro avg       0.74      0.74      0.74     63000\n",
      "weighted avg       0.74      0.74      0.74     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[22299  8701]\n",
      " [ 7634 24366]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LC</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LF</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.740714</td>\n",
       "      <td>0.00331</td>\n",
       "      <td>0.744127</td>\n",
       "      <td>0.736190</td>\n",
       "      <td>0.740423</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>0.743966</td>\n",
       "      <td>0.735730</td>\n",
       "      <td>0.740380</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.743916</td>\n",
       "      <td>0.735713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.746032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>0.745968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LI</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MO</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MT</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PC</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.928651</td>\n",
       "      <td>0.00595</td>\n",
       "      <td>0.935397</td>\n",
       "      <td>0.923413</td>\n",
       "      <td>0.928570</td>\n",
       "      <td>0.005976</td>\n",
       "      <td>0.935340</td>\n",
       "      <td>0.923316</td>\n",
       "      <td>0.929408</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.936104</td>\n",
       "      <td>0.924209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.871310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.871310</td>\n",
       "      <td>0.871310</td>\n",
       "      <td>0.870996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.870996</td>\n",
       "      <td>0.870996</td>\n",
       "      <td>0.872312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.872312</td>\n",
       "      <td>0.872312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             acc                                     f1  \\\n",
       "                            mean      std       max       min      mean   \n",
       "appliance base                                                            \n",
       "LC        cv            1.000000  0.00000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000      NaN  1.000000  1.000000  1.000000   \n",
       "LF        cv            0.740714  0.00331  0.744127  0.736190  0.740423   \n",
       "          treino-teste  0.746032      NaN  0.746032  0.746032  0.745968   \n",
       "LI        cv            1.000000  0.00000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000      NaN  1.000000  1.000000  1.000000   \n",
       "MO        cv            1.000000  0.00000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000      NaN  1.000000  1.000000  1.000000   \n",
       "MT        cv            1.000000  0.00000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000      NaN  1.000000  1.000000  1.000000   \n",
       "PC        cv            0.928651  0.00595  0.935397  0.923413  0.928570   \n",
       "          treino-teste  0.871310      NaN  0.871310  0.871310  0.870996   \n",
       "\n",
       "                                                           auc            \\\n",
       "                             std       max       min      mean       std   \n",
       "appliance base                                                             \n",
       "LC        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "LF        cv            0.003435  0.743966  0.735730  0.740380  0.003423   \n",
       "          treino-teste       NaN  0.745968  0.745968  0.745968       NaN   \n",
       "LI        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "MO        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "MT        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "PC        cv            0.005976  0.935340  0.923316  0.929408  0.005882   \n",
       "          treino-teste       NaN  0.870996  0.870996  0.872312       NaN   \n",
       "\n",
       "                                            \n",
       "                             max       min  \n",
       "appliance base                              \n",
       "LC        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "LF        cv            0.743916  0.735713  \n",
       "          treino-teste  0.745968  0.745968  \n",
       "LI        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "MO        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "MT        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "PC        cv            0.936104  0.924209  \n",
       "          treino-teste  0.872312  0.872312  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo = SVC(kernel='rbf', random_state=SEED)\n",
    "\n",
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \n",
    "    \"base\": []\n",
    "}\n",
    "\n",
    "for rotulo_aparelho in colunas_output:\n",
    "    \n",
    "    print(\"****************************************************************\\n\")\n",
    "    print(f\"* Aparelho `{rotulo_aparelho}`...\\n\")\n",
    "    \n",
    "    #######################################################################\n",
    "    #                AVALIACAO 1 - Base de treino/validacao               #\n",
    "    #######################################################################\n",
    "\n",
    "    # # Filtrando output/status por aparelho\n",
    "    y_treino_aparelho = y_treino[rotulo_aparelho]\n",
    "    y_validacao_aparelho = y_validacao[rotulo_aparelho]\n",
    "\n",
    "    print(f\"  - Avaliando modelo através da base treino/validacao...\")\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem (lote validacao):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_validacao_aparelho).items():\n",
    "        print(f\"       - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_validacao_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "\n",
    "    # Treinando modelo\n",
    "    print(f\"     -> Treinando modelo...\\n\")\n",
    "    clf = clone(modelo)\n",
    "    \n",
    "    clf.fit(X_treino, y_treino_aparelho)\n",
    "\n",
    "    # Prevendo conjunto de dados\n",
    "    y_hat = clf.predict(X_validacao)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "    resultados_modelo[\"fold\"].append(\"-\")\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_validacao_aparelho, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_validacao_aparelho, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_validacao_aparelho, y_hat) if np.unique(y_validacao_aparelho).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"treino-teste\")\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_validacao_aparelho, y_hat))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_validacao_aparelho, y_hat))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    #######################################################################\n",
    "    #                  AVALIACAO 2 - Validacao Cruzada                    #\n",
    "    #######################################################################\n",
    "    \n",
    "    y_true_cv, y_pred_cv  = [], []\n",
    "\n",
    "    print(f\"  - Avaliando através de validação cruzada ({skf.n_splits}-folds)...\")\n",
    "\n",
    "    # Filtrando output/status por aparelho\n",
    "    y_aparelho = y_cv[rotulo_aparelho]\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem:\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_aparelho).items():\n",
    "        print(f\"        - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "    \n",
    "\n",
    "    print(f\"     -> Avaliando modelo (CV - {skf.n_splits} folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in tqdm_notebook(enumerate(skf.split(X_cv, y_aparelho)), total=skf.n_splits):\n",
    "        \n",
    "        # Preparando lotes\n",
    "        X_treino_cv, X_teste_cv = X_cv.iloc[idx_treino], X_cv.iloc[idx_teste]\n",
    "        y_treino_cv, y_teste_cv = y_aparelho.iloc[idx_treino], y_aparelho.iloc[idx_teste]\n",
    "\n",
    "        # Treinando modelo\n",
    "        clf = clone(modelo)\n",
    "        \n",
    "        clf.fit(X_treino_cv, y_treino_cv)\n",
    "\n",
    "        # Prevendo conjunto de dados\n",
    "        y_hat = clf.predict(X_teste_cv)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste_cv, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste_cv, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste_cv, y_hat) if np.unique(y_teste_cv).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"cv\")\n",
    "\n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true_cv.extend(y_teste_cv)\n",
    "        y_pred_cv.extend(y_hat)\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true_cv, y_pred_cv))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true_cv, y_pred_cv))\n",
    "    print()\n",
    "    print(\"**********************************************\")\n",
    "    print()\n",
    "    \n",
    "# Consolidando DataFrame\n",
    "df_resultados = pd.DataFrame(resultados_modelo)\n",
    "\n",
    "arquivo_resultados = os.path.join(caminho_dados_notebook, f\"resultados_{dominio}_svm.xlsx\")\n",
    "if os.path.isfile(arquivo_resultados): os.remove(arquivo_resultados)\n",
    "df_resultados.to_excel(arquivo_resultados, index=False)\n",
    "    \n",
    "print(\"############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\")\n",
    "display(df_resultados.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T19:59:41.720698Z",
     "start_time": "2020-08-31T19:59:41.680673Z"
    }
   },
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T03:52:19.841404Z",
     "start_time": "2021-05-02T22:19:01.487888Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "\n",
      "* Aparelho `LC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     12400\n",
      "           1       1.00      0.98      0.99     12800\n",
      "\n",
      "    accuracy                           0.99     25200\n",
      "   macro avg       0.99      0.99      0.99     25200\n",
      "weighted avg       0.99      0.99      0.99     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12381    19]\n",
      " [  239 12561]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128ff98e2a6a42bc89dad40c6d82c409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[30999     1]\n",
      " [    1 31999]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LI`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f632a7818b4a609f61a526e69d82d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MO`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     12400\n",
      "           1       0.98      1.00      0.99     12800\n",
      "\n",
      "    accuracy                           0.99     25200\n",
      "   macro avg       0.99      0.99      0.99     25200\n",
      "weighted avg       0.99      0.99      0.99     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12093   307]\n",
      " [   13 12787]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4155d5e44c54af99dfec7f7e3e4f09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MT`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb0ab14d2fb460eb1e1e2d9e407f182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `PC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33d6fa2c86c430b80ea83d942536a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LF`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     12400\n",
      "           1       0.97      0.95      0.96     12800\n",
      "\n",
      "    accuracy                           0.96     25200\n",
      "   macro avg       0.96      0.96      0.96     25200\n",
      "weighted avg       0.96      0.96      0.96     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[11980   420]\n",
      " [  582 12218]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d82905ba1cb9408cbc98383b6b705851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    2 31998]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LC</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.989762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989762</td>\n",
       "      <td>0.989762</td>\n",
       "      <td>0.989761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989761</td>\n",
       "      <td>0.989761</td>\n",
       "      <td>0.989898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989898</td>\n",
       "      <td>0.989898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LF</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.960238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.960238</td>\n",
       "      <td>0.960238</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.960330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.960330</td>\n",
       "      <td>0.960330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LI</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MO</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.987302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987302</td>\n",
       "      <td>0.987302</td>\n",
       "      <td>0.987292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987292</td>\n",
       "      <td>0.987292</td>\n",
       "      <td>0.987113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987113</td>\n",
       "      <td>0.987113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MT</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PC</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             acc                                      f1  \\\n",
       "                            mean       std       max       min      mean   \n",
       "appliance base                                                             \n",
       "LC        cv            0.999968  0.000043  1.000000  0.999921  0.999968   \n",
       "          treino-teste  0.989762       NaN  0.989762  0.989762  0.989761   \n",
       "LF        cv            0.999968  0.000071  1.000000  0.999841  0.999968   \n",
       "          treino-teste  0.960238       NaN  0.960238  0.960238  0.960235   \n",
       "LI        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "MO        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  0.987302       NaN  0.987302  0.987302  0.987292   \n",
       "MT        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "PC        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "\n",
       "                                                           auc            \\\n",
       "                             std       max       min      mean       std   \n",
       "appliance base                                                             \n",
       "LC        cv            0.000043  1.000000  0.999921  0.999968  0.000043   \n",
       "          treino-teste       NaN  0.989761  0.989761  0.989898       NaN   \n",
       "LF        cv            0.000071  1.000000  0.999841  0.999969  0.000070   \n",
       "          treino-teste       NaN  0.960235  0.960235  0.960330       NaN   \n",
       "LI        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "MO        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  0.987292  0.987292  0.987113       NaN   \n",
       "MT        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "PC        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "\n",
       "                                            \n",
       "                             max       min  \n",
       "appliance base                              \n",
       "LC        cv            1.000000  0.999919  \n",
       "          treino-teste  0.989898  0.989898  \n",
       "LF        cv            1.000000  0.999844  \n",
       "          treino-teste  0.960330  0.960330  \n",
       "LI        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "MO        cv            1.000000  1.000000  \n",
       "          treino-teste  0.987113  0.987113  \n",
       "MT        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "PC        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo = XGBClassifier(eval_metric='error', random_state=SEED, n_jobs=4)\n",
    "\n",
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \n",
    "    \"base\": []\n",
    "}\n",
    "\n",
    "for rotulo_aparelho in colunas_output:\n",
    "    \n",
    "    print(\"****************************************************************\\n\")\n",
    "    print(f\"* Aparelho `{rotulo_aparelho}`...\\n\")\n",
    "    \n",
    "    #######################################################################\n",
    "    #                AVALIACAO 1 - Base de treino/validacao               #\n",
    "    #######################################################################\n",
    "\n",
    "    # # Filtrando output/status por aparelho\n",
    "    y_treino_aparelho = y_treino[rotulo_aparelho]\n",
    "    y_validacao_aparelho = y_validacao[rotulo_aparelho]\n",
    "\n",
    "    print(f\"  - Avaliando modelo através da base treino/validacao...\")\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem (lote validacao):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_validacao_aparelho).items():\n",
    "        print(f\"       - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_validacao_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "\n",
    "    # Treinando modelo\n",
    "    print(f\"     -> Treinando modelo...\\n\")\n",
    "    clf = clone(modelo)\n",
    "    \n",
    "    clf.fit(X_treino, y_treino_aparelho)\n",
    "\n",
    "    # Prevendo conjunto de dados\n",
    "    y_hat = clf.predict(X_validacao)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "    resultados_modelo[\"fold\"].append(\"-\")\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_validacao_aparelho, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_validacao_aparelho, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_validacao_aparelho, y_hat) if np.unique(y_validacao_aparelho).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"treino-teste\")\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_validacao_aparelho, y_hat))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_validacao_aparelho, y_hat))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    #######################################################################\n",
    "    #                  AVALIACAO 2 - Validacao Cruzada                    #\n",
    "    #######################################################################\n",
    "    \n",
    "    y_true_cv, y_pred_cv  = [], []\n",
    "\n",
    "    print(f\"  - Avaliando através de validação cruzada ({skf.n_splits}-folds)...\")\n",
    "\n",
    "    # Filtrando output/status por aparelho\n",
    "    y_aparelho = y_cv[rotulo_aparelho]\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem:\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_aparelho).items():\n",
    "        print(f\"        - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "    \n",
    "\n",
    "    print(f\"     -> Avaliando modelo (CV - {skf.n_splits} folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in tqdm_notebook(enumerate(skf.split(X_cv, y_aparelho)), total=skf.n_splits):\n",
    "        \n",
    "        # Preparando lotes\n",
    "        X_treino_cv, X_teste_cv = X_cv.iloc[idx_treino], X_cv.iloc[idx_teste]\n",
    "        y_treino_cv, y_teste_cv = y_aparelho.iloc[idx_treino], y_aparelho.iloc[idx_teste]\n",
    "\n",
    "        # Treinando modelo\n",
    "        clf = clone(modelo)\n",
    "        \n",
    "        clf.fit(X_treino_cv, y_treino_cv)\n",
    "\n",
    "        # Prevendo conjunto de dados\n",
    "        y_hat = clf.predict(X_teste_cv)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste_cv, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste_cv, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste_cv, y_hat) if np.unique(y_teste_cv).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"cv\")\n",
    "\n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true_cv.extend(y_teste_cv)\n",
    "        y_pred_cv.extend(y_hat)\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true_cv, y_pred_cv))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true_cv, y_pred_cv))\n",
    "    print()\n",
    "    print(\"**********************************************\")\n",
    "    print()\n",
    "\n",
    "# Consolidando DataFrame\n",
    "df_resultados = pd.DataFrame(resultados_modelo)\n",
    "\n",
    "arquivo_resultados = os.path.join(caminho_dados_notebook, f\"resultados_{dominio}_xgboost.xlsx\")\n",
    "if os.path.isfile(arquivo_resultados): os.remove(arquivo_resultados)\n",
    "df_resultados.to_excel(arquivo_resultados, index=False)\n",
    "    \n",
    "print(\"############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\")\n",
    "display(df_resultados.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:10:29.051087Z",
     "start_time": "2021-05-03T03:52:22.146464Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "\n",
      "* Aparelho `LC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df619ccbbef346449319f2a4f651ecba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LI`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bcd9832e1e44a4084ca199f966cec87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MO`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864ada0fda3043beaad5513c8a366eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.48      0.65     31000\n",
      "           1       0.67      1.00      0.80     32000\n",
      "\n",
      "    accuracy                           0.75     63000\n",
      "   macro avg       0.83      0.74      0.73     63000\n",
      "weighted avg       0.83      0.75      0.73     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[15000 16000]\n",
      " [   45 31955]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `MT`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12400\n",
      "           1       1.00      1.00      1.00     12800\n",
      "\n",
      "    accuracy                           1.00     25200\n",
      "   macro avg       1.00      1.00      1.00     25200\n",
      "weighted avg       1.00      1.00      1.00     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[12400     0]\n",
      " [    0 12800]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e191ac5d89b54584a89e9c2b5c4715ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31000\n",
      "           1       1.00      1.00      1.00     32000\n",
      "\n",
      "    accuracy                           1.00     63000\n",
      "   macro avg       1.00      1.00      1.00     63000\n",
      "weighted avg       1.00      1.00      1.00     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[31000     0]\n",
      " [    0 32000]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `PC`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84     12400\n",
      "           1       0.83      0.90      0.86     12800\n",
      "\n",
      "    accuracy                           0.85     25200\n",
      "   macro avg       0.86      0.85      0.85     25200\n",
      "weighted avg       0.86      0.85      0.85     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[10009  2391]\n",
      " [ 1308 11492]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9977f5963a24a0695f9a3106a21bf2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.87     31000\n",
      "           1       0.84      0.94      0.89     32000\n",
      "\n",
      "    accuracy                           0.88     63000\n",
      "   macro avg       0.88      0.88      0.88     63000\n",
      "weighted avg       0.88      0.88      0.88     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[25109  5891]\n",
      " [ 1845 30155]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "****************************************************************\n",
      "\n",
      "* Aparelho `LF`...\n",
      "\n",
      "  - Avaliando modelo através da base treino/validacao...\n",
      "     -> Detalhes da amostragem (lote validacao):\n",
      "     ---\n",
      "       - Classe `0`: 12400 amostras (49.2%)\n",
      "       - Classe `1`: 12800 amostras (50.8%)\n",
      "\n",
      "     -> Treinando modelo...\n",
      "\n",
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87     12400\n",
      "           1       0.87      0.87      0.87     12800\n",
      "\n",
      "    accuracy                           0.87     25200\n",
      "   macro avg       0.87      0.87      0.87     25200\n",
      "weighted avg       0.87      0.87      0.87     25200\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[10784  1616]\n",
      " [ 1609 11191]]\n",
      "\n",
      "  - Avaliando através de validação cruzada (5-folds)...\n",
      "     -> Detalhes da amostragem:\n",
      "     ---\n",
      "        - Classe `0`: 31000 amostras (49.2%)\n",
      "        - Classe `1`: 32000 amostras (50.8%)\n",
      "\n",
      "     -> Avaliando modelo (CV - 5 folds)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a41eae27d574bac9104b1bf849d84a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      > Resultado:\n",
      "        = Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90     31000\n",
      "           1       0.91      0.90      0.90     32000\n",
      "\n",
      "    accuracy                           0.90     63000\n",
      "   macro avg       0.90      0.90      0.90     63000\n",
      "weighted avg       0.90      0.90      0.90     63000\n",
      "\n",
      "        = Confusion Matrix:\n",
      "\n",
      "[[27998  3002]\n",
      " [ 3266 28734]]\n",
      "\n",
      "**********************************************\n",
      "\n",
      "############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LC</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LF</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.900508</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.896032</td>\n",
       "      <td>0.900493</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>0.904188</td>\n",
       "      <td>0.896004</td>\n",
       "      <td>0.900549</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.904214</td>\n",
       "      <td>0.895998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.872024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.872024</td>\n",
       "      <td>0.872024</td>\n",
       "      <td>0.871990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.871990</td>\n",
       "      <td>0.871990</td>\n",
       "      <td>0.871987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.871987</td>\n",
       "      <td>0.871987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LI</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MO</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.745317</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.748254</td>\n",
       "      <td>0.743492</td>\n",
       "      <td>0.725425</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.729423</td>\n",
       "      <td>0.723475</td>\n",
       "      <td>0.741232</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.744254</td>\n",
       "      <td>0.739408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MT</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PC</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.877206</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.878730</td>\n",
       "      <td>0.875714</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.877882</td>\n",
       "      <td>0.874976</td>\n",
       "      <td>0.876156</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.877629</td>\n",
       "      <td>0.874793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.853214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.853214</td>\n",
       "      <td>0.853214</td>\n",
       "      <td>0.852704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.852704</td>\n",
       "      <td>0.852704</td>\n",
       "      <td>0.852495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.852495</td>\n",
       "      <td>0.852495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             acc                                      f1  \\\n",
       "                            mean       std       max       min      mean   \n",
       "appliance base                                                             \n",
       "LC        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "LF        cv            0.900508  0.003033  0.904206  0.896032  0.900493   \n",
       "          treino-teste  0.872024       NaN  0.872024  0.872024  0.871990   \n",
       "LI        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "MO        cv            0.745317  0.001864  0.748254  0.743492  0.725425   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "MT        cv            1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "          treino-teste  1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "PC        cv            0.877206  0.001313  0.878730  0.875714  0.876404   \n",
       "          treino-teste  0.853214       NaN  0.853214  0.853214  0.852704   \n",
       "\n",
       "                                                           auc            \\\n",
       "                             std       max       min      mean       std   \n",
       "appliance base                                                             \n",
       "LC        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "LF        cv            0.003038  0.904188  0.896004  0.900549  0.003056   \n",
       "          treino-teste       NaN  0.871990  0.871990  0.871987       NaN   \n",
       "LI        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "MO        cv            0.002426  0.729423  0.723475  0.741232  0.001905   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "MT        cv            0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "          treino-teste       NaN  1.000000  1.000000  1.000000       NaN   \n",
       "PC        cv            0.001292  0.877882  0.874976  0.876156  0.001278   \n",
       "          treino-teste       NaN  0.852704  0.852704  0.852495       NaN   \n",
       "\n",
       "                                            \n",
       "                             max       min  \n",
       "appliance base                              \n",
       "LC        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "LF        cv            0.904214  0.895998  \n",
       "          treino-teste  0.871987  0.871987  \n",
       "LI        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "MO        cv            0.744254  0.739408  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "MT        cv            1.000000  1.000000  \n",
       "          treino-teste  1.000000  1.000000  \n",
       "PC        cv            0.877629  0.874793  \n",
       "          treino-teste  0.852495  0.852495  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo = MLPClassifier(alpha=1e-3, hidden_layer_sizes=(10,), random_state=SEED)\n",
    "\n",
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \n",
    "    \"base\": []\n",
    "}\n",
    "\n",
    "for rotulo_aparelho in colunas_output:\n",
    "    \n",
    "    print(\"****************************************************************\\n\")\n",
    "    print(f\"* Aparelho `{rotulo_aparelho}`...\\n\")\n",
    "    \n",
    "    #######################################################################\n",
    "    #                AVALIACAO 1 - Base de treino/validacao               #\n",
    "    #######################################################################\n",
    "\n",
    "    # # Filtrando output/status por aparelho\n",
    "    y_treino_aparelho = y_treino[rotulo_aparelho]\n",
    "    y_validacao_aparelho = y_validacao[rotulo_aparelho]\n",
    "\n",
    "    print(f\"  - Avaliando modelo através da base treino/validacao...\")\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem (lote validacao):\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_validacao_aparelho).items():\n",
    "        print(f\"       - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_validacao_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "\n",
    "    # Treinando modelo\n",
    "    print(f\"     -> Treinando modelo...\\n\")\n",
    "    clf = clone(modelo)\n",
    "    \n",
    "    clf.fit(X_treino, y_treino_aparelho)\n",
    "\n",
    "    # Prevendo conjunto de dados\n",
    "    y_hat = clf.predict(X_validacao)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "    resultados_modelo[\"fold\"].append(\"-\")\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_validacao_aparelho, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_validacao_aparelho, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_validacao_aparelho, y_hat) if np.unique(y_validacao_aparelho).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"treino-teste\")\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_validacao_aparelho, y_hat))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_validacao_aparelho, y_hat))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    #######################################################################\n",
    "    #                  AVALIACAO 2 - Validacao Cruzada                    #\n",
    "    #######################################################################\n",
    "    \n",
    "    y_true_cv, y_pred_cv  = [], []\n",
    "\n",
    "    print(f\"  - Avaliando através de validação cruzada ({skf.n_splits}-folds)...\")\n",
    "\n",
    "    # Filtrando output/status por aparelho\n",
    "    y_aparelho = y_cv[rotulo_aparelho]\n",
    "    \n",
    "    print(\"     -> Detalhes da amostragem:\")\n",
    "    print(\"     ---\")\n",
    "    for item in Counter(y_aparelho).items():\n",
    "        print(f\"        - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y_aparelho)*100,1)}%)\" )\n",
    "    print()\n",
    "    \n",
    "\n",
    "    print(f\"     -> Avaliando modelo (CV - {skf.n_splits} folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in tqdm_notebook(enumerate(skf.split(X_cv, y_aparelho)), total=skf.n_splits):\n",
    "        \n",
    "        # Preparando lotes\n",
    "        X_treino_cv, X_teste_cv = X_cv.iloc[idx_treino], X_cv.iloc[idx_teste]\n",
    "        y_treino_cv, y_teste_cv = y_aparelho.iloc[idx_treino], y_aparelho.iloc[idx_teste]\n",
    "\n",
    "        # Treinando modelo\n",
    "        clf = clone(modelo)\n",
    "        \n",
    "        clf.fit(X_treino_cv, y_treino_cv)\n",
    "\n",
    "        # Prevendo conjunto de dados\n",
    "        y_hat = clf.predict(X_teste_cv)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(rotulo_aparelho)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste_cv, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste_cv, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste_cv, y_hat) if np.unique(y_teste_cv).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"cv\")\n",
    "\n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true_cv.extend(y_teste_cv)\n",
    "        y_pred_cv.extend(y_hat)\n",
    "\n",
    "    print(\"      > Resultado:\")\n",
    "    print(\"        = Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true_cv, y_pred_cv))\n",
    "    print(\"        = Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true_cv, y_pred_cv))\n",
    "    print()\n",
    "    print(\"**********************************************\")\n",
    "    print()\n",
    "\n",
    "# Consolidando DataFrame\n",
    "df_resultados = pd.DataFrame(resultados_modelo)\n",
    "\n",
    "arquivo_resultados = os.path.join(caminho_dados_notebook, f\"resultados_{dominio}_mlp.xlsx\")\n",
    "if os.path.isfile(arquivo_resultados): os.remove(arquivo_resultados)\n",
    "df_resultados.to_excel(arquivo_resultados, index=False)\n",
    "    \n",
    "print(\"############################## RESULTADO FINAL DO DOMINIO/MODELO ##############################\")\n",
    "display(df_resultados.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise dos Resultados (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:10:32.077065Z",
     "start_time": "2021-05-03T09:10:31.295643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Análise por modelo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBOOST</th>\n",
       "      <td>cv</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBOOST</th>\n",
       "      <td>treino-teste</td>\n",
       "      <td>0.989550</td>\n",
       "      <td>0.015440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960238</td>\n",
       "      <td>0.989548</td>\n",
       "      <td>0.015441</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.989557</td>\n",
       "      <td>0.015411</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>treino-teste</td>\n",
       "      <td>0.954206</td>\n",
       "      <td>0.071192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.853214</td>\n",
       "      <td>0.954116</td>\n",
       "      <td>0.071345</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852704</td>\n",
       "      <td>0.954080</td>\n",
       "      <td>0.071405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>cv</td>\n",
       "      <td>0.944894</td>\n",
       "      <td>0.096612</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.736190</td>\n",
       "      <td>0.944832</td>\n",
       "      <td>0.096722</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.735730</td>\n",
       "      <td>0.944965</td>\n",
       "      <td>0.096713</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.735713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>treino-teste</td>\n",
       "      <td>0.936224</td>\n",
       "      <td>0.106449</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.936161</td>\n",
       "      <td>0.106510</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>0.936380</td>\n",
       "      <td>0.106350</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>cv</td>\n",
       "      <td>0.920505</td>\n",
       "      <td>0.094627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.743492</td>\n",
       "      <td>0.917054</td>\n",
       "      <td>0.101116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.723475</td>\n",
       "      <td>0.919656</td>\n",
       "      <td>0.096015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.739408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 base       acc                                 f1            \\\n",
       "                           mean       std  max       min      mean       std   \n",
       "model                                                                          \n",
       "XGBOOST            cv  0.999989  0.000034  1.0  0.999841  0.999989  0.000034   \n",
       "XGBOOST  treino-teste  0.989550  0.015440  1.0  0.960238  0.989548  0.015441   \n",
       "MLP      treino-teste  0.954206  0.071192  1.0  0.853214  0.954116  0.071345   \n",
       "SVM                cv  0.944894  0.096612  1.0  0.736190  0.944832  0.096722   \n",
       "SVM      treino-teste  0.936224  0.106449  1.0  0.746032  0.936161  0.106510   \n",
       "MLP                cv  0.920505  0.094627  1.0  0.743492  0.917054  0.101116   \n",
       "\n",
       "                             auc                           \n",
       "         max       min      mean       std  max       min  \n",
       "model                                                      \n",
       "XGBOOST  1.0  0.999841  0.999989  0.000034  1.0  0.999844  \n",
       "XGBOOST  1.0  0.960235  0.989557  0.015411  1.0  0.960330  \n",
       "MLP      1.0  0.852704  0.954080  0.071405  1.0  0.852495  \n",
       "SVM      1.0  0.735730  0.944965  0.096713  1.0  0.735713  \n",
       "SVM      1.0  0.745968  0.936380  0.106350  1.0  0.745968  \n",
       "MLP      1.0  0.723475  0.919656  0.096015  1.0  0.739408  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Análise por aparelho/modelo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>model</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">LC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.989762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989762</td>\n",
       "      <td>0.989762</td>\n",
       "      <td>0.989761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989761</td>\n",
       "      <td>0.989761</td>\n",
       "      <td>0.989898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989898</td>\n",
       "      <td>0.989898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">LF</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.900508</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.904206</td>\n",
       "      <td>0.896032</td>\n",
       "      <td>0.900493</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>0.904188</td>\n",
       "      <td>0.896004</td>\n",
       "      <td>0.900549</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.904214</td>\n",
       "      <td>0.895998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.872024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.872024</td>\n",
       "      <td>0.872024</td>\n",
       "      <td>0.871990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.871990</td>\n",
       "      <td>0.871990</td>\n",
       "      <td>0.871987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.871987</td>\n",
       "      <td>0.871987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.740714</td>\n",
       "      <td>0.003310</td>\n",
       "      <td>0.744127</td>\n",
       "      <td>0.736190</td>\n",
       "      <td>0.740423</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>0.743966</td>\n",
       "      <td>0.735730</td>\n",
       "      <td>0.740380</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.743916</td>\n",
       "      <td>0.735713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.746032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>0.745968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.960238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.960238</td>\n",
       "      <td>0.960238</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.960330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.960330</td>\n",
       "      <td>0.960330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">LI</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MO</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.745317</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.748254</td>\n",
       "      <td>0.743492</td>\n",
       "      <td>0.725425</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.729423</td>\n",
       "      <td>0.723475</td>\n",
       "      <td>0.741232</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.744254</td>\n",
       "      <td>0.739408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.987302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987302</td>\n",
       "      <td>0.987302</td>\n",
       "      <td>0.987292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987292</td>\n",
       "      <td>0.987292</td>\n",
       "      <td>0.987113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987113</td>\n",
       "      <td>0.987113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MT</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">PC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.877206</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.878730</td>\n",
       "      <td>0.875714</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.877882</td>\n",
       "      <td>0.874976</td>\n",
       "      <td>0.876156</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.877629</td>\n",
       "      <td>0.874793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.853214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.853214</td>\n",
       "      <td>0.853214</td>\n",
       "      <td>0.852704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.852704</td>\n",
       "      <td>0.852704</td>\n",
       "      <td>0.852495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.852495</td>\n",
       "      <td>0.852495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>cv</th>\n",
       "      <td>0.928651</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.935397</td>\n",
       "      <td>0.923413</td>\n",
       "      <td>0.928570</td>\n",
       "      <td>0.005976</td>\n",
       "      <td>0.935340</td>\n",
       "      <td>0.923316</td>\n",
       "      <td>0.929408</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.936104</td>\n",
       "      <td>0.924209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>0.871310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.871310</td>\n",
       "      <td>0.871310</td>\n",
       "      <td>0.870996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.870996</td>\n",
       "      <td>0.870996</td>\n",
       "      <td>0.872312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.872312</td>\n",
       "      <td>0.872312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>cv</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino-teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     acc                                \\\n",
       "                                    mean       std       max       min   \n",
       "appliance model   base                                                   \n",
       "LC        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            0.999968  0.000043  1.000000  0.999921   \n",
       "                  treino-teste  0.989762       NaN  0.989762  0.989762   \n",
       "LF        MLP     cv            0.900508  0.003033  0.904206  0.896032   \n",
       "                  treino-teste  0.872024       NaN  0.872024  0.872024   \n",
       "          SVM     cv            0.740714  0.003310  0.744127  0.736190   \n",
       "                  treino-teste  0.746032       NaN  0.746032  0.746032   \n",
       "          XGBOOST cv            0.999968  0.000071  1.000000  0.999841   \n",
       "                  treino-teste  0.960238       NaN  0.960238  0.960238   \n",
       "LI        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "MO        MLP     cv            0.745317  0.001864  0.748254  0.743492   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  0.987302       NaN  0.987302  0.987302   \n",
       "MT        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "PC        MLP     cv            0.877206  0.001313  0.878730  0.875714   \n",
       "                  treino-teste  0.853214       NaN  0.853214  0.853214   \n",
       "          SVM     cv            0.928651  0.005950  0.935397  0.923413   \n",
       "                  treino-teste  0.871310       NaN  0.871310  0.871310   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "\n",
       "                                      f1                                \\\n",
       "                                    mean       std       max       min   \n",
       "appliance model   base                                                   \n",
       "LC        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            0.999968  0.000043  1.000000  0.999921   \n",
       "                  treino-teste  0.989761       NaN  0.989761  0.989761   \n",
       "LF        MLP     cv            0.900493  0.003038  0.904188  0.896004   \n",
       "                  treino-teste  0.871990       NaN  0.871990  0.871990   \n",
       "          SVM     cv            0.740423  0.003435  0.743966  0.735730   \n",
       "                  treino-teste  0.745968       NaN  0.745968  0.745968   \n",
       "          XGBOOST cv            0.999968  0.000071  1.000000  0.999841   \n",
       "                  treino-teste  0.960235       NaN  0.960235  0.960235   \n",
       "LI        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "MO        MLP     cv            0.725425  0.002426  0.729423  0.723475   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  0.987292       NaN  0.987292  0.987292   \n",
       "MT        MLP     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "PC        MLP     cv            0.876404  0.001292  0.877882  0.874976   \n",
       "                  treino-teste  0.852704       NaN  0.852704  0.852704   \n",
       "          SVM     cv            0.928570  0.005976  0.935340  0.923316   \n",
       "                  treino-teste  0.870996       NaN  0.870996  0.870996   \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000   \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000   \n",
       "\n",
       "                                     auc                                \n",
       "                                    mean       std       max       min  \n",
       "appliance model   base                                                  \n",
       "LC        MLP     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          XGBOOST cv            0.999968  0.000043  1.000000  0.999919  \n",
       "                  treino-teste  0.989898       NaN  0.989898  0.989898  \n",
       "LF        MLP     cv            0.900549  0.003056  0.904214  0.895998  \n",
       "                  treino-teste  0.871987       NaN  0.871987  0.871987  \n",
       "          SVM     cv            0.740380  0.003423  0.743916  0.735713  \n",
       "                  treino-teste  0.745968       NaN  0.745968  0.745968  \n",
       "          XGBOOST cv            0.999969  0.000070  1.000000  0.999844  \n",
       "                  treino-teste  0.960330       NaN  0.960330  0.960330  \n",
       "LI        MLP     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "MO        MLP     cv            0.741232  0.001905  0.744254  0.739408  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  0.987113       NaN  0.987113  0.987113  \n",
       "MT        MLP     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          SVM     cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  \n",
       "PC        MLP     cv            0.876156  0.001278  0.877629  0.874793  \n",
       "                  treino-teste  0.852495       NaN  0.852495  0.852495  \n",
       "          SVM     cv            0.929408  0.005882  0.936104  0.924209  \n",
       "                  treino-teste  0.872312       NaN  0.872312  0.872312  \n",
       "          XGBOOST cv            1.000000  0.000000  1.000000  1.000000  \n",
       "                  treino-teste  1.000000       NaN  1.000000  1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_resultados_svm = pd.read_excel(os.path.join(caminho_dados_notebook, f\"resultados_{dominio}_svm.xlsx\"), engine='openpyxl')\n",
    "df_resultados_svm[\"model\"] = \"SVM\"\n",
    "\n",
    "df_resultados_xgboost = pd.read_excel(os.path.join(caminho_dados_notebook, f\"resultados_{dominio}_xgboost.xlsx\"), engine='openpyxl')\n",
    "df_resultados_xgboost[\"model\"] = \"XGBOOST\"\n",
    "\n",
    "df_resultados_mlp = pd.read_excel(os.path.join(caminho_dados_notebook, f\"resultados_{dominio}_mlp.xlsx\"), engine='openpyxl')\n",
    "df_resultados_mlp[\"model\"] = \"MLP\"\n",
    "\n",
    "# df_resultados_elm = pd.read_excel(os.path.join(caminho_dados_notebook, \"df_resultados_elm.xlsx\"))\n",
    "# df_resultados_elm[\"model\"] = \"ELM\"\n",
    "\n",
    "df_analise = pd.concat([\n",
    "    df_resultados_svm,\n",
    "    df_resultados_xgboost,\n",
    "    df_resultados_mlp, \n",
    "#     df_resultados_elm,  \n",
    "])\n",
    "\n",
    "print(\"* Análise por modelo:\")\n",
    "df_analise_modelo = df_analise.groupby([\"model\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"f1\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"auc\": [\"mean\",\"std\",\"max\",\"min\"]\n",
    "}).reset_index().sort_values(('f1','mean'), ascending=False).set_index(\"model\")\n",
    "display(df_analise_modelo)\n",
    "df_analise_modelo.to_excel(os.path.join(caminho_dados_notebook, f\"analise_{dominio}_modelos.xlsx\"))\n",
    "\n",
    "print()\n",
    "print(\"* Análise por aparelho/modelo:\")\n",
    "df_analise_aparelho = df_analise.groupby([\"appliance\",\"model\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"f1\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"auc\": [\"mean\",\"std\",\"max\",\"min\"]\n",
    "})#.reset_index().sort_values(('f1','mean'), ascending=False).set_index([\"aparelho\",\"metodologia\"])\n",
    "display(df_analise_aparelho)\n",
    "df_analise_aparelho.to_excel(os.path.join(caminho_dados_notebook, f\"analise_{dominio}_aparelhos.xls\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:10:32.109285Z",
     "start_time": "2021-05-03T09:10:32.079991Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T09:10:32.155124Z",
     "start_time": "2021-05-03T09:10:32.113288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Diego Luiz Cavalca\n",
      "\n",
      "Last updated: Mon Jan 24 2022 08:52:41Hora oficial do Brasil\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.8\n",
      "IPython version      : 7.21.0\n",
      "\n",
      "Compiler    : MSC v.1928 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 158 Stepping 9, GenuineIntel\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 5e5bccaaf9e541e11be67706c7eb7d7b39a8be65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -a \"Diego Luiz Cavalca\" -u -n -t -z -v -m -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

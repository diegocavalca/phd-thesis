{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Quali - Aprendizado Profundo (Ext. Artibutos RP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estruturação de pipeline baseado em aprendizado raso utilizando atributos extraídos via Deep Learning dos RPs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:02:32.836311Z",
     "start_time": "2021-03-31T00:02:29.940078Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "from pretty_confusion_matrix import *\n",
    "\n",
    "# TODO: implementar rotina na classe PyNILM.utils\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "def listar_variaveis_memoria(ambiente):\n",
    "    print(\"* Variáveis instanciadas em memória:\")\n",
    "    print(\"---\")\n",
    "    total = 0\n",
    "    for name, size in sorted(((name, sys.getsizeof(value)) for name, value in ambiente.items()),\n",
    "                             key= lambda x: -x[1])[:10]:\n",
    "        total += size\n",
    "        print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))\n",
    "    print(\"---\")\n",
    "    print(\"Total:\", sizeof_fmt(total))\n",
    "    \n",
    "# TODO: implementar na classe utils\n",
    "def highlight_col(x):\n",
    "    r = 'background-color: #D9D9D9'\n",
    "    df1 = pd.DataFrame('', index=x.index, columns=x.columns)\n",
    "    df1.iloc[:, -2] = r\n",
    "    return df1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:02:32.852287Z",
     "start_time": "2021-03-31T00:02:32.838323Z"
    }
   },
   "outputs": [],
   "source": [
    "# CONSTANTES FUNDAMENTAIS DE ORGANIZACAO DE PASTAS/ARQUIVOS\n",
    "RESIDENCIA = 3\n",
    "\n",
    "# Path do arquivo H5 (base REDD ja preparada p/ NILMTK) e outros insumos fundamentais\n",
    "caminho_dados = \"D:/Projetos/phd-thesis/datasets/\"\n",
    "\n",
    "# Definir diretorios onde iremos salvar os insumos gerados do notebook (dados, imagens, etc.)\n",
    "caminho_dados_notebook = os.path.join(caminho_dados, \"23\") # Num. notebook\n",
    "if not os.path.isdir(caminho_dados_notebook):\n",
    "    os.makedirs(caminho_dados_notebook)\n",
    "caminho_imagens_notebook = os.path.join(caminho_dados_notebook, \"imagens\") # Num. notebook\n",
    "if not os.path.isdir(caminho_imagens_notebook):\n",
    "    os.makedirs(caminho_imagens_notebook)\n",
    "\n",
    "# Path do arquivo H5 (base REDD ja preparada p/ NILMTK)\n",
    "caminho_redd = os.path.join(caminho_dados, \"REDD/low_freq\")\n",
    "\n",
    "# Path completo do arquivo REDD\n",
    "arquivo_dataset = os.path.join(caminho_redd, \"redd.h5\")\n",
    "\n",
    "# VARIAVEL AUXILIAR\n",
    "# Path dos arquivos relacionados as janelas\n",
    "caminho_janelas = os.path.join(caminho_redd, \"../../phd\")\n",
    "if not os.path.isdir(caminho_janelas):\n",
    "    os.makedirs(caminho_janelas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:02:34.285880Z",
     "start_time": "2021-03-31T00:02:32.854280Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from six import iteritems\n",
    "\n",
    "from nilmtk import DataSet, TimeFrame, MeterGroup, HDFDataStore\n",
    "from nilmtk.legacy.disaggregate import CombinatorialOptimisation, FHMM\n",
    "import nilmtk.utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T23:30:48.143441Z",
     "start_time": "2021-03-30T23:30:47.750179Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base REDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:02:36.592136Z",
     "start_time": "2021-03-31T00:02:34.288879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NILMTK -> Detalhes sobre o dataset REDD:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ul><li><strong>name</strong>: REDD</li><li><strong>long_name</strong>: The Reference Energy Disaggregation Data set</li><li><strong>creators</strong>: <ul><li>Kolter, Zico</li><li>Johnson, Matthew</li></ul></li><li><strong>publication_date</strong>: 2011</li><li><strong>institution</strong>: Massachusetts Institute of Technology (MIT)</li><li><strong>contact</strong>: zkolter@cs.cmu.edu</li><li><strong>description</strong>: Several weeks of power data for 6 different homes.</li><li><strong>subject</strong>: Disaggregated power demand from domestic buildings.</li><li><strong>number_of_buildings</strong>: 6</li><li><strong>timezone</strong>: US/Eastern</li><li><strong>geo_location</strong>: <ul><li><strong>locality</strong>: Massachusetts</li><li><strong>country</strong>: US</li><li><strong>latitude</strong>: 42.360091</li><li><strong>longitude</strong>: -71.09416</li></ul></li><li><strong>related_documents</strong>: <ul><li><a href=\"http://redd.csail.mit.edu\">http://redd.csail.mit.edu</a></li><li>J. Zico Kolter and Matthew J. Johnson. REDD: A public data set for energy disaggregation research. In proceedings of the SustKDD workshop on Data Mining Applications in Sustainability, 2011. <a href=\"http://redd.csail.mit.edu/kolter-kddsust11.pdf\">http://redd.csail.mit.edu/kolter-kddsust11.pdf</a>\n",
       "</li></ul></li><li><strong>schema</strong>: <a href=\"https://github.com/nilmtk/nilm_metadata/tree/v0.2\">https://github.com/nilmtk/nilm_metadata/tree/v0.2</a></li><li><strong>meter_devices</strong>: <ul><li><strong>eMonitor</strong>: <ul><li><strong>model</strong>: eMonitor</li><li><strong>manufacturer</strong>: Powerhouse Dynamics</li><li><strong>manufacturer_url</strong>: <a href=\"http://powerhousedynamics.com\">http://powerhousedynamics.com</a></li><li><strong>description</strong>: Measures circuit-level power demand.  Comes with 24 CTs. This FAQ page suggests the eMonitor measures real (active) power: <a href=\"http://www.energycircle.com/node/14103\">http://www.energycircle.com/node/14103</a>  although the REDD readme.txt says all channels record apparent power.\n",
       "</li><li><strong>sample_period</strong>: 3</li><li><strong>max_sample_period</strong>: 50</li><li><strong>measurements</strong>: <ul><li>{'physical_quantity': 'power', 'type': 'active', 'upper_limit': 5000, 'lower_limit': 0}</li></ul></li><li><strong>wireless</strong>: False</li></ul></li><li><strong>REDD_whole_house</strong>: <ul><li><strong>description</strong>: REDD's DIY power meter used to measure whole-home AC waveforms at high frequency.  To quote from their paper: \"CTs from TED (<a href=\"http://www.theenergydetective.com\">http://www.theenergydetective.com</a>) to measure current in the power mains, a Pico TA041 oscilloscope probe (<a href=\"http://www.picotechnologies.com\">http://www.picotechnologies.com</a>) to measure voltage for one of the two phases in the home, and a National Instruments NI-9239 analog to digital converter to transform both these analog signals to digital readings. This A/D converter has 24 bit resolution with noise of approximately 70 ÂµV, which determines the noise level of our current and voltage readings: the TED CTs are rated for 200 amp circuits and a maximum of 3 volts, so we are able to differentiate between currents of approximately ((200))(70 Ã— 10âˆ’6)/(3) = 4.66mA, corresponding to power changes of about 0.5 watts. Similarly, since we use a 1:100 voltage stepdown in the oscilloscope probe, we can detect voltage differences of about 7mV.\"\n",
       "</li><li><strong>sample_period</strong>: 1</li><li><strong>max_sample_period</strong>: 30</li><li><strong>measurements</strong>: <ul><li>{'physical_quantity': 'power', 'type': 'apparent', 'upper_limit': 50000, 'lower_limit': 0}</li></ul></li><li><strong>wireless</strong>: False</li></ul></li></ul></li></ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PARÂMETROS DO ESTUDO:\n",
      "{'base': <nilmtk.dataset.DataSet object at 0x00000259CD79C790>,\n",
      " 'debug': False,\n",
      " 'fim_intervalo': '2011-04-23 08:43:26',\n",
      " 'id_residencia': 3,\n",
      " 'inicio_intervalo': '2011-04-16 05:11:30'}\n"
     ]
    }
   ],
   "source": [
    "# Gerar arquivo H5 (Nilmtk) do dataset REDD, caso n exista\n",
    "if not os.path.isfile(arquivo_dataset):\n",
    "    from nilmtk.dataset_converters import convert_redd\n",
    "    \n",
    "    print(\"Gerando arquivo H5 (NILMTK) da base REDD, aguarde...\")\n",
    "    print(\"-----\")\n",
    "    convert_redd(caminho_redd, arquivo_dataset)\n",
    "\n",
    "# Carregando dataset REDD no objeto NILMTK\n",
    "# Exemplo de carregamento da base REDD no NILMTK\n",
    "import h5py # * Evitar erro de incompatibilidade entre h5py e nilmtk\n",
    "from nilmtk import DataSet\n",
    "from nilmtk.utils import print_dict\n",
    "redd = DataSet(arquivo_dataset)\n",
    "print(\"NILMTK -> Detalhes sobre o dataset REDD:\")\n",
    "print_dict(redd.metadata)\n",
    "print()\n",
    "\n",
    "# Parametros dos dados\n",
    "PARAMETROS_DATASET = {\n",
    "    \"base\":redd,\n",
    "    \"id_residencia\": RESIDENCIA,\n",
    "    \"inicio_intervalo\":'2011-04-16 05:11:30',\n",
    "    \"fim_intervalo\":'2011-04-23 08:43:26',\n",
    "    \"debug\": False    \n",
    "}\n",
    "print(\"PARÂMETROS DO ESTUDO:\")\n",
    "pprint(PARAMETROS_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:02:36.608093Z",
     "start_time": "2021-03-31T00:02:36.595128Z"
    }
   },
   "outputs": [],
   "source": [
    "def carregar_dados_aparelho(janelas, instancia, aparelho, taxa, tamanho_janela, split_teste=None, eliminar_janelas_vazias=False, debug=False):\n",
    "    # Extrair series divididas em janelas para cada medidor\n",
    "    dados_cargas = janelas.preparar(\n",
    "        taxa_amostral=taxa, \n",
    "        intervalo_medicao=tamanho_janela\n",
    "    )\n",
    "    print()\n",
    "\n",
    "    # Pprearando dados (Serie / Estado)\n",
    "    # X\n",
    "    dados_medidores = janelas.filtrar_cargas(\n",
    "        dados_cargas,\n",
    "        filtros=[\n",
    "            (1, 'site_meter'),\n",
    "            (2, 'site_meter'),    \n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    dados_aparelho = janelas.filtrar_cargas(dados_cargas, filtros=[(instancia, aparelho)])[0]\n",
    "    \n",
    "    # Validar tamanho dos dados de medidores (podem ter mais registros que os aparelhos)\n",
    "    janela_media_medidores = int(np.sum([len(d[\"janelas\"])for d in dados_medidores])/len(dados_medidores))\n",
    "    janela_media_aparelho = len(dados_aparelho[\"janelas\"])#int(np.sum([len(d[\"janelas\"])for d in dados_aparelho])/len(dados_aparelho))\n",
    "\n",
    "    # Ajustando para medidores terem o mesmo shape de janelas dos aparelhos \n",
    "    if janela_media_medidores > janela_media_aparelho:\n",
    "        diferenca = janela_media_medidores-janela_media_aparelho\n",
    "        #if debug: print(\"  -> Diferenca encontrada entre medidores/aparelhos:\", diferenca, \", ajustando..\")\n",
    "        for i in range(len(dados_medidores)):\n",
    "            removidos = 0\n",
    "            while removidos < diferenca:\n",
    "                # Remover ultima janela\n",
    "                dados_medidores[i][\"janelas\"] = dados_medidores[i][\"janelas\"][:-1,:]\n",
    "                removidos += 1\n",
    "    \n",
    "    # Estruturando dados modelagem (X e y)\n",
    "    X = dados_medidores[0][\"janelas\"] + dados_medidores[1][\"janelas\"]\n",
    "\n",
    "    # Selecionando apenas janelas VALIDAS (ocorrencia de ao menos 1 carga)\n",
    "    # TODO: Implementar na biblioteca esta rotina de validacao\n",
    "    if eliminar_janelas_vazias:\n",
    "        idx_janelas_validas = np.where(np.sum(X, axis=1)>0)[0]\n",
    "        X = X[idx_janelas_validas]\n",
    "        #for i in range(len(dados_aparelhos)):\n",
    "        dados_aparelho[\"janelas\"] = dados_aparelho[\"janelas\"][idx_janelas_validas]\n",
    "        rotulos = copy.deepcopy(dados_aparelho[\"rotulos\"])\n",
    "        dados_aparelho[\"rotulos\"][\"estado\"] = rotulos[\"estado\"][idx_janelas_validas]\n",
    "        dados_aparelho[\"rotulos\"][\"media\"]  = rotulos[\"media\"][idx_janelas_validas]\n",
    "        dados_aparelho[\"rotulos\"][\"total\"]  = rotulos[\"total\"][idx_janelas_validas]\n",
    "        if debug:\n",
    "            print(\"   - `{}-{}`: {} => {}\".format(\n",
    "                dados_aparelho[\"carga\"].upper(), \n",
    "                dados_aparelho[\"instancia\"],\n",
    "                Counter(rotulos[\"estado\"]),\n",
    "                Counter(dados_aparelho[\"rotulos\"][\"estado\"])\n",
    "            ))\n",
    "\n",
    "    # y\n",
    "    y = dados_aparelho[\"rotulos\"][\"estado\"]\n",
    "\n",
    "    # <<< Limpando memoria >>>\n",
    "    dados_cargas = None\n",
    "    del dados_cargas\n",
    "    dados_medidores = None\n",
    "    del dados_medidores\n",
    "    dados_aparelho = None\n",
    "    del dados_aparelho\n",
    "    gc.collect()\n",
    "    # <<< Limpando memoria >>>\n",
    "\n",
    "    # Fazendo split dos dados (treino/teste)\n",
    "    if split_teste is None:\n",
    "        return X, y\n",
    "    else:\n",
    "        X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
    "            X, y, \n",
    "            test_size=split_teste,\n",
    "            stratify=y,\n",
    "            random_state=SEED\n",
    "        )\n",
    "        print()\n",
    "\n",
    "        return X_treino, X_teste, y_treino, y_teste        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melhores Combinações de Taxas e Janelas para cada Aparelho (estudo 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:02:37.095824Z",
     "start_time": "2021-03-31T00:02:36.960575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carga</th>\n",
       "      <th>taxa_amostragem</th>\n",
       "      <th>janela</th>\n",
       "      <th>loss</th>\n",
       "      <th>acuracia</th>\n",
       "      <th>precisao</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dish_washer - 9</td>\n",
       "      <td>2</td>\n",
       "      <td>720</td>\n",
       "      <td>0.05</td>\n",
       "      <td>95.33</td>\n",
       "      <td>20.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>22.22</td>\n",
       "      <td>59.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fridge - 7</td>\n",
       "      <td>2</td>\n",
       "      <td>1080</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>microwave - 16</td>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>0.04</td>\n",
       "      <td>95.83</td>\n",
       "      <td>66.67</td>\n",
       "      <td>33.33</td>\n",
       "      <td>44.44</td>\n",
       "      <td>71.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>washer_dryer - 13</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.89</td>\n",
       "      <td>100.00</td>\n",
       "      <td>95.74</td>\n",
       "      <td>97.83</td>\n",
       "      <td>98.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>washer_dryer - 14</td>\n",
       "      <td>3</td>\n",
       "      <td>360</td>\n",
       "      <td>0.02</td>\n",
       "      <td>97.99</td>\n",
       "      <td>100.00</td>\n",
       "      <td>55.56</td>\n",
       "      <td>71.43</td>\n",
       "      <td>85.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               carga  taxa_amostragem  janela  loss  acuracia  precisao  \\\n",
       "0    dish_washer - 9                2     720  0.05     95.33     20.00   \n",
       "1         fridge - 7                2    1080  0.00    100.00    100.00   \n",
       "2     microwave - 16                2     900  0.04     95.83     66.67   \n",
       "3  washer_dryer - 13                2      60  0.00     99.89    100.00   \n",
       "4  washer_dryer - 14                3     360  0.02     97.99    100.00   \n",
       "\n",
       "   recall      f1  f1_macro  \n",
       "0   25.00   22.22     59.91  \n",
       "1  100.00  100.00    100.00  \n",
       "2   33.33   44.44     71.14  \n",
       "3   95.74   97.83     98.88  \n",
       "4   55.56   71.43     85.19  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_melhores_taxas_janelas = pd.read_csv(os.path.join(caminho_dados, \"19\", \"melhores_taxa_janela_aparelhos.csv\"), index_col=0)\n",
    "df_melhores_taxas_janelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:02:37.773563Z",
     "start_time": "2021-03-31T00:02:37.757550Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# - Desenvolver módulo da metodologia na lib PyNILM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros de RP dos Aparelhos (estudo 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:02:39.007150Z",
     "start_time": "2021-03-31T00:02:38.885409Z"
    }
   },
   "outputs": [],
   "source": [
    "# Carregando arquivos de parametros, caso n estejam (kernel reiniciado)\n",
    "if not 'parametros_rp_aparelho' in locals():\n",
    "    with open(os.path.join(caminho_dados, \"18\", \"parametros_rp_aparelho.json\"),'r') as arquivo:\n",
    "        parametros_rp_aparelho = json.load(arquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambiente e Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:02:45.402263Z",
     "start_time": "2021-03-31T00:02:39.853122Z"
    }
   },
   "outputs": [],
   "source": [
    "# from PyNILM.dados.janelas import Janelas\n",
    "from PyNILM.dados.janelas import Janelas\n",
    "from PyNILM.avaliacao.metricas import *\n",
    "from PyNILM.avaliacao.graficos import *\n",
    "from PyNILM.avaliacao.analises import *\n",
    "\n",
    "from pyts.image import RecurrencePlot, GramianAngularField\n",
    "\n",
    "# Garantindo reprodutibilidade\n",
    "import random as rn\n",
    "\n",
    "# Constantes dos experimentos\n",
    "SEED = 33\n",
    "FRACAO_TESTE = 0.25\n",
    "EPOCAS = 100\n",
    "TAMANHO_LOTE = 32\n",
    "VERBOSIDADE = 2\n",
    "\n",
    "# Parametros RP (verificado empiricamente)\n",
    "PARAMETROS_RP = {\n",
    "    \"dimension\": 1,\n",
    "    \"time_delay\": 1,\n",
    "    \"threshold\": None,\n",
    "    \"percentage\": 10\n",
    "}\n",
    "TAMANHO_IMAGEM = (32,32)\n",
    "\n",
    "# Travar Seed's\n",
    "np.random.seed(SEED)\n",
    "rn.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "\n",
    "# Teste da classe\n",
    "janelas_treino = Janelas(\n",
    "    base=redd,\n",
    "    id_residencia=3,\n",
    "    inicio_intervalo='2011-04-16',\n",
    "    fim_intervalo='2011-05-16',\n",
    "    debug = False\n",
    ")\n",
    "\n",
    "janelas_teste = Janelas(\n",
    "    base=redd,\n",
    "    id_residencia=3,\n",
    "    inicio_intervalo='2011-05-17',\n",
    "    fim_intervalo='2011-05-30',\n",
    "    debug = False\n",
    ")\n",
    "# Habilitando/limitando utilização de GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:02:45.418246Z",
     "start_time": "2021-03-31T00:02:45.407276Z"
    }
   },
   "outputs": [],
   "source": [
    "def instancia_aparelho_residencia(aparelho, residencia, base = redd):\n",
    "    \"\"\"Função para coletar o id/instancia do aparelho na residencia,\n",
    "    permitindo executar os testes independente da residencia\"\"\"\n",
    "    instancia = []\n",
    "    #for e in base.buildings[residencia].elec.all_meters():\n",
    "    for e_i in range(1, len(janelas.base.buildings[residencia].elec.all_meters())):\n",
    "\n",
    "        # Selecionando canal/aparelho\n",
    "        e = janelas.base.buildings[residencia].elec[e_i]\n",
    "        \n",
    "        if not hasattr(e,'meters'):\n",
    "            if e.label().lower().replace(\" \",\"_\") == aparelho:\n",
    "                instancia.append( e.instance() )\n",
    "        else:\n",
    "            for e_ in e.meters:\n",
    "                if e_.label().lower().replace(\" \",\"_\") == aparelho:\n",
    "                    instancia.append( e_.instance() )\n",
    "    return instancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração RP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:02:45.541402Z",
     "start_time": "2021-03-31T00:02:45.420238Z"
    }
   },
   "outputs": [],
   "source": [
    "# Construindo o pipeline de dados\n",
    "# ----------\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Constante fundamentais\n",
    "TAMANHO_IMAGEM = (224,224,3) # Apenas 1 canal\n",
    "TIPO_DADOS = np.float32\n",
    "def serie_para_imagem(serie, params_rp = PARAMETROS_RP, tam_imagem=TAMANHO_IMAGEM, \n",
    "                      normalizar=False, padronizar=False):\n",
    "    \"\"\"\n",
    "    Funcao responsavel por gerar e tratar a imagem RP (baseado estudo #17).\n",
    "    \"\"\"\n",
    "    # Gerando imagem RP/redimensiona_prndo\n",
    "    imagem = RecurrencePlot(**params_rp).fit_transform([serie])[0]\n",
    "    imagem = cv2.resize(\n",
    "            imagem, \n",
    "            dsize=tam_imagem[:2], \n",
    "            interpolation=cv2.INTER_CUBIC\n",
    "        ).astype(TIPO_DADOS)\n",
    "    \n",
    "    if np.sum(imagem) > 0:\n",
    "        # Normalizar\n",
    "        if normalizar:\n",
    "                imagem = (imagem - imagem.min()) / (imagem.max() - imagem.min()) # MinMax (0,1)\n",
    "            #imagem = (imagem - imagem.mean()) / np.max([imagem.std(), 1e-4])\n",
    "\n",
    "    #     # centralizar\n",
    "    #     if centralizar:\n",
    "    #         imagem -= imagem.mean()\n",
    "\n",
    "        # Padronizar\n",
    "        elif padronizar:\n",
    "            imagem = (imagem - imagem.mean())/imagem.std()#tf.image.per_image_standardization(imagem).numpy()\n",
    "\n",
    "    # N canais\n",
    "    imagem = np.stack([imagem for i in range(tam_imagem[-1])],axis=-1).astype(TIPO_DADOS)     \n",
    "    \n",
    "    return imagem\n",
    "\n",
    "def preparar_amostras(X, y, params_rp=PARAMETROS_RP, tam_imagem=TAMANHO_IMAGEM, normalizar=False, padronizar=False):\n",
    "    X_imagem = np.empty((len(X), *TAMANHO_IMAGEM))\n",
    "    for i, x in tqdm_notebook(enumerate(X), total=len(X)):\n",
    "        X_imagem[i,] = serie_para_imagem(\n",
    "            x, \n",
    "            params_rp=PARAMETROS_RP, \n",
    "            tam_imagem=TAMANHO_IMAGEM,\n",
    "            normalizar=normalizar,\n",
    "            padronizar=padronizar,\n",
    "        )\n",
    "    return X_imagem, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T23:40:21.754487Z",
     "start_time": "2021-03-30T23:36:46.987920Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EXTRAÇÃO RP (BASE TREINO)...\n",
      "\n",
      "* Aparelho DISH_WASHER - 9:\n",
      "\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "   - Carregando dados (taxa=2, janela=720)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 395 amostras (96.8%)\n",
      "      - Classe `1`: 13 amostras (3.2%)\n",
      "\n",
      "* Convertendo séries para RPs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b199080b7a48dd97f17567bca03050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Persistindo dados...\n",
      "\n",
      "* Aparelho FRIDGE - 7:\n",
      "\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "   - Carregando dados (taxa=2, janela=1080)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `1`: 269 amostras (98.2%)\n",
      "      - Classe `0`: 5 amostras (1.8%)\n",
      "\n",
      "* Convertendo séries para RPs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb3a3181c494080ba84a4983ce8a49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Persistindo dados...\n",
      "\n",
      "* Aparelho MICROWAVE - 16:\n",
      "\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "   - Carregando dados (taxa=2, janela=900)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 306 amostras (93.9%)\n",
      "      - Classe `1`: 20 amostras (6.1%)\n",
      "\n",
      "* Convertendo séries para RPs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4ab50951524db483a0524899f48676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Persistindo dados...\n",
      "\n",
      "* Aparelho WASHER_DRYER - 13:\n",
      "\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "   - Carregando dados (taxa=2, janela=60)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 4643 amostras (96.0%)\n",
      "      - Classe `1`: 192 amostras (4.0%)\n",
      "\n",
      "* Convertendo séries para RPs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1607d4852f4a40f084f8693321cdf9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4835 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Persistindo dados...\n",
      "\n",
      "   - Carregando dados (taxa=2, janela=60)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 4582 amostras (94.8%)\n",
      "      - Classe `1`: 253 amostras (5.2%)\n",
      "\n",
      "* Convertendo séries para RPs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d3cbe48f074f9ca7e55a433f74cbee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4835 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Persistindo dados...\n",
      "\n",
      "* Aparelho WASHER_DRYER - 14:\n",
      "\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "   - Carregando dados (taxa=3, janela=360)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 514 amostras (94.8%)\n",
      "      - Classe `1`: 28 amostras (5.2%)\n",
      "\n",
      "* Convertendo séries para RPs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf6961724084753a9ebeb515e357879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Persistindo dados...\n",
      "\n",
      "   - Carregando dados (taxa=3, janela=360)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 508 amostras (93.7%)\n",
      "      - Classe `1`: 34 amostras (6.3%)\n",
      "\n",
      "* Convertendo séries para RPs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc5d7d2ba384c19b944fffbb071d9eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Persistindo dados...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rqa = []\n",
    "\n",
    "janelas = janelas_treino\n",
    "\n",
    "print(\"# EXTRAÇÃO RP (BASE TREINO)...\\n\")\n",
    "\n",
    "for rotulo_aparelho in df_melhores_taxas_janelas.loc[\n",
    "    df_melhores_taxas_janelas[\"carga\"].isin(\n",
    "        ['dish_washer - 9','fridge - 7','microwave - 16','washer_dryer - 13',\n",
    "         'washer_dryer - 14']),\n",
    "    : ][\"carga\"].values:\n",
    "    \n",
    "    print(f\"* Aparelho {rotulo_aparelho.upper()}:\")\n",
    "    print()\n",
    "    \n",
    "    # Informacoes da carga selecionada\n",
    "    CARGA = rotulo_aparelho.split(\" - \")[0]\n",
    "    #INSTANCIA = int(rotulo_aparelho.split(\" - \")[1])\n",
    "\n",
    "    config_aparelho = df_melhores_taxas_janelas[\n",
    "        df_melhores_taxas_janelas[\"carga\"]==rotulo_aparelho\n",
    "    ].to_dict(\"records\")[0]\n",
    "    TAXA = config_aparelho[\"taxa_amostragem\"]\n",
    "    TAMANHO_JANELA = config_aparelho[\"janela\"]\n",
    "    CONFIG_RP_APARELHO = PARAMETROS_RP\n",
    "    \n",
    "    # Percorrer instancias do aparelho na residencia\n",
    "    for INSTANCIA in instancia_aparelho_residencia(CARGA, RESIDENCIA, base = redd):\n",
    "        \n",
    "        # Extrair series divididas em janelas para cada medidor\n",
    "        print(\"   - Carregando dados (taxa={:.0f}, janela={:.0f})...\".format(\n",
    "            TAXA, TAMANHO_JANELA\n",
    "        ))\n",
    "        X, y = carregar_dados_aparelho(\n",
    "            janelas=janelas,\n",
    "            instancia=INSTANCIA,\n",
    "            aparelho=CARGA,\n",
    "            tamanho_janela=TAMANHO_JANELA,\n",
    "            taxa=TAXA,\n",
    "            eliminar_janelas_vazias=True\n",
    "        )\n",
    "        print()\n",
    "        \n",
    "        print(\"   - Detalhes da amostragem (lotes):\")\n",
    "        print(\"   ---\")\n",
    "        for item in Counter(y).items():\n",
    "            print(f\"      - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y)*100,1)}%)\" )\n",
    "        print()\n",
    "        \n",
    "        print(\"* Convertendo séries para RPs...\")\n",
    "        #rqa.extend( preparar_amostras(X, y, rotulo_aparelho) )\n",
    "        X, y = preparar_amostras(\n",
    "            X, y, \n",
    "            params_rp=PARAMETROS_RP,\n",
    "            tam_imagem=TAMANHO_IMAGEM,\n",
    "            normalizar=False # config. estudo 17 = False\n",
    "        )\n",
    "        #print(X.shape)\n",
    "        \n",
    "        print(\"* Persistindo dados...\")\n",
    "        np.save(os.path.join(\n",
    "            caminho_dados_notebook, \"treino\",\n",
    "            rotulo_aparelho.lower().replace(\" \", \"_\"),\n",
    "        )+\"_X.npy\", X) \n",
    "        np.save(os.path.join(\n",
    "            caminho_dados_notebook, \"treino\",\n",
    "            rotulo_aparelho.lower().replace(\" \", \"_\"),\n",
    "        )+\"_y.npy\", y) \n",
    "        print()\n",
    "        #rotulo_aparelho\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T23:43:52.442656Z",
     "start_time": "2021-03-30T23:40:21.762473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EXTRAÇÃO RP (BASE TESTE)...\n",
      "\n",
      "* Aparelho DISH_WASHER - 9:\n",
      "\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "   - Carregando dados (taxa=2, janela=720)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 395 amostras (96.8%)\n",
      "      - Classe `1`: 13 amostras (3.2%)\n",
      "\n",
      "* Convertendo séries para RPs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c86b771eb24bbd939061a1ea91c02f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Persistindo dados...\n",
      "\n",
      "* Aparelho FRIDGE - 7:\n",
      "\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "   - Carregando dados (taxa=2, janela=1080)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `1`: 269 amostras (98.2%)\n",
      "      - Classe `0`: 5 amostras (1.8%)\n",
      "\n",
      "* Convertendo séries para RPs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02e24c9ab98464caadd5d1a565d8f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Persistindo dados...\n",
      "\n",
      "* Aparelho MICROWAVE - 16:\n",
      "\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "   - Carregando dados (taxa=2, janela=900)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 306 amostras (93.9%)\n",
      "      - Classe `1`: 20 amostras (6.1%)\n",
      "\n",
      "* Convertendo séries para RPs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5efb1c1637c4d8ab3b5c3cffa62062d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Persistindo dados...\n",
      "\n",
      "* Aparelho WASHER_DRYER - 13:\n",
      "\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "   - Carregando dados (taxa=2, janela=60)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 4643 amostras (96.0%)\n",
      "      - Classe `1`: 192 amostras (4.0%)\n",
      "\n",
      "* Convertendo séries para RPs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4faea201eb7b41e89a038a23cb1fc8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4835 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Persistindo dados...\n",
      "\n",
      "   - Carregando dados (taxa=2, janela=60)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 4582 amostras (94.8%)\n",
      "      - Classe `1`: 253 amostras (5.2%)\n",
      "\n",
      "* Convertendo séries para RPs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8731c5a710f4c309b22c7f5bb5aea72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4835 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Persistindo dados...\n",
      "\n",
      "* Aparelho WASHER_DRYER - 14:\n",
      "\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "   - Carregando dados (taxa=3, janela=360)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 514 amostras (94.8%)\n",
      "      - Classe `1`: 28 amostras (5.2%)\n",
      "\n",
      "* Convertendo séries para RPs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0a7ae9c1d24c5ea4aeb6de333dde91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Persistindo dados...\n",
      "\n",
      "   - Carregando dados (taxa=3, janela=360)...\n",
      "Meter 13 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "Meter 14 is in a nested meter group. Retrieving just the ElecMeter.\n",
      "\n",
      "\n",
      "   - Detalhes da amostragem (lotes):\n",
      "   ---\n",
      "      - Classe `0`: 508 amostras (93.7%)\n",
      "      - Classe `1`: 34 amostras (6.3%)\n",
      "\n",
      "* Convertendo séries para RPs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b536b8ac67804886827cbb2be2317405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Persistindo dados...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rqa = []\n",
    "\n",
    "janelas = janelas_teste\n",
    "\n",
    "print(\"# EXTRAÇÃO RP (BASE TESTE)...\\n\")\n",
    "\n",
    "for rotulo_aparelho in df_melhores_taxas_janelas.loc[\n",
    "    df_melhores_taxas_janelas[\"carga\"].isin(\n",
    "        ['dish_washer - 9','fridge - 7','microwave - 16','washer_dryer - 13',\n",
    "         'washer_dryer - 14']),\n",
    "    : ][\"carga\"].values:\n",
    "    \n",
    "    print(f\"* Aparelho {rotulo_aparelho.upper()}:\")\n",
    "    print()\n",
    "    \n",
    "    # Informacoes da carga selecionada\n",
    "    CARGA = rotulo_aparelho.split(\" - \")[0]\n",
    "    #INSTANCIA = int(rotulo_aparelho.split(\" - \")[1])\n",
    "\n",
    "    config_aparelho = df_melhores_taxas_janelas[\n",
    "        df_melhores_taxas_janelas[\"carga\"]==rotulo_aparelho\n",
    "    ].to_dict(\"records\")[0]\n",
    "    TAXA = config_aparelho[\"taxa_amostragem\"]\n",
    "    TAMANHO_JANELA = config_aparelho[\"janela\"]\n",
    "    CONFIG_RP_APARELHO = PARAMETROS_RP\n",
    "    \n",
    "    # Percorrer instancias do aparelho na residencia\n",
    "    for INSTANCIA in instancia_aparelho_residencia(CARGA, RESIDENCIA, base = redd):\n",
    "        \n",
    "        # Extrair series divididas em janelas para cada medidor\n",
    "        print(\"   - Carregando dados (taxa={:.0f}, janela={:.0f})...\".format(\n",
    "            TAXA, TAMANHO_JANELA\n",
    "        ))\n",
    "        X, y = carregar_dados_aparelho(\n",
    "            janelas=janelas,\n",
    "            instancia=INSTANCIA,\n",
    "            aparelho=CARGA,\n",
    "            tamanho_janela=TAMANHO_JANELA,\n",
    "            taxa=TAXA,\n",
    "            eliminar_janelas_vazias=True\n",
    "        )\n",
    "        print()\n",
    "        \n",
    "        print(\"   - Detalhes da amostragem (lotes):\")\n",
    "        print(\"   ---\")\n",
    "        for item in Counter(y).items():\n",
    "            print(f\"      - Classe `{item[0]}`: {item[1]} amostras ({round(item[1]/len(y)*100,1)}%)\" )\n",
    "        print()\n",
    "        \n",
    "        print(\"* Convertendo séries para RPs...\")\n",
    "        #rqa.extend( preparar_amostras(X, y, rotulo_aparelho) )\n",
    "        X, y = preparar_amostras(\n",
    "            X, y, \n",
    "            params_rp=PARAMETROS_RP,\n",
    "            tam_imagem=TAMANHO_IMAGEM,\n",
    "            normalizar=False # config. estudo 17 = False\n",
    "        )\n",
    "        #print(X.shape)\n",
    "        \n",
    "        print(\"* Persistindo dados...\")\n",
    "        np.save(os.path.join(\n",
    "            caminho_dados_notebook, \"teste\",\n",
    "            rotulo_aparelho.lower().replace(\" \", \"_\"),\n",
    "        )+\"_X.npy\", X) \n",
    "        np.save(os.path.join(\n",
    "            caminho_dados_notebook, \"teste\",\n",
    "            rotulo_aparelho.lower().replace(\" \", \"_\"),\n",
    "        )+\"_y.npy\", y) \n",
    "        print()\n",
    "        #rotulo_aparelho\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração de Atributos (Deep Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:02:48.545535Z",
     "start_time": "2021-03-31T00:02:48.486636Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "\n",
    "resultados = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:02:49.960443Z",
     "start_time": "2021-03-31T00:02:49.262613Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import applications as transfer_learning\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def extrair_atributos_dl(X, modelo, preprocessamento):\n",
    "    X = preprocessamento(X)\n",
    "    atributos = modelo.predict(X)\n",
    "    return atributos\n",
    "\n",
    "# Exemplo:\n",
    "modelo_extrator = transfer_learning.vgg16.VGG16(\n",
    "            weights='imagenet', \n",
    "            include_top=False,\n",
    "            pooling='avg'\n",
    "        )\n",
    "preprocess_extrator = transfer_learning.vgg16.preprocess_input\n",
    "# extrair_atributos_dl(\n",
    "#     X, \n",
    "#     modelo=modelo_extrator,\n",
    "#     preprocessamento=preprocess_extrator\n",
    "# ).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:31:52.441801Z",
     "start_time": "2021-03-31T00:02:51.546524Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Appliance `dish_washer - 9`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98       395\n",
      "         1.0       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.97       408\n",
      "   macro avg       0.48      0.50      0.49       408\n",
      "weighted avg       0.94      0.97      0.95       408\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[395   0]\n",
      " [ 13   0]]\n",
      "\n",
      "* Appliance `fridge - 7`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.98      1.00      0.99       269\n",
      "\n",
      "    accuracy                           0.98       274\n",
      "   macro avg       0.49      0.50      0.50       274\n",
      "weighted avg       0.96      0.98      0.97       274\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[  0   5]\n",
      " [  0 269]]\n",
      "\n",
      "* Appliance `microwave - 16`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98       306\n",
      "         1.0       0.90      0.45      0.60        20\n",
      "\n",
      "    accuracy                           0.96       326\n",
      "   macro avg       0.93      0.72      0.79       326\n",
      "weighted avg       0.96      0.96      0.96       326\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[305   1]\n",
      " [ 11   9]]\n",
      "\n",
      "* Appliance `washer_dryer - 13`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      4582\n",
      "         1.0       0.98      0.73      0.83       253\n",
      "\n",
      "    accuracy                           0.98      4835\n",
      "   macro avg       0.98      0.86      0.91      4835\n",
      "weighted avg       0.98      0.98      0.98      4835\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[4578    4]\n",
      " [  69  184]]\n",
      "\n",
      "* Appliance `washer_dryer - 14`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99       508\n",
      "         1.0       0.96      0.79      0.87        34\n",
      "\n",
      "    accuracy                           0.99       542\n",
      "   macro avg       0.98      0.90      0.93       542\n",
      "weighted avg       0.98      0.99      0.98       542\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[507   1]\n",
      " [  7  27]]\n",
      "\n",
      "############################## FINAL MODEL RESULTS ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dish_washer - 9</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.968137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.968171</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.491898</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">fridge - 7</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.981752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.982011</td>\n",
       "      <td>0.018967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.745420</td>\n",
       "      <td>0.268351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">microwave - 16</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.993865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993865</td>\n",
       "      <td>0.993865</td>\n",
       "      <td>0.972056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.972056</td>\n",
       "      <td>0.972056</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.963258</td>\n",
       "      <td>0.019375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.747087</td>\n",
       "      <td>0.189375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.723333</td>\n",
       "      <td>0.181761</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">washer_dryer - 13</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.985729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985729</td>\n",
       "      <td>0.985729</td>\n",
       "      <td>0.917316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.917316</td>\n",
       "      <td>0.917316</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.984902</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>0.991718</td>\n",
       "      <td>0.975155</td>\n",
       "      <td>0.911358</td>\n",
       "      <td>0.036825</td>\n",
       "      <td>0.956155</td>\n",
       "      <td>0.835640</td>\n",
       "      <td>0.863410</td>\n",
       "      <td>0.052259</td>\n",
       "      <td>0.938908</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">washer_dryer - 14</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.987085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987085</td>\n",
       "      <td>0.987085</td>\n",
       "      <td>0.939202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.939202</td>\n",
       "      <td>0.939202</td>\n",
       "      <td>0.897059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.897059</td>\n",
       "      <td>0.897059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.985219</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.913418</td>\n",
       "      <td>0.100730</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.740385</td>\n",
       "      <td>0.886520</td>\n",
       "      <td>0.135286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               acc                                      f1  \\\n",
       "                              mean       std       max       min      mean   \n",
       "appliance         base                                                       \n",
       "dish_washer - 9   teste   0.968137       NaN  0.968137  0.968137  0.491905   \n",
       "                  treino  0.968171  0.011700  0.975610  0.951220  0.491898   \n",
       "fridge - 7        teste   0.981752       NaN  0.981752  0.981752  0.495396   \n",
       "                  treino  0.982011  0.018967  1.000000  0.962963  0.745420   \n",
       "microwave - 16    teste   0.993865       NaN  0.993865  0.993865  0.972056   \n",
       "                  treino  0.963258  0.019375  1.000000  0.937500  0.747087   \n",
       "washer_dryer - 13 teste   0.985729       NaN  0.985729  0.985729  0.917316   \n",
       "                  treino  0.984902  0.005164  0.991718  0.975155  0.911358   \n",
       "washer_dryer - 14 teste   0.987085       NaN  0.987085  0.987085  0.939202   \n",
       "                  treino  0.985219  0.014599  1.000000  0.962963  0.913418   \n",
       "\n",
       "                                                             auc            \\\n",
       "                               std       max       min      mean       std   \n",
       "appliance         base                                                       \n",
       "dish_washer - 9   teste        NaN  0.491905  0.491905  0.500000       NaN   \n",
       "                  treino  0.003035  0.493827  0.487500  0.500000  0.000000   \n",
       "fridge - 7        teste        NaN  0.495396  0.495396  0.500000       NaN   \n",
       "                  treino  0.268351  1.000000  0.490566  0.500000  0.000000   \n",
       "microwave - 16    teste        NaN  0.972056  0.972056  0.950000       NaN   \n",
       "                  treino  0.189375  1.000000  0.483871  0.723333  0.181761   \n",
       "washer_dryer - 13 teste        NaN  0.917316  0.917316  0.863636       NaN   \n",
       "                  treino  0.036825  0.956155  0.835640  0.863410  0.052259   \n",
       "washer_dryer - 14 teste        NaN  0.939202  0.939202  0.897059       NaN   \n",
       "                  treino  0.100730  1.000000  0.740385  0.886520  0.135286   \n",
       "\n",
       "                                              \n",
       "                               max       min  \n",
       "appliance         base                        \n",
       "dish_washer - 9   teste   0.500000  0.500000  \n",
       "                  treino  0.500000  0.500000  \n",
       "fridge - 7        teste   0.500000  0.500000  \n",
       "                  treino  0.500000  0.500000  \n",
       "microwave - 16    teste   0.950000  0.950000  \n",
       "                  treino  1.000000  0.500000  \n",
       "washer_dryer - 13 teste   0.863636  0.863636  \n",
       "                  treino  0.938908  0.760000  \n",
       "washer_dryer - 14 teste   0.897059  0.897059  \n",
       "                  treino  1.000000  0.666667  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \"base\": []\n",
    "}\n",
    "\n",
    "for a in df_melhores_taxas_janelas.loc[\n",
    "    df_melhores_taxas_janelas[\"carga\"].isin(\n",
    "        ['dish_washer - 9','fridge - 7','microwave - 16','washer_dryer - 13',\n",
    "         'washer_dryer - 14']),\n",
    "    : ][\"carga\"].values:\n",
    "    \n",
    "    \n",
    "    print(f\"* Appliance `{a}`...\\n\")\n",
    "    \n",
    "    # Carregando dados (treino)\n",
    "    X = np.load(\n",
    "        os.path.join(\n",
    "            caminho_dados_notebook, \"treino\", \n",
    "            a.lower().replace(\" \", \"_\"),\n",
    "        )+\"_X.npy\"\n",
    "    ).astype(TIPO_DADOS)\n",
    "    y = np.load(\n",
    "        os.path.join(\n",
    "            caminho_dados_notebook, \"treino\",\n",
    "            a.lower().replace(\" \", \"_\"),\n",
    "        )+\"_y.npy\"\n",
    "    ).astype(TIPO_DADOS)\n",
    "    \n",
    "    # Extrair atributos usando Deep/Tranfer Learning\n",
    "    X = extrair_atributos_dl(\n",
    "        X, \n",
    "        modelo=modelo_extrator,\n",
    "        preprocessamento=preprocess_extrator\n",
    "    )\n",
    "    \n",
    "    y_true, y_pred  = [], []\n",
    "    \n",
    "    \n",
    "    print(\"   - Evaluation model (CV - 10 folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in enumerate(skf.split(X, y)):\n",
    "\n",
    "        # Preparando lotes\n",
    "        X_treino, X_teste = X[idx_treino], X[idx_teste]\n",
    "        y_treino, y_teste = y[idx_treino], y[idx_teste]\n",
    "        \n",
    "        # Treinando modelo\n",
    "        modelo = SVC(kernel='rbf', random_state=SEED)\n",
    "        modelo.fit(X_treino, y_treino)\n",
    "        \n",
    "        # Prevendo conjunto de teste\n",
    "        y_hat = modelo.predict(X_teste)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(a)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"treino\")\n",
    "        \n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true.extend(y_teste)\n",
    "        y_pred.extend(y_hat)\n",
    "     \n",
    "    \n",
    "    # Carregando dados (teste)\n",
    "    X_teste = np.load(\n",
    "        os.path.join(\n",
    "            caminho_dados_notebook, \"teste\", \n",
    "            a.lower().replace(\" \", \"_\"),\n",
    "        )+\"_X.npy\"\n",
    "    ).astype(TIPO_DADOS)\n",
    "    y_teste = np.load(\n",
    "        os.path.join(\n",
    "            caminho_dados_notebook, \"teste\",\n",
    "            a.lower().replace(\" \", \"_\"),\n",
    "        )+\"_y.npy\"\n",
    "    ).astype(TIPO_DADOS)\n",
    "    \n",
    "    # Extrair atributos usando Deep/Tranfer Learning\n",
    "    X_teste = extrair_atributos_dl(\n",
    "        X_teste, \n",
    "        modelo=modelo_extrator,\n",
    "        preprocessamento=preprocess_extrator\n",
    "    )\n",
    "    \n",
    "    # Treinando modelo\n",
    "    modelo = SVC(kernel='rbf', random_state=SEED)\n",
    "    modelo.fit(X, y)\n",
    "\n",
    "    # Prevendo conjunto de teste\n",
    "    y_hat = modelo.predict(X_teste)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(a)\n",
    "    resultados_modelo[\"fold\"].append(0)\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"teste\")\n",
    "    \n",
    "    print()\n",
    "    print(\"   - Final Results:\")\n",
    "    print(\"   ---\")\n",
    "    print()\n",
    "\n",
    "    print(\"      -> Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"      -> Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "# Consolidating DataFrame\n",
    "df_resultados_svm = pd.DataFrame(resultados_modelo)\n",
    "df_resultados_svm.to_excel(os.path.join(caminho_dados_notebook, \"df_resultados_svm.xlsx\"))\n",
    "    \n",
    "print(\"############################## FINAL MODEL RESULTS ##############################\")\n",
    "display(df_resultados_svm.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T19:59:41.720698Z",
     "start_time": "2020-08-31T19:59:41.680673Z"
    }
   },
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T01:01:51.383296Z",
     "start_time": "2021-03-31T00:31:52.477665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Appliance `dish_washer - 9`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "[21:32:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:32:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:32:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:32:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:32:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:32:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:32:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:32:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:32:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:32:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:33:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98       395\n",
      "         1.0       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.97       408\n",
      "   macro avg       0.48      0.50      0.49       408\n",
      "weighted avg       0.94      0.97      0.95       408\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[395   0]\n",
      " [ 13   0]]\n",
      "\n",
      "* Appliance `fridge - 7`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "[21:34:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:34:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:34:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:34:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:34:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:34:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:34:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:34:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:34:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:34:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:35:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.98      0.99      0.99       269\n",
      "\n",
      "    accuracy                           0.97       274\n",
      "   macro avg       0.49      0.50      0.49       274\n",
      "weighted avg       0.96      0.97      0.97       274\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[  0   5]\n",
      " [  2 267]]\n",
      "\n",
      "* Appliance `microwave - 16`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "[21:35:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:35:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:35:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:35:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:35:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:35:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:35:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:35:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:35:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:35:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:36:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98       306\n",
      "         1.0       0.63      0.60      0.62        20\n",
      "\n",
      "    accuracy                           0.95       326\n",
      "   macro avg       0.80      0.79      0.80       326\n",
      "weighted avg       0.95      0.95      0.95       326\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[299   7]\n",
      " [  8  12]]\n",
      "\n",
      "* Appliance `washer_dryer - 13`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "[21:47:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:47:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:47:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:47:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:47:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:47:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:47:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:47:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:48:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:48:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      4582\n",
      "         1.0       0.99      0.72      0.84       253\n",
      "\n",
      "    accuracy                           0.99      4835\n",
      "   macro avg       0.99      0.86      0.91      4835\n",
      "weighted avg       0.99      0.99      0.98      4835\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[4580    2]\n",
      " [  70  183]]\n",
      "\n",
      "* Appliance `washer_dryer - 14`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "[22:00:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:00:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99       508\n",
      "         1.0       1.00      0.68      0.81        34\n",
      "\n",
      "    accuracy                           0.98       542\n",
      "   macro avg       0.99      0.84      0.90       542\n",
      "weighted avg       0.98      0.98      0.98       542\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[508   0]\n",
      " [ 11  23]]\n",
      "\n",
      "############################## FINAL MODEL RESULTS ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dish_washer - 9</th>\n",
       "      <th>teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.968171</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.491898</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">fridge - 7</th>\n",
       "      <th>teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.034957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.743422</td>\n",
       "      <td>0.270524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.496154</td>\n",
       "      <td>0.012163</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">microwave - 16</th>\n",
       "      <th>teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.953977</td>\n",
       "      <td>0.021591</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.761079</td>\n",
       "      <td>0.158922</td>\n",
       "      <td>0.891803</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.788495</td>\n",
       "      <td>0.189077</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">washer_dryer - 13</th>\n",
       "      <th>teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.985109</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.991718</td>\n",
       "      <td>0.975155</td>\n",
       "      <td>0.912183</td>\n",
       "      <td>0.036527</td>\n",
       "      <td>0.954348</td>\n",
       "      <td>0.835640</td>\n",
       "      <td>0.861628</td>\n",
       "      <td>0.049488</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">washer_dryer - 14</th>\n",
       "      <th>teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.979630</td>\n",
       "      <td>0.018415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.862554</td>\n",
       "      <td>0.130776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.740385</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.166725</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               acc                                      f1  \\\n",
       "                              mean       std       max       min      mean   \n",
       "appliance         base                                                       \n",
       "dish_washer - 9   teste   1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "                  treino  0.968171  0.011700  0.975610  0.951220  0.491898   \n",
       "fridge - 7        teste   1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "                  treino  0.974603  0.034957  1.000000  0.888889  0.743422   \n",
       "microwave - 16    teste   1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "                  treino  0.953977  0.021591  0.969697  0.909091  0.761079   \n",
       "washer_dryer - 13 teste   1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "                  treino  0.985109  0.005142  0.991718  0.975155  0.912183   \n",
       "washer_dryer - 14 teste   1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "                  treino  0.979630  0.018415  1.000000  0.962963  0.862554   \n",
       "\n",
       "                                                             auc            \\\n",
       "                               std       max       min      mean       std   \n",
       "appliance         base                                                       \n",
       "dish_washer - 9   teste        NaN  1.000000  1.000000  1.000000       NaN   \n",
       "                  treino  0.003035  0.493827  0.487500  0.500000  0.000000   \n",
       "fridge - 7        teste        NaN  1.000000  1.000000  1.000000       NaN   \n",
       "                  treino  0.270524  1.000000  0.470588  0.496154  0.012163   \n",
       "microwave - 16    teste        NaN  1.000000  1.000000  1.000000       NaN   \n",
       "                  treino  0.158922  0.891803  0.483871  0.788495  0.189077   \n",
       "washer_dryer - 13 teste        NaN  1.000000  1.000000  1.000000       NaN   \n",
       "                  treino  0.036527  0.954348  0.835640  0.861628  0.049488   \n",
       "washer_dryer - 14 teste        NaN  1.000000  1.000000  1.000000       NaN   \n",
       "                  treino  0.130776  1.000000  0.740385  0.820833  0.166725   \n",
       "\n",
       "                                              \n",
       "                               max       min  \n",
       "appliance         base                        \n",
       "dish_washer - 9   teste   1.000000  1.000000  \n",
       "                  treino  0.500000  0.500000  \n",
       "fridge - 7        teste   1.000000  1.000000  \n",
       "                  treino  0.500000  0.461538  \n",
       "microwave - 16    teste   1.000000  1.000000  \n",
       "                  treino  0.983871  0.500000  \n",
       "washer_dryer - 13 teste   1.000000  1.000000  \n",
       "                  treino  0.920000  0.760000  \n",
       "washer_dryer - 14 teste   1.000000  1.000000  \n",
       "                  treino  1.000000  0.666667  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \"base\": []\n",
    "}\n",
    "\n",
    "for a in df_melhores_taxas_janelas.loc[\n",
    "    df_melhores_taxas_janelas[\"carga\"].isin(\n",
    "        ['dish_washer - 9','fridge - 7','microwave - 16','washer_dryer - 13',\n",
    "         'washer_dryer - 14']),\n",
    "    : ][\"carga\"].values:\n",
    "    \n",
    "    \n",
    "    print(f\"* Appliance `{a}`...\\n\")\n",
    "    \n",
    "    # Carregando dados (treino)\n",
    "    X = np.load(\n",
    "        os.path.join(\n",
    "            caminho_dados_notebook, \"treino\", \n",
    "            a.lower().replace(\" \", \"_\"),\n",
    "        )+\"_X.npy\"\n",
    "    ).astype(TIPO_DADOS)\n",
    "    y = np.load(\n",
    "        os.path.join(\n",
    "            caminho_dados_notebook, \"treino\",\n",
    "            a.lower().replace(\" \", \"_\"),\n",
    "        )+\"_y.npy\"\n",
    "    ).astype(TIPO_DADOS)\n",
    "    \n",
    "    # Extrair atributos usando Deep/Tranfer Learning\n",
    "    X = extrair_atributos_dl(\n",
    "        X, \n",
    "        modelo=modelo_extrator,\n",
    "        preprocessamento=preprocess_extrator\n",
    "    )\n",
    "    \n",
    "    y_true, y_pred  = [], []\n",
    "    \n",
    "    \n",
    "    print(\"   - Evaluation model (CV - 10 folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in enumerate(skf.split(X, y)):\n",
    "\n",
    "        # Preparando lotes\n",
    "        X_treino, X_teste = X[idx_treino], X[idx_teste]\n",
    "        y_treino, y_teste = y[idx_treino], y[idx_teste]\n",
    "        \n",
    "        # Treinando modelo\n",
    "        modelo = XGBClassifier(random_state=SEED, n_jobs=4)\n",
    "        modelo.fit(X_treino, y_treino)\n",
    "        \n",
    "        # Prevendo conjunto de teste\n",
    "        y_hat = modelo.predict(X_teste)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(a)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"treino\")\n",
    "        \n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true.extend(y_teste)\n",
    "        y_pred.extend(y_hat)\n",
    "     \n",
    "    \n",
    "    # Carregando dados (teste)\n",
    "    X_teste = np.load(\n",
    "        os.path.join(\n",
    "            caminho_dados_notebook, \"teste\", \n",
    "            a.lower().replace(\" \", \"_\"),\n",
    "        )+\"_X.npy\"\n",
    "    ).astype(TIPO_DADOS)\n",
    "    y_teste = np.load(\n",
    "        os.path.join(\n",
    "            caminho_dados_notebook, \"teste\",\n",
    "            a.lower().replace(\" \", \"_\"),\n",
    "        )+\"_y.npy\"\n",
    "    ).astype(TIPO_DADOS)\n",
    "    \n",
    "    # Extrair atributos usando Deep/Tranfer Learning\n",
    "    X_teste = extrair_atributos_dl(\n",
    "        X_teste, \n",
    "        modelo=modelo_extrator,\n",
    "        preprocessamento=preprocess_extrator\n",
    "    )\n",
    "    \n",
    "    # Treinando modelo\n",
    "    modelo = XGBClassifier(random_state=SEED, n_jobs=4)\n",
    "    modelo.fit(X, y)\n",
    "\n",
    "    # Prevendo conjunto de teste\n",
    "    y_hat = modelo.predict(X_teste)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(a)\n",
    "    resultados_modelo[\"fold\"].append(0)\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"teste\")\n",
    "    \n",
    "    print()\n",
    "    print(\"   - Final Results:\")\n",
    "    print(\"   ---\")\n",
    "    print()\n",
    "\n",
    "    print(\"      -> Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"      -> Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "# Consolidating DataFrame\n",
    "df_resultados_xgboost = pd.DataFrame(resultados_modelo)\n",
    "df_resultados_xgboost.to_excel(os.path.join(caminho_dados_notebook, \"df_resultados_xgboost.xlsx\"))\n",
    "    \n",
    "print(\"############################## FINAL MODEL RESULTS ##############################\")\n",
    "display(df_resultados_xgboost.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T11:33:41.769727Z",
     "start_time": "2021-03-31T11:33:41.720801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dish_washer - 9</th>\n",
       "      <th>teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.968171</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.491898</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">fridge - 7</th>\n",
       "      <th>teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.034957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.743422</td>\n",
       "      <td>0.270524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.496154</td>\n",
       "      <td>0.012163</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">microwave - 16</th>\n",
       "      <th>teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.953977</td>\n",
       "      <td>0.021591</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.761079</td>\n",
       "      <td>0.158922</td>\n",
       "      <td>0.891803</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.788495</td>\n",
       "      <td>0.189077</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">washer_dryer - 13</th>\n",
       "      <th>teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.985109</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.991718</td>\n",
       "      <td>0.975155</td>\n",
       "      <td>0.912183</td>\n",
       "      <td>0.036527</td>\n",
       "      <td>0.954348</td>\n",
       "      <td>0.835640</td>\n",
       "      <td>0.861628</td>\n",
       "      <td>0.049488</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">washer_dryer - 14</th>\n",
       "      <th>teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.979630</td>\n",
       "      <td>0.018415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.862554</td>\n",
       "      <td>0.130776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.740385</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.166725</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               acc                                      f1  \\\n",
       "                              mean       std       max       min      mean   \n",
       "appliance         base                                                       \n",
       "dish_washer - 9   teste   1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "                  treino  0.968171  0.011700  0.975610  0.951220  0.491898   \n",
       "fridge - 7        teste   1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "                  treino  0.974603  0.034957  1.000000  0.888889  0.743422   \n",
       "microwave - 16    teste   1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "                  treino  0.953977  0.021591  0.969697  0.909091  0.761079   \n",
       "washer_dryer - 13 teste   1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "                  treino  0.985109  0.005142  0.991718  0.975155  0.912183   \n",
       "washer_dryer - 14 teste   1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "                  treino  0.979630  0.018415  1.000000  0.962963  0.862554   \n",
       "\n",
       "                                                             auc            \\\n",
       "                               std       max       min      mean       std   \n",
       "appliance         base                                                       \n",
       "dish_washer - 9   teste        NaN  1.000000  1.000000  1.000000       NaN   \n",
       "                  treino  0.003035  0.493827  0.487500  0.500000  0.000000   \n",
       "fridge - 7        teste        NaN  1.000000  1.000000  1.000000       NaN   \n",
       "                  treino  0.270524  1.000000  0.470588  0.496154  0.012163   \n",
       "microwave - 16    teste        NaN  1.000000  1.000000  1.000000       NaN   \n",
       "                  treino  0.158922  0.891803  0.483871  0.788495  0.189077   \n",
       "washer_dryer - 13 teste        NaN  1.000000  1.000000  1.000000       NaN   \n",
       "                  treino  0.036527  0.954348  0.835640  0.861628  0.049488   \n",
       "washer_dryer - 14 teste        NaN  1.000000  1.000000  1.000000       NaN   \n",
       "                  treino  0.130776  1.000000  0.740385  0.820833  0.166725   \n",
       "\n",
       "                                              \n",
       "                               max       min  \n",
       "appliance         base                        \n",
       "dish_washer - 9   teste   1.000000  1.000000  \n",
       "                  treino  0.500000  0.500000  \n",
       "fridge - 7        teste   1.000000  1.000000  \n",
       "                  treino  0.500000  0.461538  \n",
       "microwave - 16    teste   1.000000  1.000000  \n",
       "                  treino  0.983871  0.500000  \n",
       "washer_dryer - 13 teste   1.000000  1.000000  \n",
       "                  treino  0.920000  0.760000  \n",
       "washer_dryer - 14 teste   1.000000  1.000000  \n",
       "                  treino  1.000000  0.666667  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:02:06.492208Z",
     "start_time": "2021-03-30T23:55:02.280Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T01:01:51.399213Z",
     "start_time": "2021-03-31T01:01:51.388242Z"
    }
   },
   "outputs": [],
   "source": [
    "# resultados_modelo = {\n",
    "#     \"appliance\": [], \"fold\": [],\n",
    "#     \"acc\": [], \"f1\": [], \"auc\": []\n",
    "# }\n",
    "\n",
    "# for a in df_melhores_taxas_janelas.loc[\n",
    "#     df_melhores_taxas_janelas[\"carga\"].isin(\n",
    "#         ['dish_washer - 9','fridge - 7','microwave - 16','washer_dryer - 13',\n",
    "#          'washer_dryer - 14']),\n",
    "#     : ][\"carga\"].values:\n",
    "    \n",
    "    \n",
    "#     print(f\"* Appliance `{a}`...\\n\")\n",
    "    \n",
    "#     # Carregando dados\n",
    "#     X = np.load(\n",
    "#         os.path.join(\n",
    "#             caminho_dados_notebook, \n",
    "#             a.lower().replace(\" \", \"_\"),\n",
    "#         )+\"_X.npy\"\n",
    "#     ).astype(TIPO_DADOS)\n",
    "#     y = np.load(\n",
    "#         os.path.join(\n",
    "#             caminho_dados_notebook, \n",
    "#             a.lower().replace(\" \", \"_\"),\n",
    "#         )+\"_y.npy\"\n",
    "#     ).astype(TIPO_DADOS)\n",
    "    \n",
    "#     # Extrair atributos usando Deep/Tranfer Learning\n",
    "#     X = extrair_atributos_dl(\n",
    "#         X, \n",
    "#         modelo=modelo_extrator,\n",
    "#         preprocessamento=preprocess_extrator\n",
    "#     )\n",
    "    \n",
    "#     y_true, y_pred  = [], []\n",
    "    \n",
    "    \n",
    "#     print(\"   - Evaluation model (CV - 10 folds)...\\n\")\n",
    "#     for it, (idx_treino, idx_teste) in enumerate(skf.split(X, y)):\n",
    "\n",
    "#         # Preparando lotes\n",
    "#         X_treino, X_teste = X[idx_treino], X[idx_teste]\n",
    "#         y_treino, y_teste = y[idx_treino], y[idx_teste]\n",
    "        \n",
    "#         # Treinando modelo\n",
    "#         modelo = MLPClassifier(alpha=1e-3, hidden_layer_sizes=(10,), random_state=SEED)\n",
    "#         modelo.fit(X_treino, y_treino)\n",
    "        \n",
    "#         # Prevendo conjunto de teste\n",
    "#         y_hat = modelo.predict(X_teste)\n",
    "\n",
    "#         # Incrementando resultados\n",
    "#         resultados_modelo[\"appliance\"].append(a)\n",
    "#         resultados_modelo[\"fold\"].append(it+1)\n",
    "#         resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "#         resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "#         resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "        \n",
    "#         # Extendendo rotulos (analise global)\n",
    "#         y_true.extend(y_teste)\n",
    "#         y_pred.extend(y_hat)\n",
    "        \n",
    "#     print()\n",
    "#     print(\"   - Final Results:\")\n",
    "#     print(\"   ---\")\n",
    "#     print()\n",
    "\n",
    "#     print(\"      -> Classification Report:\")\n",
    "#     print()\n",
    "#     print(classification_report(y_true, y_pred))\n",
    "#     print(\"      -> Confusion Matrix:\")\n",
    "#     print()\n",
    "#     print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "#     print()\n",
    "    \n",
    "# # Consolidating DataFrame\n",
    "# df_resultados_mlp = pd.DataFrame(resultados_modelo)\n",
    "# df_resultados_mlp.to_excel(os.path.join(caminho_dados_notebook, \"df_resultados_mlp.xlsx\"))\n",
    "\n",
    "# print(\"############################## FINAL MODEL RESULTS ##############################\")\n",
    "# display(df_resultados_mlp.groupby(\"appliance\").agg({\n",
    "#     \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "#     \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "#     \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "# }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T01:33:26.158347Z",
     "start_time": "2021-03-31T01:01:51.407189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Appliance `dish_washer - 9`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98       395\n",
      "         1.0       0.20      0.08      0.11        13\n",
      "\n",
      "    accuracy                           0.96       408\n",
      "   macro avg       0.59      0.53      0.55       408\n",
      "weighted avg       0.95      0.96      0.95       408\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[391   4]\n",
      " [ 12   1]]\n",
      "\n",
      "* Appliance `fridge - 7`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         5\n",
      "         1.0       0.98      0.99      0.99       269\n",
      "\n",
      "    accuracy                           0.97       274\n",
      "   macro avg       0.49      0.50      0.49       274\n",
      "weighted avg       0.96      0.97      0.97       274\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[  0   5]\n",
      " [  2 267]]\n",
      "\n",
      "* Appliance `microwave - 16`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.98      0.97       306\n",
      "         1.0       0.57      0.40      0.47        20\n",
      "\n",
      "    accuracy                           0.94       326\n",
      "   macro avg       0.77      0.69      0.72       326\n",
      "weighted avg       0.94      0.94      0.94       326\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[300   6]\n",
      " [ 12   8]]\n",
      "\n",
      "* Appliance `washer_dryer - 13`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      4582\n",
      "         1.0       0.88      0.70      0.78       253\n",
      "\n",
      "    accuracy                           0.98      4835\n",
      "   macro avg       0.93      0.85      0.89      4835\n",
      "weighted avg       0.98      0.98      0.98      4835\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[4558   24]\n",
      " [  75  178]]\n",
      "\n",
      "* Appliance `washer_dryer - 14`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98       508\n",
      "         1.0       0.79      0.68      0.73        34\n",
      "\n",
      "    accuracy                           0.97       542\n",
      "   macro avg       0.89      0.83      0.86       542\n",
      "weighted avg       0.97      0.97      0.97       542\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[502   6]\n",
      " [ 11  23]]\n",
      "\n",
      "############################## FINAL MODEL RESULTS ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dish_washer - 9</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.997549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997549</td>\n",
       "      <td>0.997549</td>\n",
       "      <td>0.979368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.979368</td>\n",
       "      <td>0.979368</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.960854</td>\n",
       "      <td>0.034818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.539870</td>\n",
       "      <td>0.161901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.467532</td>\n",
       "      <td>0.544872</td>\n",
       "      <td>0.160385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">fridge - 7</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.978102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>0.494465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.494465</td>\n",
       "      <td>0.494465</td>\n",
       "      <td>0.498141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.498141</td>\n",
       "      <td>0.498141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.034957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.743422</td>\n",
       "      <td>0.270524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.496154</td>\n",
       "      <td>0.012163</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">microwave - 16</th>\n",
       "      <th>teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.944413</td>\n",
       "      <td>0.035634</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.701923</td>\n",
       "      <td>0.178774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.475410</td>\n",
       "      <td>0.690054</td>\n",
       "      <td>0.158364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">washer_dryer - 13</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.989245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989245</td>\n",
       "      <td>0.989245</td>\n",
       "      <td>0.939910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.939910</td>\n",
       "      <td>0.939910</td>\n",
       "      <td>0.897233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.897233</td>\n",
       "      <td>0.897233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.979525</td>\n",
       "      <td>0.006124</td>\n",
       "      <td>0.989648</td>\n",
       "      <td>0.968944</td>\n",
       "      <td>0.883928</td>\n",
       "      <td>0.040598</td>\n",
       "      <td>0.941730</td>\n",
       "      <td>0.808965</td>\n",
       "      <td>0.849459</td>\n",
       "      <td>0.058568</td>\n",
       "      <td>0.934553</td>\n",
       "      <td>0.756725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">washer_dryer - 14</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.998155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998155</td>\n",
       "      <td>0.998155</td>\n",
       "      <td>0.992046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992046</td>\n",
       "      <td>0.992046</td>\n",
       "      <td>0.985294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985294</td>\n",
       "      <td>0.985294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.968586</td>\n",
       "      <td>0.024753</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.834783</td>\n",
       "      <td>0.152204</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.823284</td>\n",
       "      <td>0.159154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.490196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               acc                                      f1  \\\n",
       "                              mean       std       max       min      mean   \n",
       "appliance         base                                                       \n",
       "dish_washer - 9   teste   0.997549       NaN  0.997549  0.997549  0.979368   \n",
       "                  treino  0.960854  0.034818  1.000000  0.878049  0.539870   \n",
       "fridge - 7        teste   0.978102       NaN  0.978102  0.978102  0.494465   \n",
       "                  treino  0.974603  0.034957  1.000000  0.888889  0.743422   \n",
       "microwave - 16    teste   1.000000       NaN  1.000000  1.000000  1.000000   \n",
       "                  treino  0.944413  0.035634  1.000000  0.875000  0.701923   \n",
       "washer_dryer - 13 teste   0.989245       NaN  0.989245  0.989245  0.939910   \n",
       "                  treino  0.979525  0.006124  0.989648  0.968944  0.883928   \n",
       "washer_dryer - 14 teste   0.998155       NaN  0.998155  0.998155  0.992046   \n",
       "                  treino  0.968586  0.024753  1.000000  0.925926  0.834783   \n",
       "\n",
       "                                                             auc            \\\n",
       "                               std       max       min      mean       std   \n",
       "appliance         base                                                       \n",
       "dish_washer - 9   teste        NaN  0.979368  0.979368  0.961538       NaN   \n",
       "                  treino  0.161901  1.000000  0.467532  0.544872  0.160385   \n",
       "fridge - 7        teste        NaN  0.494465  0.494465  0.498141       NaN   \n",
       "                  treino  0.270524  1.000000  0.470588  0.496154  0.012163   \n",
       "microwave - 16    teste        NaN  1.000000  1.000000  1.000000       NaN   \n",
       "                  treino  0.178774  1.000000  0.475410  0.690054  0.158364   \n",
       "washer_dryer - 13 teste        NaN  0.939910  0.939910  0.897233       NaN   \n",
       "                  treino  0.040598  0.941730  0.808965  0.849459  0.058568   \n",
       "washer_dryer - 14 teste        NaN  0.992046  0.992046  0.985294       NaN   \n",
       "                  treino  0.152204  1.000000  0.480769  0.823284  0.159154   \n",
       "\n",
       "                                              \n",
       "                               max       min  \n",
       "appliance         base                        \n",
       "dish_washer - 9   teste   0.961538  0.961538  \n",
       "                  treino  1.000000  0.461538  \n",
       "fridge - 7        teste   0.498141  0.498141  \n",
       "                  treino  0.500000  0.461538  \n",
       "microwave - 16    teste   1.000000  1.000000  \n",
       "                  treino  1.000000  0.483333  \n",
       "washer_dryer - 13 teste   0.897233  0.897233  \n",
       "                  treino  0.934553  0.756725  \n",
       "washer_dryer - 14 teste   0.985294  0.985294  \n",
       "                  treino  1.000000  0.490196  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": [], \"base\": []\n",
    "}\n",
    "\n",
    "for a in df_melhores_taxas_janelas.loc[\n",
    "    df_melhores_taxas_janelas[\"carga\"].isin(\n",
    "        ['dish_washer - 9','fridge - 7','microwave - 16','washer_dryer - 13',\n",
    "         'washer_dryer - 14']),\n",
    "    : ][\"carga\"].values:\n",
    "    \n",
    "    \n",
    "    print(f\"* Appliance `{a}`...\\n\")\n",
    "    \n",
    "    # Carregando dados (treino)\n",
    "    X = np.load(\n",
    "        os.path.join(\n",
    "            caminho_dados_notebook, \"treino\", \n",
    "            a.lower().replace(\" \", \"_\"),\n",
    "        )+\"_X.npy\"\n",
    "    ).astype(TIPO_DADOS)\n",
    "    y = np.load(\n",
    "        os.path.join(\n",
    "            caminho_dados_notebook, \"treino\",\n",
    "            a.lower().replace(\" \", \"_\"),\n",
    "        )+\"_y.npy\"\n",
    "    ).astype(TIPO_DADOS)\n",
    "    \n",
    "    # Extrair atributos usando Deep/Tranfer Learning\n",
    "    X = extrair_atributos_dl(\n",
    "        X, \n",
    "        modelo=modelo_extrator,\n",
    "        preprocessamento=preprocess_extrator\n",
    "    )\n",
    "    \n",
    "    y_true, y_pred  = [], []\n",
    "    \n",
    "    \n",
    "    print(\"   - Evaluation model (CV - 10 folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in enumerate(skf.split(X, y)):\n",
    "\n",
    "        # Preparando lotes\n",
    "        X_treino, X_teste = X[idx_treino], X[idx_teste]\n",
    "        y_treino, y_teste = y[idx_treino], y[idx_teste]\n",
    "        \n",
    "        # Treinando modelo\n",
    "        modelo =  MLPClassifier(alpha=1e-3, hidden_layer_sizes=(10,), random_state=SEED)\n",
    "        modelo.fit(X_treino, y_treino)\n",
    "        \n",
    "        # Prevendo conjunto de teste\n",
    "        y_hat = modelo.predict(X_teste)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(a)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "        resultados_modelo[\"base\"].append(\"treino\")\n",
    "        \n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true.extend(y_teste)\n",
    "        y_pred.extend(y_hat)\n",
    "     \n",
    "    \n",
    "    # Carregando dados (teste)\n",
    "    X_teste = np.load(\n",
    "        os.path.join(\n",
    "            caminho_dados_notebook, \"teste\", \n",
    "            a.lower().replace(\" \", \"_\"),\n",
    "        )+\"_X.npy\"\n",
    "    ).astype(TIPO_DADOS)\n",
    "    y_teste = np.load(\n",
    "        os.path.join(\n",
    "            caminho_dados_notebook, \"teste\",\n",
    "            a.lower().replace(\" \", \"_\"),\n",
    "        )+\"_y.npy\"\n",
    "    ).astype(TIPO_DADOS)\n",
    "    \n",
    "    # Extrair atributos usando Deep/Tranfer Learning\n",
    "    X_teste = extrair_atributos_dl(\n",
    "        X_teste, \n",
    "        modelo=modelo_extrator,\n",
    "        preprocessamento=preprocess_extrator\n",
    "    )\n",
    "    \n",
    "    # Treinando modelo\n",
    "    modelo =  MLPClassifier(alpha=1e-3, hidden_layer_sizes=(10,), random_state=SEED)\n",
    "    modelo.fit(X, y)\n",
    "\n",
    "    # Prevendo conjunto de teste\n",
    "    y_hat = modelo.predict(X_teste)\n",
    "\n",
    "    # Incrementando resultados\n",
    "    resultados_modelo[\"appliance\"].append(a)\n",
    "    resultados_modelo[\"fold\"].append(0)\n",
    "    resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "    resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "    resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "    resultados_modelo[\"base\"].append(\"teste\")\n",
    "    \n",
    "    print()\n",
    "    print(\"   - Final Results:\")\n",
    "    print(\"   ---\")\n",
    "    print()\n",
    "\n",
    "    print(\"      -> Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"      -> Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "# Consolidating DataFrame\n",
    "df_resultados_mlp = pd.DataFrame(resultados_modelo)\n",
    "df_resultados_mlp.to_excel(os.path.join(caminho_dados_notebook, \"df_resultados_mlp.xlsx\"))\n",
    "    \n",
    "print(\"############################## FINAL MODEL RESULTS ##############################\")\n",
    "display(df_resultados_mlp.groupby([\"appliance\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## ELM - Extreme Learning Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T02:32:19.809428Z",
     "start_time": "2020-09-03T02:32:19.796427Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from elm import ELM\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T02:32:31.695795Z",
     "start_time": "2020-09-03T02:32:20.111449Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Appliance `fridge - 7`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        11\n",
      "         1.0       0.85      1.00      0.92        60\n",
      "\n",
      "    accuracy                           0.85        71\n",
      "   macro avg       0.42      0.50      0.46        71\n",
      "weighted avg       0.71      0.85      0.77        71\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[ 0 11]\n",
      " [ 0 60]]\n",
      "\n",
      "* Appliance `dish_washer - 9`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.30      0.46       336\n",
      "         1.0       0.03      1.00      0.06         7\n",
      "\n",
      "    accuracy                           0.31       343\n",
      "   macro avg       0.51      0.65      0.26       343\n",
      "weighted avg       0.98      0.31      0.45       343\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[100 236]\n",
      " [  0   7]]\n",
      "\n",
      "* Appliance `washer_dryer - 13`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.31      0.47       218\n",
      "         1.0       0.06      0.90      0.11        10\n",
      "\n",
      "    accuracy                           0.34       228\n",
      "   macro avg       0.52      0.61      0.29       228\n",
      "weighted avg       0.94      0.34      0.46       228\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[ 68 150]\n",
      " [  1   9]]\n",
      "\n",
      "* Appliance `washer_dryer - 14`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.38      0.54       218\n",
      "         1.0       0.05      0.70      0.09        10\n",
      "\n",
      "    accuracy                           0.39       228\n",
      "   macro avg       0.51      0.54      0.32       228\n",
      "weighted avg       0.92      0.39      0.52       228\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[ 82 136]\n",
      " [  3   7]]\n",
      "\n",
      "* Appliance `microwave - 16`...\n",
      "\n",
      "   - Evaluation model (CV - 10 folds)...\n",
      "\n",
      "\n",
      "   - Final Results:\n",
      "   ---\n",
      "\n",
      "      -> Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.31      0.48       407\n",
      "         1.0       0.07      1.00      0.13        21\n",
      "\n",
      "    accuracy                           0.35       428\n",
      "   macro avg       0.54      0.66      0.30       428\n",
      "weighted avg       0.95      0.35      0.46       428\n",
      "\n",
      "      -> Confusion Matrix:\n",
      "\n",
      "[[128 279]\n",
      " [  0  21]]\n",
      "\n",
      "############################## FINAL MODEL RESULTS ##############################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dish_washer - 9</th>\n",
       "      <td>0.311513</td>\n",
       "      <td>0.147756</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.250487</td>\n",
       "      <td>0.102857</td>\n",
       "      <td>0.379162</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.616622</td>\n",
       "      <td>0.101367</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fridge - 7</th>\n",
       "      <td>0.846429</td>\n",
       "      <td>0.033882</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.458242</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>microwave - 16</th>\n",
       "      <td>0.348117</td>\n",
       "      <td>0.108929</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.300441</td>\n",
       "      <td>0.074358</td>\n",
       "      <td>0.407869</td>\n",
       "      <td>0.202990</td>\n",
       "      <td>0.657165</td>\n",
       "      <td>0.057642</td>\n",
       "      <td>0.743902</td>\n",
       "      <td>0.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>washer_dryer - 13</th>\n",
       "      <td>0.337945</td>\n",
       "      <td>0.066310</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.287393</td>\n",
       "      <td>0.044969</td>\n",
       "      <td>0.356989</td>\n",
       "      <td>0.203846</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.144927</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.204545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>washer_dryer - 14</th>\n",
       "      <td>0.391107</td>\n",
       "      <td>0.090202</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.311818</td>\n",
       "      <td>0.056856</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.538528</td>\n",
       "      <td>0.227790</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.159091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        acc                                      f1            \\\n",
       "                       mean       std       max       min      mean       std   \n",
       "appliance                                                                       \n",
       "dish_washer - 9    0.311513  0.147756  0.500000  0.147059  0.250487  0.102857   \n",
       "fridge - 7         0.846429  0.033882  0.857143  0.750000  0.458242  0.010425   \n",
       "microwave - 16     0.348117  0.108929  0.511628  0.214286  0.300441  0.074358   \n",
       "washer_dryer - 13  0.337945  0.066310  0.434783  0.217391  0.287393  0.044969   \n",
       "washer_dryer - 14  0.391107  0.090202  0.545455  0.260870  0.311818  0.056856   \n",
       "\n",
       "                                            auc                                \n",
       "                        max       min      mean       std       max       min  \n",
       "appliance                                                                      \n",
       "dish_washer - 9    0.379162  0.128205  0.616622  0.101367  0.742424  0.500000  \n",
       "fridge - 7         0.461538  0.428571  0.500000  0.000000  0.500000  0.500000  \n",
       "microwave - 16     0.407869  0.202990  0.657165  0.057642  0.743902  0.587500  \n",
       "washer_dryer - 13  0.356989  0.203846  0.606061  0.144927  0.704545  0.204545  \n",
       "washer_dryer - 14  0.427083  0.233333  0.538528  0.227790  0.761905  0.159091  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultados_modelo = {\n",
    "    \"appliance\": [], \"fold\": [],\n",
    "    \"acc\": [], \"f1\": [], \"auc\": []\n",
    "}\n",
    "\n",
    "for a in df_melhores_taxas_janelas.loc[\n",
    "    df_melhores_taxas_janelas[\"carga\"].isin(\n",
    "        ['dish_washer - 9','fridge - 7','microwave - 16','washer_dryer - 13',\n",
    "         'washer_dryer - 14']),\n",
    "    : ][\"carga\"].values:\n",
    "    \n",
    "    \n",
    "    print(f\"* Appliance `{a}`...\\n\")\n",
    "    \n",
    "    # Carregando dados\n",
    "    X = np.load(\n",
    "        os.path.join(\n",
    "            caminho_dados_notebook, \n",
    "            a.lower().replace(\" \", \"_\"),\n",
    "        )+\"_X.npy\"\n",
    "    ).astype(TIPO_DADOS)\n",
    "    y = np.load(\n",
    "        os.path.join(\n",
    "            caminho_dados_notebook, \n",
    "            a.lower().replace(\" \", \"_\"),\n",
    "        )+\"_y.npy\"\n",
    "    ).astype(TIPO_DADOS)\n",
    "    \n",
    "    # Extrair atributos usando Deep/Tranfer Learning\n",
    "    X = extrair_atributos_dl(\n",
    "        X, \n",
    "        modelo=modelo_extrator,\n",
    "        preprocessamento=preprocess_extrator\n",
    "    )\n",
    "        \n",
    "    y_true, y_pred  = [], []\n",
    "    \n",
    "    \n",
    "    print(\"   - Evaluation model (CV - 10 folds)...\\n\")\n",
    "    for it, (idx_treino, idx_teste) in enumerate(skf.split(X, y)):\n",
    "\n",
    "        # Preparando lotes\n",
    "        X_treino, X_teste = X[idx_treino], X[idx_teste]\n",
    "        y_treino, y_teste = y[idx_treino], y[idx_teste]\n",
    "        \n",
    "        # Treinando modelo\n",
    "        modelo = ELM(hid_num=10)\n",
    "        modelo.fit(normalize(X_treino), y_treino)\n",
    "        \n",
    "        # Prevendo conjunto de teste\n",
    "        y_hat = modelo.predict(normalize(X_teste))\n",
    "        y_hat = (y_hat > 0.5).astype(int)\n",
    "\n",
    "        # Incrementando resultados\n",
    "        resultados_modelo[\"appliance\"].append(a)\n",
    "        resultados_modelo[\"fold\"].append(it+1)\n",
    "        resultados_modelo[\"acc\"].append( accuracy_score(y_teste, y_hat) )\n",
    "        resultados_modelo[\"f1\"].append( f1_score(y_teste, y_hat, average=\"macro\") )\n",
    "        resultados_modelo[\"auc\"].append(roc_auc_score(y_teste, y_hat) if np.unique(y_teste).shape[0]>1 else 0.5)\n",
    "        \n",
    "        # Extendendo rotulos (analise global)\n",
    "        y_true.extend(y_teste)\n",
    "        y_pred.extend(y_hat)\n",
    "        \n",
    "    print()\n",
    "    print(\"   - Final Results:\")\n",
    "    print(\"   ---\")\n",
    "    print()\n",
    "\n",
    "    print(\"      -> Classification Report:\")\n",
    "    print()\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"      -> Confusion Matrix:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "# Consolidating DataFrame\n",
    "df_resultados_elm = pd.DataFrame(resultados_modelo)\n",
    "df_resultados_elm.to_excel(os.path.join(caminho_dados_notebook, \"df_resultados_elm.xlsx\"))\n",
    "\n",
    "print(\"############################## FINAL MODEL RESULTS ##############################\")\n",
    "display(df_resultados_elm.groupby(\"appliance\").agg({\n",
    "    \"acc\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"f1\": [\"mean\", \"std\", \"max\", \"min\"],\n",
    "    \"auc\": [\"mean\", \"std\", \"max\", \"min\"]\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise dos Resultados (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T11:49:02.372043Z",
     "start_time": "2021-03-31T11:48:59.563384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Análise por modelo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBOOST</th>\n",
       "      <td>teste</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>teste</td>\n",
       "      <td>0.992610</td>\n",
       "      <td>0.009104</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>0.881158</td>\n",
       "      <td>0.217398</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.494465</td>\n",
       "      <td>0.868441</td>\n",
       "      <td>0.210701</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.498141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>teste</td>\n",
       "      <td>0.983314</td>\n",
       "      <td>0.009541</td>\n",
       "      <td>0.993865</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.763175</td>\n",
       "      <td>0.246814</td>\n",
       "      <td>0.972056</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.742139</td>\n",
       "      <td>0.223176</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>treino</td>\n",
       "      <td>0.976712</td>\n",
       "      <td>0.017036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.761836</td>\n",
       "      <td>0.214826</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.694653</td>\n",
       "      <td>0.197203</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBOOST</th>\n",
       "      <td>treino</td>\n",
       "      <td>0.972298</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.754227</td>\n",
       "      <td>0.207444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.693422</td>\n",
       "      <td>0.196615</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>treino</td>\n",
       "      <td>0.965596</td>\n",
       "      <td>0.030885</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.740785</td>\n",
       "      <td>0.207886</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.467532</td>\n",
       "      <td>0.680764</td>\n",
       "      <td>0.187977</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           base       acc                                      f1            \\\n",
       "                     mean       std       max       min      mean       std   \n",
       "model                                                                         \n",
       "XGBOOST   teste  1.000000  0.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "MLP       teste  0.992610  0.009104  1.000000  0.978102  0.881158  0.217398   \n",
       "SVM       teste  0.983314  0.009541  0.993865  0.968137  0.763175  0.246814   \n",
       "SVM      treino  0.976712  0.017036  1.000000  0.937500  0.761836  0.214826   \n",
       "XGBOOST  treino  0.972298  0.022801  1.000000  0.888889  0.754227  0.207444   \n",
       "MLP      treino  0.965596  0.030885  1.000000  0.875000  0.740785  0.207886   \n",
       "\n",
       "                                  auc                            \n",
       "              max       min      mean       std   max       min  \n",
       "model                                                            \n",
       "XGBOOST  1.000000  1.000000  1.000000  0.000000  1.00  1.000000  \n",
       "MLP      1.000000  0.494465  0.868441  0.210701  1.00  0.498141  \n",
       "SVM      0.972056  0.491905  0.742139  0.223176  0.95  0.500000  \n",
       "SVM      1.000000  0.483871  0.694653  0.197203  1.00  0.500000  \n",
       "XGBOOST  1.000000  0.470588  0.693422  0.196615  1.00  0.461538  \n",
       "MLP      1.000000  0.467532  0.680764  0.187977  1.00  0.461538  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Análise por aparelho/modelo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appliance</th>\n",
       "      <th>model</th>\n",
       "      <th>base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dish_washer - 9</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.997549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997549</td>\n",
       "      <td>0.997549</td>\n",
       "      <td>0.979368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.979368</td>\n",
       "      <td>0.979368</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.960854</td>\n",
       "      <td>0.034818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.539870</td>\n",
       "      <td>0.161901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.467532</td>\n",
       "      <td>0.544872</td>\n",
       "      <td>0.160385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.968137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.491905</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.968171</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.491898</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.968171</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.491898</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">fridge - 7</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.978102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>0.494465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.494465</td>\n",
       "      <td>0.494465</td>\n",
       "      <td>0.498141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.498141</td>\n",
       "      <td>0.498141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.034957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.743422</td>\n",
       "      <td>0.270524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.496154</td>\n",
       "      <td>0.012163</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.981752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.495396</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.982011</td>\n",
       "      <td>0.018967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.745420</td>\n",
       "      <td>0.268351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.034957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.743422</td>\n",
       "      <td>0.270524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.496154</td>\n",
       "      <td>0.012163</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">microwave - 16</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.944413</td>\n",
       "      <td>0.035634</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.701923</td>\n",
       "      <td>0.178774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.475410</td>\n",
       "      <td>0.690054</td>\n",
       "      <td>0.158364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.993865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993865</td>\n",
       "      <td>0.993865</td>\n",
       "      <td>0.972056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.972056</td>\n",
       "      <td>0.972056</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.963258</td>\n",
       "      <td>0.019375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.747087</td>\n",
       "      <td>0.189375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.723333</td>\n",
       "      <td>0.181761</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.953977</td>\n",
       "      <td>0.021591</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.761079</td>\n",
       "      <td>0.158922</td>\n",
       "      <td>0.891803</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.788495</td>\n",
       "      <td>0.189077</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">washer_dryer - 13</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.989245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989245</td>\n",
       "      <td>0.989245</td>\n",
       "      <td>0.939910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.939910</td>\n",
       "      <td>0.939910</td>\n",
       "      <td>0.897233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.897233</td>\n",
       "      <td>0.897233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.979525</td>\n",
       "      <td>0.006124</td>\n",
       "      <td>0.989648</td>\n",
       "      <td>0.968944</td>\n",
       "      <td>0.883928</td>\n",
       "      <td>0.040598</td>\n",
       "      <td>0.941730</td>\n",
       "      <td>0.808965</td>\n",
       "      <td>0.849459</td>\n",
       "      <td>0.058568</td>\n",
       "      <td>0.934553</td>\n",
       "      <td>0.756725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.985729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985729</td>\n",
       "      <td>0.985729</td>\n",
       "      <td>0.917316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.917316</td>\n",
       "      <td>0.917316</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.984902</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>0.991718</td>\n",
       "      <td>0.975155</td>\n",
       "      <td>0.911358</td>\n",
       "      <td>0.036825</td>\n",
       "      <td>0.956155</td>\n",
       "      <td>0.835640</td>\n",
       "      <td>0.863410</td>\n",
       "      <td>0.052259</td>\n",
       "      <td>0.938908</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.985109</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.991718</td>\n",
       "      <td>0.975155</td>\n",
       "      <td>0.912183</td>\n",
       "      <td>0.036527</td>\n",
       "      <td>0.954348</td>\n",
       "      <td>0.835640</td>\n",
       "      <td>0.861628</td>\n",
       "      <td>0.049488</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">washer_dryer - 14</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.998155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998155</td>\n",
       "      <td>0.998155</td>\n",
       "      <td>0.992046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992046</td>\n",
       "      <td>0.992046</td>\n",
       "      <td>0.985294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985294</td>\n",
       "      <td>0.985294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.968586</td>\n",
       "      <td>0.024753</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.834783</td>\n",
       "      <td>0.152204</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.823284</td>\n",
       "      <td>0.159154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.490196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>teste</th>\n",
       "      <td>0.987085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987085</td>\n",
       "      <td>0.987085</td>\n",
       "      <td>0.939202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.939202</td>\n",
       "      <td>0.939202</td>\n",
       "      <td>0.897059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.897059</td>\n",
       "      <td>0.897059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.985219</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.913418</td>\n",
       "      <td>0.100730</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.740385</td>\n",
       "      <td>0.886520</td>\n",
       "      <td>0.135286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBOOST</th>\n",
       "      <th>teste</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treino</th>\n",
       "      <td>0.979630</td>\n",
       "      <td>0.018415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.862554</td>\n",
       "      <td>0.130776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.740385</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.166725</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       acc                                \\\n",
       "                                      mean       std       max       min   \n",
       "appliance         model   base                                             \n",
       "dish_washer - 9   MLP     teste   0.997549       NaN  0.997549  0.997549   \n",
       "                          treino  0.960854  0.034818  1.000000  0.878049   \n",
       "                  SVM     teste   0.968137       NaN  0.968137  0.968137   \n",
       "                          treino  0.968171  0.011700  0.975610  0.951220   \n",
       "                  XGBOOST teste   1.000000       NaN  1.000000  1.000000   \n",
       "                          treino  0.968171  0.011700  0.975610  0.951220   \n",
       "fridge - 7        MLP     teste   0.978102       NaN  0.978102  0.978102   \n",
       "                          treino  0.974603  0.034957  1.000000  0.888889   \n",
       "                  SVM     teste   0.981752       NaN  0.981752  0.981752   \n",
       "                          treino  0.982011  0.018967  1.000000  0.962963   \n",
       "                  XGBOOST teste   1.000000       NaN  1.000000  1.000000   \n",
       "                          treino  0.974603  0.034957  1.000000  0.888889   \n",
       "microwave - 16    MLP     teste   1.000000       NaN  1.000000  1.000000   \n",
       "                          treino  0.944413  0.035634  1.000000  0.875000   \n",
       "                  SVM     teste   0.993865       NaN  0.993865  0.993865   \n",
       "                          treino  0.963258  0.019375  1.000000  0.937500   \n",
       "                  XGBOOST teste   1.000000       NaN  1.000000  1.000000   \n",
       "                          treino  0.953977  0.021591  0.969697  0.909091   \n",
       "washer_dryer - 13 MLP     teste   0.989245       NaN  0.989245  0.989245   \n",
       "                          treino  0.979525  0.006124  0.989648  0.968944   \n",
       "                  SVM     teste   0.985729       NaN  0.985729  0.985729   \n",
       "                          treino  0.984902  0.005164  0.991718  0.975155   \n",
       "                  XGBOOST teste   1.000000       NaN  1.000000  1.000000   \n",
       "                          treino  0.985109  0.005142  0.991718  0.975155   \n",
       "washer_dryer - 14 MLP     teste   0.998155       NaN  0.998155  0.998155   \n",
       "                          treino  0.968586  0.024753  1.000000  0.925926   \n",
       "                  SVM     teste   0.987085       NaN  0.987085  0.987085   \n",
       "                          treino  0.985219  0.014599  1.000000  0.962963   \n",
       "                  XGBOOST teste   1.000000       NaN  1.000000  1.000000   \n",
       "                          treino  0.979630  0.018415  1.000000  0.962963   \n",
       "\n",
       "                                        f1                                \\\n",
       "                                      mean       std       max       min   \n",
       "appliance         model   base                                             \n",
       "dish_washer - 9   MLP     teste   0.979368       NaN  0.979368  0.979368   \n",
       "                          treino  0.539870  0.161901  1.000000  0.467532   \n",
       "                  SVM     teste   0.491905       NaN  0.491905  0.491905   \n",
       "                          treino  0.491898  0.003035  0.493827  0.487500   \n",
       "                  XGBOOST teste   1.000000       NaN  1.000000  1.000000   \n",
       "                          treino  0.491898  0.003035  0.493827  0.487500   \n",
       "fridge - 7        MLP     teste   0.494465       NaN  0.494465  0.494465   \n",
       "                          treino  0.743422  0.270524  1.000000  0.470588   \n",
       "                  SVM     teste   0.495396       NaN  0.495396  0.495396   \n",
       "                          treino  0.745420  0.268351  1.000000  0.490566   \n",
       "                  XGBOOST teste   1.000000       NaN  1.000000  1.000000   \n",
       "                          treino  0.743422  0.270524  1.000000  0.470588   \n",
       "microwave - 16    MLP     teste   1.000000       NaN  1.000000  1.000000   \n",
       "                          treino  0.701923  0.178774  1.000000  0.475410   \n",
       "                  SVM     teste   0.972056       NaN  0.972056  0.972056   \n",
       "                          treino  0.747087  0.189375  1.000000  0.483871   \n",
       "                  XGBOOST teste   1.000000       NaN  1.000000  1.000000   \n",
       "                          treino  0.761079  0.158922  0.891803  0.483871   \n",
       "washer_dryer - 13 MLP     teste   0.939910       NaN  0.939910  0.939910   \n",
       "                          treino  0.883928  0.040598  0.941730  0.808965   \n",
       "                  SVM     teste   0.917316       NaN  0.917316  0.917316   \n",
       "                          treino  0.911358  0.036825  0.956155  0.835640   \n",
       "                  XGBOOST teste   1.000000       NaN  1.000000  1.000000   \n",
       "                          treino  0.912183  0.036527  0.954348  0.835640   \n",
       "washer_dryer - 14 MLP     teste   0.992046       NaN  0.992046  0.992046   \n",
       "                          treino  0.834783  0.152204  1.000000  0.480769   \n",
       "                  SVM     teste   0.939202       NaN  0.939202  0.939202   \n",
       "                          treino  0.913418  0.100730  1.000000  0.740385   \n",
       "                  XGBOOST teste   1.000000       NaN  1.000000  1.000000   \n",
       "                          treino  0.862554  0.130776  1.000000  0.740385   \n",
       "\n",
       "                                       auc                                \n",
       "                                      mean       std       max       min  \n",
       "appliance         model   base                                            \n",
       "dish_washer - 9   MLP     teste   0.961538       NaN  0.961538  0.961538  \n",
       "                          treino  0.544872  0.160385  1.000000  0.461538  \n",
       "                  SVM     teste   0.500000       NaN  0.500000  0.500000  \n",
       "                          treino  0.500000  0.000000  0.500000  0.500000  \n",
       "                  XGBOOST teste   1.000000       NaN  1.000000  1.000000  \n",
       "                          treino  0.500000  0.000000  0.500000  0.500000  \n",
       "fridge - 7        MLP     teste   0.498141       NaN  0.498141  0.498141  \n",
       "                          treino  0.496154  0.012163  0.500000  0.461538  \n",
       "                  SVM     teste   0.500000       NaN  0.500000  0.500000  \n",
       "                          treino  0.500000  0.000000  0.500000  0.500000  \n",
       "                  XGBOOST teste   1.000000       NaN  1.000000  1.000000  \n",
       "                          treino  0.496154  0.012163  0.500000  0.461538  \n",
       "microwave - 16    MLP     teste   1.000000       NaN  1.000000  1.000000  \n",
       "                          treino  0.690054  0.158364  1.000000  0.483333  \n",
       "                  SVM     teste   0.950000       NaN  0.950000  0.950000  \n",
       "                          treino  0.723333  0.181761  1.000000  0.500000  \n",
       "                  XGBOOST teste   1.000000       NaN  1.000000  1.000000  \n",
       "                          treino  0.788495  0.189077  0.983871  0.500000  \n",
       "washer_dryer - 13 MLP     teste   0.897233       NaN  0.897233  0.897233  \n",
       "                          treino  0.849459  0.058568  0.934553  0.756725  \n",
       "                  SVM     teste   0.863636       NaN  0.863636  0.863636  \n",
       "                          treino  0.863410  0.052259  0.938908  0.760000  \n",
       "                  XGBOOST teste   1.000000       NaN  1.000000  1.000000  \n",
       "                          treino  0.861628  0.049488  0.920000  0.760000  \n",
       "washer_dryer - 14 MLP     teste   0.985294       NaN  0.985294  0.985294  \n",
       "                          treino  0.823284  0.159154  1.000000  0.490196  \n",
       "                  SVM     teste   0.897059       NaN  0.897059  0.897059  \n",
       "                          treino  0.886520  0.135286  1.000000  0.666667  \n",
       "                  XGBOOST teste   1.000000       NaN  1.000000  1.000000  \n",
       "                          treino  0.820833  0.166725  1.000000  0.666667  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_resultados_svm = pd.read_excel(os.path.join(caminho_dados_notebook, \"df_resultados_svm.xlsx\"), engine=\"openpyxl\")\n",
    "df_resultados_svm[\"model\"] = \"SVM\"\n",
    "\n",
    "df_resultados_xgboost = pd.read_excel(os.path.join(caminho_dados_notebook, \"df_resultados_xgboost.xlsx\"), engine=\"openpyxl\")\n",
    "df_resultados_xgboost[\"model\"] = \"XGBOOST\"\n",
    "\n",
    "df_resultados_mlp = pd.read_excel(os.path.join(caminho_dados_notebook, \"df_resultados_mlp.xlsx\"), engine=\"openpyxl\")\n",
    "df_resultados_mlp[\"model\"] = \"MLP\"\n",
    "\n",
    "# df_resultados_elm = pd.read_excel(os.path.join(caminho_dados_notebook, \"df_resultados_elm.xlsx\"), engine=\"openpyxl)\n",
    "# df_resultados_elm[\"model\"] = \"ELM\"\n",
    "\n",
    "df_analise = pd.concat([\n",
    "    df_resultados_svm,\n",
    "    df_resultados_xgboost,\n",
    "    df_resultados_mlp, \n",
    "#     df_resultados_elm,  \n",
    "])\n",
    "\n",
    "print(\"* Análise por modelo:\")\n",
    "df_analise_modelo = df_analise.groupby([\"model\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"f1\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"auc\": [\"mean\",\"std\",\"max\",\"min\"]\n",
    "}).reset_index().sort_values(('f1','mean'), ascending=False).set_index(\"model\")\n",
    "display(df_analise_modelo)\n",
    "df_analise_modelo.to_excel(os.path.join(caminho_dados_notebook, \"df_analise_modelo.xlsx\"))\n",
    "\n",
    "print()\n",
    "print(\"* Análise por aparelho/modelo:\")\n",
    "df_analise_aparelho = df_analise.groupby([\"appliance\",\"model\",\"base\"]).agg({\n",
    "    \"acc\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"f1\": [\"mean\",\"std\",\"max\",\"min\"],\n",
    "    \"auc\": [\"mean\",\"std\",\"max\",\"min\"]\n",
    "})#.reset_index().sort_values(('f1','mean'), ascending=False).set_index([\"aparelho\",\"metodologia\"])\n",
    "display(df_analise_aparelho)\n",
    "df_analise_aparelho.to_excel(os.path.join(caminho_dados_notebook, \"df_analise_aparelho.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T20:08:48.625381Z",
     "start_time": "2020-09-05T20:08:48.043316Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T20:08:49.020933Z",
     "start_time": "2020-09-05T20:08:48.809454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diego Luiz Cavalca \n",
      "last updated: Sat Sep 05 2020 17:08:48 Hora oficial do Brasil \n",
      "\n",
      "CPython 3.7.8\n",
      "IPython 7.17.0\n",
      "\n",
      "compiler   : MSC v.1916 64 bit (AMD64)\n",
      "system     : Windows\n",
      "release    : 10\n",
      "machine    : AMD64\n",
      "processor  : Intel64 Family 6 Model 158 Stepping 9, GenuineIntel\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      "Git hash   : 5725caa95e9d7f4b19a57eff5b998f1738bc40b4\n"
     ]
    }
   ],
   "source": [
    "%watermark -a \"Diego Luiz Cavalca\" -u -n -t -z -v -m -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
